---
layout: post
title: Lucene in action-07-analysis 分析
date: 2022-01-10 21:01:55 +0800 
categories: [Lucene]
tags: [Lucene, search, sh]
published: true
---

# 分析

分析(Analysis)， 在 Lucene 当中指的是将域(Field) 文本转换为最基本的索引表示单元——-项(Term)的过程。

在搜索过程中，这些项用于决定什么样的文档能匹配查询条件。

例如，如果这句话“For example. if this sentence were indexed into a field”被索引到一个域(Field)中(假设域类型为 Field.Text)， 相应产生的项可能是以 for 和 example两个单词打头，其它的项随之按照它在句子中出现的先后顺序逐个排列。分析器(analyzer) 对分析操作进行了封装。分析器通过执行若干操作，将文本语汇单元化，这些操作可能包括提取单词、去除标点符号、去掉语汇单元上的音调符号、将字母转换为小写(也称为规格化)、移除常用词、将单词转换为词干形式(词干还原)，或者将单词转换为基本形(lemmatization) 等。这个过程也称为语汇单元化过程 (tokenization)，而从文本流中得到的文本块称为语汇单元(tokens)。各语汇单元与关联的域(Field)名相结合就形成了各个项(Term)。

开发 Lucene 的主要日的是为了让信息检索变得更容易。强调检索是很重要的。用户一定希望向 Lucene 中装载大量文本，并且希望通过文本中的单词迅速的找到相关的文档。为了让Lucene 理解“单词”是什么，就要在索引时分析文本，并将项从文本中提取出来。而这些项构成了搜索的基础构件。

使用 Lucene时，选择一个合适的分析器是非常关键的。对分析器的选择没有惟一的标准。待分析的语种是影响分析器选择的因素之一，因为每种语言都有其自身的特点。影响分析器选择的另一个因素是被分析的文本所属的领域，不同的行业有不同的术语、缩写词和缩略语，我们在分析过程中一定要注意这一点。尽管我们在选择分析器时考虑了很多因素，但是不存在任何一个分析器能适用于所有情况。有可能所有的内置分析器都不能满足你的需求，这时就得创建一个自定义分析解决方案；令人振奋的是， Lucene的构件模块让这一过程变得十分容易。

当读者研究分析过程时，可能经常会问“Google 是怎么做的?”。 

Google 目前的算法是公司私有并且相对保密的，但是从搜索结果中我们可以看出一些端倪。

让我们做一个有趣的实验，在带引号和不带引号的情况下分别搜索短语“to be or not to be"。

令人惊讶的是，在不带引号的情况下， Google(在本书写作期间)惟一考虑的单词是： not：其他单词都被当作常用词被移除掉了。但是， Google 在索引期间并没有移除这些停止词(stop words)， 通过搜索带引号的短语你就可以明白这一点。这里有一个有趣的现象：目前搜索引擎中索引的停用词数量多得惊人!

Google 是怎样做到在索引 Internet 上网页中每个单词的同时，又不耗尽存储资源的呢?

基于 Lucene 的分析器为我们提供了这个问题的解决方案，正如我们下面将要讨论的一样。

这一章我们将涉及 Lucene 分析过程的方方面面，包括怎样、在何处使用分析器、内置分析器的具体作用，以及怎样利用 Lucene 中的核心API所提供的构件模块编写自定义的分析器等内容。

# 4.1 使用分析器

在深入了解分析器内部的繁琐细节之前，让我们先看一下分析器在 Lucene 中是如何被使用的。分析操作发生在两个阶段：建立索引以及使用 QueryParser 对象时。在下面的两节中，我们将详细讨论如何在这两个场景下如何使用分析器。
    在我们着手介绍具体代码之前，先阅读程序4.1以便对分析过程有一个总体的认识。我们使用4个内置分析器对两个短语进行了分析。这两个短语分别是：“The quick brownfox jumped over the lazy dogs”和“XY&Z Corporation-xyz@example.com”.在输出结果里，每个语汇单元都由方括号分隔开。进行索引时，分析期间提取出的语汇单元就是后来被编入到索引中的项。此外，最重要的就是，索引后的项就是可以用于搜索的项。





# 参考资料

《Lucene in Action II》

* any list
{:toc}