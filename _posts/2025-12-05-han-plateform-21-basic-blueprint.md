---
layout: post
title: NLP 平台-03-基础的设计蓝图
date: 2025-12-5 20:49:20 +0800
categories: [NLP]
tags: [nlp, sh]
published: true
---

# 汉语基础预料的管理平台

下面给一个**面向可交付、按优先级（P0→P2）划分的功能规划**，专注于你想先做的三类语料：**汉字（word）/ 词语（ci）/ 歇后语（xiehouyu）**。每个条目都包含：**为什么要先做、验收标准（可交付物）和实现要点/注意事项**，便于你直接落地实现或分配给团队去干。

我会把优先级分为三个阶段：

* **P0（MVP 必须）**：产品能用起来的最小集合；
* **P1（关键能力）**：提升质量与运维效率、支撑后续功能；
* **P2（增强/智能化）**：让语料“能被 NLP 用”的功能，放在稳定后实现。

---

# P0 — MVP（必须先实现，平台能“用”起来）

这些功能做完后，任何人都能把现有 JSON 导入、查、改、删，开始常规管理。

## 1. 统一元数据 Schema（必须）

**为什么？** 不同源文件字段不一致，统一 schema 是后面一切功能的前提。
**验收标准：** 定义并实现 JSON Schema（或 DB 表结构）并能用于导入校验。
**要点：**

* 公共字段：`id, type, text, pinyin?, explanation, tags[], raw?, meta{source, version, imported_at}`。
* 各类型扩展字段：

  * `word`（汉字）：`word, pinyin[], radicals, strokes, unicode, meanings[]`
  * `ci`（词语）：`ci, pinyin, pos?, senses[]`
  * `xiehouyu`（歇后语）：`riddle, answer, explanation, region?`
    **示例（简短 JSON Schema）** 我会在下一步给出可用模板（如果你要我直接生成，我现在就给出）。

---

## 2. 导入 / 清洗 Pipeline（一次性把现有 JSON 入库）

**为什么？** 源数据格式混乱，需要自动化导入并规范化，避免后续手工改大量条目。
**验收标准：** 能把 `idiom.json` / `word.json` / `ci.json` / `xiehouyu.json` 全部导入到数据库，导入报告显示：总数/成功数/失败数/重复数。
**要点：**

* 支持文件格式：JSON、CSV。
* 映射规则（字段名映射），空值填充（pinyin 自动空或调用后续任务生成）。
* 基础清洗：trim、移除不可见字符、统一引号/星号符号处理、去重（基于 text+type 或 normalized text）。
* 报告：导入日志+样例错误行。

---

## 3. 基础 CRUD 后台与列表页（Web UI）

**为什么？** 管理必须能直接查看条目并修改。
**验收标准：** 管理员能在 UI 中：搜索条目、分页浏览、查看详情、编辑保存、软删除与恢复、导出 selected CSV/JSON。
**要点：**

* 列表按 type 过滤（汉字/词/歇后语）
* 详情页显示 raw 原始数据与结构化字段（allow edit）
* 支持富文本显示 explanation（保留换行）

---

## 4. 基本搜索（文本、拼音、类型）

**为什么？** 无搜索，管理效率极低。
**验收标准：** 能做到按 `text` 模糊搜索、按 `pinyin` 搜索（拼音包含/前缀匹配）、按 `type` 过滤。
**要点：**

* 初版可以在数据库中用 LIKE / full-text（MySQL / Postgres）或简单倒排（小量数据）。
* 搜索需忽略声调/大小写/全半角差异。

---

## 5. 导出（按筛选导出 JSON/CSV）

**为什么？** 便于迁移、备份、审核。
**验收标准：** 在 UI 或 API 能导出当前筛选结果为 JSON 或 CSV 文件。

---

# P1 — 核心增强（提升数据质量、协作和安全）

在 MVP 之上，做这些能显著提升平台可维护性和团队协作效率。

## 6. 版本控制 & 审计（变更日志）

**为什么？** 数据会被多人修改，需要回溯与回滚。
**验收标准：** 每次编辑产生变更记录（用户、时间、变更前后差异），并能回滚到任意历史版本（最近若干）。
**要点：**

* 简单实现：数据库 audit 表保存 diffs 或快照。
* 高级实现：把数据存为 Git-like 版本或使用专门的版本库。

---

## 7. 批量编辑/批量替换 & 验证规则

**为什么？** 大规模修正、统一规范字段时非常必要。
**验收标准：** 支持：批量更改 tags、批量标注 pinyin、批量删除重复项；支持先预览再执行。
**要点：**

* 支持 dry-run 预览影响条目数与示例。

---

## 8. 权限与审核流（RBAC）

**为什么？** 多人协作需要控制谁能直接修改、谁需要审核。
**验收标准：** 至少支持角色：`admin, editor, reviewer, viewer`；editor 的修改进入待审核队列，reviewer 可批准/拒绝。
**要点：**

* UI 显示待审核列表，审计记录关联到用户。

---

## 9. 标签系统（tags / taxonomies）

**为什么？** 快速分类、过滤和后续自动化（如生成 relation）。
**验收标准：** 增加 tag 管理界面（新增/删除/merge tags），条目可打多个 tag，支持按 tag 搜索。
**要点：**

* 预定义几类 tag：`情感/方言/高频/多音/古义/成语成分` 等。

---

# P2 — 智能化 & 关系化（放在数据稳定后）

这些是面向 NLP、推荐、知识图谱的能力，数据稳定与结构化后更容易做。

## 10. 关系抽取与基础关联（字 ↔ 词 ↔ 成语/歇后语）

**为什么？** 建关系能让平台做语义搜索、推荐、错误检测。
**验收标准：** 系统能自动或半自动建立：词包含的汉字、成语拆字、歇后语答案到词/成语的映射；并在 UI 上展示关系图（小规模）。
**要点：**

* 规则优先（基于字符串拆分/包含），人工校验后采纳。
* 保存关系类型：`contains`, `variant_of`, `same_as`, `related_to`。

---

## 11. 同/近/反义词、形近字表（半自动）

**为什么？** 对于语言理解和校验很重要（纠错、扩展检索）。
**验收标准：** 提供接口查询近义词、反义词、形近字，支持人工确认。
**要点：**

* 初版用启发式规则+小词表，再逐步用 embedding 或外部词典扩充。

---

## 12. 导入质量监控 & 数据治理面板

**为什么？** 随着语料增长，需要指标来管控数据健康。
**验收标准：** 仪表板展示：总条数、缺失字段比例、重复率、未审核条数、最近导入统计。
**要点：**

* 定期运行校验任务，生成警告。

---

## 13. 基础 API 层（服务化）

**为什么？** 便于前端/外部系统调用语料库。
**验收标准：** 提供 REST API：查询条目、按 id 获取、批量导出、模糊搜索、检索关系。
**要点：**

* 为后续 embedding/向量服务留扩展点（e.g. `/api/v1/items?embed=true`）。

---

# 附：MVP（P0）最小可交付清单（直接可上线验收）

把 P0 的 1~5 完成即可交付给内部用户使用：

* 统一 Schema 文档（JSON Schema）
* 导入脚本（接受你现有的 4 个 JSON 并入库）
* 简单后台 UI（列表/详情/编辑/删除/导出）
* 搜索（text/pinyin/type）
* 导出功能
* 基本 README（如何导入、新增字段说明）

---

# 实现建议（技术层面、快速落地提示）

* **后端**：Java(Spring Boot) 或 Node.js（你熟悉 Java 可优先用 Spring Boot），ORM：JPA / MyBatis 或 MongoDB（如果你偏文档型）
* **DB**：关系型（MySQL/Postgres）适合做 audit/关系；文档型（MongoDB）对原始 JSON 更友好；两者都可（混合架构）
* **搜索**：小数据量下直接 DB 全文或 LIKE；中大型推荐 Elasticsearch / Meilisearch。
* **前端**：Vue3 + Vite（你之前提过 Vue），组件：表格（分页）、详情编辑（富文本）、批量导入页。
* **版本/审计**：用 audit 表或把每次修改 snapshot 存到 `history` 表。
* **导入**：先做一个 CLI 工具/后端 API，用批处理 + dry-run 模式。

* any list
{:toc}