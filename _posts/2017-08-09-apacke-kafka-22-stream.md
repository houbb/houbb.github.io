---
layout: post
title:  Apache Kafka-22-kafka stream 流详解
date:  2017-8-9 09:32:36 +0800
categories: [MQ]
tags: [apache, kafka, mq]
published: false
---

# 流

Kafka一般被认为是一个强大的消息总线，可以传递事件流，但没有处理和转换事件的能力。Kafka可靠的传递能力让它成为流式处理系统完美的数据来源。

很多基于Kafka构建的流式处理系统都将Kafka作为唯一可靠的数据来源，如ApacheStorm、ApacheSparkStreaming， Apache Flink， Apache Samza 9.


有时候，行业分析师声称这些流式处理系统与那些已经存在了二十多年的复杂事件处理(CEP)系统没有什么两样。

但是流式处理系统却很成功，而只有寥寥可数的系统在采用CEP，他们为此感到很惊讶。

笔者认为，CEP的主要问题在于缺少事件流的处理能力。

随着Kafka越来越流行，最初作为简单的消息总线，后来成为一种数据集成系统。很多公司的系统里都包含了大量有价值的数据流，它们井然有序地存在了很长时间，好像在等待一个流式处理框架的出现。

换句话说，在出现数据库之前，数据的处理是一项艰巨的任务。类似地，因为缺少能够提供可靠存储和集成的流式平台，流式处理的发展也受到了阻碍。

从0.10.0版本开始，Kafka不仅为每一个流行的流式处理框架提供了可靠的数据来源，还提供了一个强大的流式处理类库，并将其作为客户端类库的一部分。

这样，开发人员就可以在应用程序里读取、处理和生成事件，而不需要再依赖外部的处理框架。

本章将以解释什么是流式处理作为开头(因为这个术语经常被人误解)，然后讨论流式处理的一些基本概念和流式处理系统常用的设计模式，然后深入介绍Kafka的流式处理类库，包括它的目标和架构，接着将会给出一个示例，介绍如何使用KafkaStreams(以下简称Streams)来计算股价移动平均数，最后讨论流式处理的其他使用场景，并在结束部分列出为Kafka选择流式处理框架(如果有的话)的参考标准。

本章主要是简单地介绍流式处理，并不会涵盖Streams的每一个特性，也不会对每一个现有的流式处理框架进行比较，因为光这些内容就可以单独写成一本甚至好几本书了。

## 什么是流式处理

人们对流式处理的理解非常混乱。

因为有太多关于流式处理的定义，它们混淆了实现细节、性能需求、数据模型和软件工程的各个方面。

笔者亲眼目睹了发生在关系型数据库上的类似窘境，关系模型的抽象定义总是夹杂了数据库引擎的实现细节和特定局限性。

流式处理领域还处在发展阶段，有一些流行的实现方案，其处理方式可能很特别，或者有特定的局限，但这并不能说明它们的实现细节就是流式处理固有的组成部分。

先来看看什么是数据流(也被称为"事件流"或"流数据")。首先，数据流是无边界数据集的抽象表示。无边界意味着无限和持续增长。无边界数据集之所以是无限的，是因为随着时间的推移，新的记录会不断加入进来。这个定义已经被包括Google和Amazon在内的大部分公司所采纳。

这个简单的模型(事件流)可以表示很多业务活动，比如信用卡交易、股票交易、包裹递送、流经交换机的网络事件、制造商设备传感器发出的事件、发送出去的邮件、游戏里物体的移动，等等。这个清单是无穷无尽的，因为几乎每一件事情都可以被看成事件的序列。
除了没有边界外，事件流模型还有其他一些属性。

### 事件流是有序的

事件的发生总是有个先后顺序。以金融活动事件为例，先将钱存进账户后再花钱，这与先花钱再还钱的次序是完全不一样的。后者会出现透支，而前者不会。这是事件流与数据库表的不同点之一。数据库表里的记录是无序的，而SQL语法中的orderby并不是关系模型的组成部分，它是为了报表查询而添加的。

### 不可变的数据记录

事件一旦发生，就不能被改变。一个金融交易被取消，并不是说它就消失了，相反，这需要往事件流里添加一个额外的事件，表示前一个交易的取消操作。

顾客的一次退货并不意味着之前的销售记录被删除，相反，退货行为被当成一个额外的事件记录下来。这是数据流与数据表之间的另一个不同点——可以删除和修改数据表里的记录，但这些操作只不过是发生在数据库里的事务，这些事务可以被看成事件流。假设你对数据库的二进制日志(binlog)、预写式日志(WAL)和重做日志(redolog)的概念都很熟悉，那么就会知道，如果往数据库表插入一条记录，然后将其删除，表里就不会再有这条记录。但重做日志里包含了两个事务：插入事务和删除事务。

### 事件流是可重播的

这是事件流非常有价值的一个属性。

用户可以很容易地找出那些不可重播的流(流经套接字的TCP数据包就是不可重播的)，但对于大多数业务来说，重播发生在几个月前(甚至几年前)的原始事件流是一个很重要的需求。

可能是为了尝试使用新的分析方法纠正过去的错误，或是为了进行审计。

这也就是为什么我们相信Kafka能够让现代业务领域的流式处理大获成功——可以借助Kafka来捕捉和重播事件流。

如果没有这项能力，流式处理充其量只是数据科学实验室里的一个玩具而已。

如果事件流的定义里没有提到事件所包含的数据和每秒钟的事件数量，那么它就变得毫无意义。不同系统之间的数据是不一样的，事件可以很小(有时候只有几个字节)，也可以很大(包含很多消息头的XML消息)，它们可以是完全非结构化的键值对，可以是半结构化的JSON，也可以是结构化的Avro或Protobuf。虽然数据流经常被视为"大数据"，并且包含了每秒钟数百万的事件，不过这里所讨论的技术同样适用(通常是更加适用)于小一点的事件流，可能每秒钟甚至每分钟只有几个事件。
知道什么是事件流以后，是时候了解"流式处理"的真正含义了。流式处理是指实时地处理一个或多个事件流。流式处理是一种编程范式，就像请求与响应范式和批处理范式那样。下面将对这3种范式进行比较，以便更好地理解如何在软件架构中应用流式处理。请求与响应

这是延迟最小的一种范式，响应时间处于亚毫秒到毫秒之间，而且响应时间一般非常稳定。这种处理模式一般是阻塞的，应用程序向处理系统发出请求，然后等待响应。在数据库领域，这种范式就是线上交易处理(OLTP)。销售点(POS)系统、信用卡处理系统和基于时间的追踪系统一般都使用这种范式。

### 批处理

这种范式具有高延迟和高吞吐量的特点。处理系统按照设定的时间启动处理进程，比如每天的下午两点开始启动，每小时启动一次等。它读取所有的输人数据(从上一次执行之后的所有可用数据，或者从月初开始的所有数据等)，输出结果，然后等待下一次启动。处理时间从几分钟到几小时不等，并且用户从结果里读到的都是旧数据。

在数据库领域，它们就是数据仓库(DWH)或商业智能(BI)系统。它们每天加载巨大批次的数据，并生成报表，用户在下一次加载数据之前看到的都是相同的报表。

从规模上来说，这种范式既高效又经济。但在近几年，为了能够更及时、高效地作出决策，业务要求在更短的时间内能提供可用的数据，这就给那些为探索规模经济而开发却无法提供低延迟报表的系统带来了巨大的压力。

### 流式处理

这种范式介于上述两者之间。大部分的业务不要求亚毫秒级的响应，不过也接受不了要等到第二天才知道结果。大部分业务流程都是持续进行的，只要业务报告保持更新，业务产品线能够持续响应，那么业务流程就可以进行下去，而无需等待特定的响应，也不要求在几毫秒内得到响应。

一些业务流程具有持续性和非阻塞的特点，比如针对可疑信用卡交易的警告、网络警告、根据供应关系实时调整价格、跟踪包裹。

流的定义不依赖任何一个特定的框架、API或特性。

只要持续地从一个无边界的数据集读取数据，然后对它们进行处理并生成结果，那就是在进行流式处理。

重点是，整个处理过程必须是持续的。一个在每天凌晨两点启动的流程，从流里读取500条记录，生成结果，然后结束，这样的流程不是流式处理。

# 流式处理的一些概念

流式处理的很多方面与普通的数据处理是很相似的：写一些代码来接收数据，对数据进行处理，可能做一些转换、聚合和增强的操作，然后把生成的结果输出到某个地方。

不过流式处理有一些特有的概念，对于那些有数据处理经验但是首次尝试开发流式处理应用程序的人来说，很容易造成混淆。

下面将试着澄清这些概念。

## 时间

时间或许就是流式处理最为重要的概念，也是最让人感到困惑的。

在讨论分布式系统时，该如何理解复杂的时间概念?推荐阅读JustinSheehy的论文"ThereisNoNow"。

在流式处理里，时间是一个非常重要的概念，因为大部分流式应用的操作都是基于时间窗口的。例如，流式应用可能会计算股价的5分钟移动平均数。如果生产者因为网络问题离线了2小时，然后带着2小时的数据重新连线，我们需要知道该如何处理这些数据。这些数据大部分都已经超过了5分钟，而且没有参与之前的计算。

流式处理系统一般包含如下几个时间概念。

### 事件时间

事件时间是指所追踪事件的发生时间和记录的创建时间。

例如，度量的获取时间、商店里商品的出售时间、网站用户访问网页的时间，等等。

在Kafka0.10.0和更高版本里，生产者会自动在记录中添加记录的创建时间。如果这个时间戳与应用程序对"事件时间"的定义不一样，

例如，Kafka的记录是基于事件发生后的数据库记录创建的，那就需要自己设置这个时间戳字段。在处理数据流时，事件时间是很重要的。

### 日志追加时间

日志追加时间是指事件保存到broker的时间。

在Kafka0.10.0和更高版本里，如果启用了自动添加时间戳的功能，或者记录是使用旧版本的生产者客户端生成的，而且没有包含时间戳，那么broker会在接收这些记录时自动添加时间戳。

这个时间戳一般与流式处理没有太大关系，因为用户一般只对事件的发生时间感兴趣。

例如，如果要计算每天生产了多少台设备，就需要计算在那一天实际生产的设备数量，尽管这些事件有可能因为网络问题到了第二天才进入Kafka。

不过，如果真实的事件时间没有被记录下来，那么就可以使用日志追加时间，在记录创建之后，这个时间就不会发生改变。

### 处理时间

处理时间是指应用程序在收到事件之后要对其进行处理的时间。

这个时间可以是在事件发生之后的几毫秒、几小时或几天。同一个事件可能会被分配不同的时间戳，这取决于应用程序何时读取这个事件。

如果应用程序使用了两个线程来读取同一个事件，这个时间戳也会不一样!所以这个时间戳非常不可靠，应该避免使用它。

### 注意时区问题

在处理与时间有关的问题时，需要注意时区问题。

整个数据管道应该使用同一个时区，否则操作的结果就会出现混淆，变得毫无意义。

如果时区问题不可避免，那么在处理事件之前需要将它们转换到同一个时区，这就要求记录里同时包含时区信息。

## 状态

如果只是单独处理每一个事件，那么流式处理就很简单。

例如，如果想从Kafka读取在线购物交易事件流，找出金额超过10000美元的交易，并将结果通过邮件发送给销售人员，那么可以使用Kafka消费者客户端和SMTP库，几行代码就可以搞定。

如果操作里包含了多个事件，流式处理就会变得很有意思，比如根据类型计算事件的数量、移动平均数、合并两个流以便生成更丰富的信息流。

在这些情况下，光处理单个事件是不够的，用户需要跟踪更多的信息，比如这个小时内看到的每种类型事件的个数、需要合并的事件、将每种类型的事件值相加，等等。

**事件与事件之间的信息被称为"状态"**。这些状态一般被保存在应用程序的本地变量里。

例如，使用散列表来保存移动计数器。事实上，本书的很多例子就是这么做的。不过，这不是一种可靠的方法，因为如果应用程序关闭，状态就会丢失，结果就会发生变化，而这并不是用户希望看到的。所以，要小心地持久化最近的状态，如果应用程序重启，要将其恢复。

流式处理包含以下几种类型的状态。

### 本地状态或内部状态

这种状态只能被单个应用程序实例访问，它们一般使用内嵌在应用程序里的数据库进行维护和管理。本地状态的优势在于它的速度，不足之处在于它受到内存大小的限制。所以，流式处理的很多设计模式都将数据拆分到多个子流，这样就可以使用有限的本地状态来处理它们。

### 外部状态

这种状态使用外部的数据存储来维护，一般使用NoSQL系统，比如Cassandra。
    
使用外部存储的优势在于，它没有大小的限制，而且可以被应用程序的多个实例访问，甚至被不同的应用程序访问。

不足之处在于，引入额外的系统会造成更大的延迟和复杂性。

大部分流式处理应用尽量避免使用外部存储，或者将信息缓存在本地，减少与外部存储发生交互，以此来降低延迟，而这就引人了如何维护内部和外部状态一致性的问题。

## 流和表的二元性

大家都熟悉数据库表，表就是记录的集合，每个表都有一个主键，并包含了一系列由schema定义的属性。

表的记录是可变的(可以在表上面执行更新和删除操作)。我们可以通过查询表数据获知某一时刻的数据状态。

例如，通过查询CUSTOMERS_CONTACTS这个表，就可以获取所有客户的联系信息。如果表被设计成不包含历史信息，那么就找不到客户过去的联系信息了。

在将表与流进行对比时，可以这么想：流包含了变更——流是一系列事件，每个事件就是一个变更。表包含了当前的状态，是多个变更所产生的结果。

所以说，表和流是同一个硬币的两面——世界总是在发生变化，用户有时候关注变更事件，有时候则关注世界的当前状态。如果一个系统允许使用这两种方式来查看数据，那么它就比只支持一种方式的系统强大。

为了将表转化成流，需要捕捉到在表上所发生的变更，将"insert"、"update"和"delete"事件保存到流里。

大部分数据库提供了用于捕捉变更的“ChangeDataCapture”(CDC)解决方案，

Kafka连接器将这些变更发送到Kafka，用于后续的流式处理。

**为了将流转化成表，需要“应用”流里所包含的所有变更，这也叫作流的“物化”。**

首先在内存里、内部状态存储或外部数据库里创建一个表，然后从头到尾遍历流里的所有事件，逐个地改变状态。

在完成这个过程之后，得到了一个表，它代表了某个时间点的状态。

假设有一个鞋店，某零售活动可以使用一个事件流来表示：

“红色、蓝色和绿色鞋子到货”
“蓝色鞋子卖出”
“红色鞋子卖出”
“蓝色鞋子退货”
“绿色鞋子卖出”

如果想知道现在仓库里还有哪些库存，或者到目前为止赚了多少钱，需要对视图进行物化。图11-1告诉我们，目前还有蓝色和黄色鞋子，账户上有170美元。如果想知道鞋店的繁忙程度，可以查看整个事件流，会发现总共发生了5个交易，还可以查出为什么蓝色鞋子被退货。

- 图11-1：物化仓库变更事件流

![物化仓库变更事件流](https://images.gitee.com/uploads/images/2020/0823/200129_f39f512b_508704.png)

## 时间窗口

大部分针对流的操作都是基于时间窗口的，比如移动平均数、一周内销量最好的产品、系统的99百分位等。

两个流的合并操作也是基于时间窗口的，我们会合并发生在相同时间片段上的事件。

不过，很少人会停下来仔细想想时间窗口的类型。

例如，在计算移动平均数时，需要知道以下几个问题。

- 窗口的大小。

是基于5分钟进行平均，还是15分钟，或者一天?窗口越小，就能越快地发现变更，不过噪声也越多。窗口越大，变更就越平滑，不过延迟也越严重，如果价格涨了，需要更长的时间才能看出来。

- 窗口移动的频率(“移动间隔”)。

5分钟的平均数可以每分钟变化一次，或者每秒钟变化一次，或者每当有新事件到达时发生变化。如果“移动间隔”与窗口大小相等，这种情况被称为“滚动窗口(tumblingwindow)”。如果窗口随着每一条记录移动，这种情况被称为“滑动窗口(slidingwindow)”。

- 窗口的可更新时间多长。

假设计算了00：00到00：05之间的移动平均数，一个小时之后又得到了一些“事件时间”是00：02的事件，那么需要更新00：00到00：05这个窗口的结果吗?或者就这么算了?

理想情况下，可以定义一个时间段，在这个时间段内，事件可以被添加到与它们相应的时间片段里。如果事件处于4个小时以内，那么就更新它们，否则就忽略它们。

窗口可以与时间对齐，比如5分钟的窗口如果每分钟移动一次，那么第一个分片可以是00：00-00：05，第二个就是00：01~00：06。它也可以不与时间对齐，应用可以在任何时候启动，那么第一个分片有可能是03：17-03：22。滑动窗口永远不会与时间对齐，因为只要有新记录到达，它们就会发生移动。图11-2展示了这两种时间窗口的不同之处。

- 图11-2：滚动窗口和跳跃窗口的区别

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/200336_15a81eb2_508704.png)

# 流式处理的设计模式

每一个流式处理系统都不一样，从基本的消费者、处理逻辑和生产者的组合，到使用了Spark Streaming和机器学习软件包的复杂集群，以及其他很多处于中间位置的组件。

不过有一些基本的设计模式和解决方案可以满足流式处理架构的常见需求。

下面将介绍一些这样的模式，并举例说明如何使用这种模式。

## 单个事件处理

处理单个事件是流式处理最基本的模式。

这个模式也叫map或filter模式，因为它经常被用于过滤无用的事件或者用于转换事件(map这个术语是从Map-Reduce模式中来的，map阶段转换事件，reduce阶段聚合转换过的事件)。

在这种模式下，应用程序读取流中的事件，修改它们，然后把事件生成到另一个流上。

比如，一个应用程序从一个流中读取日志消息，并把ERROR级别的消息写到高优先级的流中，同时把其他消息写到低优先级的流中。

再如，一个应用程序从流中读取事件，并把事件从JSON格式改为Avro格式。这类应用程序不需要在程序内部维护状态，因为每一个事件都是独立处理的。

这也意味着，从错误中恢复或进行负载均衡会非常容易，因为不需要进行恢复状态的操作，只需要将事件交给应用程序的另一个实例去处理。

这种模式可以使用一个生产者和一个消费者来实现，如图11-3所示。

- 图11-3：单事件处理拓扑

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/200506_af04951d_508704.png)

## 使用本地状态

大部分流式处理应用程序关心的是如何聚合信息，特别是基于时间窗口进行聚合。

例如，找出每天最低和最高的股票交易价格并计算移动平均数。

要实现这些聚合操作，需要维护流的状态。

在本例中，为了计算每天的最小价格和平均价格，需要将最小值和最大值保存下来，并将它们与每一个新值进行对比。

这些操作可以通过本地状态(而不是共享状态)来实现，因为本例中的每一个操作都是基于组的聚合操作，如图11-4所示。

例如，基于各个股票代码进行聚合，而不是基于整个股票市场。

我们使用了一个Kafka分区器来确保具有相同股票代码的事件总是被写入相同的分区。

应用程序的每个实例从分配给它们的分区上获取事件(这是Kafka的消费者保证)。

也就是说，应用程序的每一个实例都可以维护一个股票代码子集的状态。

- 图11-4：使用本地状态的事件拓扑

![使用本地状态的事件拓扑](https://images.gitee.com/uploads/images/2020/0823/200554_3e2874be_508704.png)

如果流式处理应用程序包含了本地状态，情况就会变得非常复杂，而且还需要解决下列的一些问题。

### 内存使用

应用实例必须有可用的内存来保存本地状态。

### 持久化

要确保在应用程序关闭时不会丢失状态，并且在应用程序重启后或者切换到另一个应用实例时可以恢复状态。

Streams可以很好地处理这些问题，它使用内嵌的RocksDB将本地状态保存在内存里，同时持久化到磁盘上，以便在重启后可以恢复。

本地状态的变更也会被发送到Kafka主题上。如果Streams节点崩溃，本地状态并不会丢失，可以通过重新读取Kafka主题上的事件来重建本地状态。

例如，如果本地状态包含“IBM当前最小价格是167.19”，并且已经保存到了Kafka上，那么稍后就可以通过读取这些数据来重建本地缓存。这些Kafka主题使用了压缩日志，以确保它们不会无限量地增长，方便重建状态。

### 再均衡

有时候，分区会被重新分配给不同的消费者。

在这种情况下，失去分区的实例必须把最后的状态保存起来，同时获得分区的实例必须知道如何恢复到正确的状态。

不同的流式处理框架为开发者提供了不同的本地状态支持。如果应用程序需要维护本地状态，那么就要知道框架是否提供了支持。

本章的末尾将会对一些框架进行简要的对比，不过软件发展变化太快，而流式处理框架更是如此。

## 多阶段处理和重分区

本地状态对按组聚合操作起到很大的作用。

但如果需要使用所有可用的信息来获得一个结果呢?

例如，假设要发布每天的“前10支”股票，这10支股票需要从每天的交易股票中挑选出来。很显然，如果只是在每个应用实例上进行处理是不够的，因为10支股票分布在多个实例上，如图11-5所示。

我们需要一个两阶段解决方案。

首先，计算每支股票当天的涨跌，这个可以在每个实例上进行。然后将结果写到一个包含了单个分区的新主题上。另一个单独的应用实例读取这个分区，找出当天的前10支股票。新主题只包含了每支股票的概要信息，比其他包含交易信息的主题要小很多，所以流量很小，使用单个应用实例就足以应付。不过，有时候需要更多的步骤才能生成结果。

- 图11-5：包含本地状态和重分区步骤的拓扑

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/200747_7c06eba7_508704.png)

这种多阶段处理对于写过Map-Reduce代码的人来说应该很熟悉，因为他们经常要使用多个reduce步骤。

如果写过Map-Reduce代码，就应该知道，处理每个reduce步骤的应用需要被隔离开来。与Map-Reduce不同的是，大多数流式处理框架可以将多个步骤放在同一个应用里，框架会负责调配每一步需要运行哪一个应用实例(或worker)。

## 使用外部查找——流和表的连接

有时候，流式处理需要将外部数据和流集成在一起，比如使用保存在外部数据库里的规则来验证事务，或者将用户信息填充到点击事件当中。

很明显，为了使用外部查找来实现数据填充，可以这样做：对于事件流里的每一个点击事件，从用户信息表里查找相关的用户信息，从中抽取用户的年龄和性别信息，把它们包含在点击事件里，然后将事件发布到另一个主题上，如图11-6所示。

- 图11-6：使用外部数据源的流式处理

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/201026_1324ccfd_508704.png)

这种方式最大的问题在于，外部查找会带来严重的延迟，一般在5~15ms之间。这在很多情况下是不可行的。

另外，外部数据存储也无法接受这种额外的负载——流式处理系统每秒钟可以处理10~50万个事件，而数据库正常情况下每秒钟只能处理1万个事件，所以需要伸缩性更强的解决方案。

为了获得更好的性能和更强的伸缩性，需要将数据库的信息缓存到流式处理应用程序里。

不过，要管理好这个缓存也是一个挑战。

比如，如何保证缓存里的数据是最新的?如果刷新太频繁，那么仍然会对数据库造成压力，缓存也就失去了作用。如果刷新不及时，那么流式处理中所用的数据就会过时。

如果能够捕捉数据库的变更事件，并形成事件流，流式处理作业就可以监听事件流，并及时更新缓存。

捕捉数据库的变更事件并形成事件流，这个过程被称为CDC——变更数据捕捉(ChangeDataCapture)。

如果使用了Connect，就会发现，有一些连接器可以用于执行CDC任务，把数据库表转成变更事件流。这样就拥有了数据库表的私有副本，一旦数据库发生变更，用户会收到通知，并根据变更事件更新私有副本里的数据，如图11-7所示。

- 图11-7：连接流和表的拓扑，不需要外部数据源

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/201124_3de946b4_508704.png)

这样一来，当收到点击事件时，可以从本地的缓存里查找user_id，并将其填充到点击事件里。

因为使用的是本地缓存，它具有更强的伸缩性，而且不会影响数据库和其他使用数据库的应用程序。

之所以将这种方案叫作流和表的连接，是因为其中的一个流代表了本地缓存表的变更。

## 流与流的连接

有时候需要连接两个真实的事件流。

什么是“真实”的流?本章开始的时候曾经说过，流是无边界的。如果使用一个流来表示一个表，那么就可以忽略流的大部分历史事件，因为你只关心表的当前状态。

不过，如果要连接两个流，那么就是在连接所有的历史事件一将两个流里具有相同键和发生在相同时间窗口内的事件匹配起来。这就是为什么流和流的连接也叫作基于时间窗口的连接(windowed-join)。

假设有一个由网站用户输入的搜索事件流和一个由用户对搜索结果进行点击的事件流。对用户的搜索和用户对搜索结果的点击进行匹配，就可以知道哪一个搜索的热度更高。

很显然，我们需要基于搜索关键词进行匹配，而且每个关键词只能与一定时间窗口内的事件进行匹配—假设用户在输人搜索关键词后几秒钟就会点击搜索结果。

因此，我们为每一个流维护了以几秒钟为单位的时间窗口，并对这些时间窗口事件结果进行匹配，如图11-8所示。

- 图11-8：连接两个流，通常包含一个移动时间窗

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/201305_9ed3956d_508704.png)

在Streams中，上述的两个流都是通过相同的键来进行分区的，这个键也是用于连接两个流的键。

这样一来，user_id：42的点击事件就被保存在点击主题的分区5上，而所有user_id：42的搜索事件被保存在搜索主题的分区5上。Streams可以确保这两个主题的分区5的事件被分配给同一个任务，这个任务就会得到所有与user_id：42相关的事件。

Streams在内嵌的RocksDB里维护了两个主题的连接时间窗口，所以能够执行连接操作。

## 乱序的事件

不管是对于流式处理还是传统的ETL系统来说，处理乱序事件都是一个挑战。

物联网领域经常发生乱序事件：一个移动设备断开WiFi连接几个小时，在重新连上WiFi之后将几个小时累积的事件一起发送出去，如图11-9所示。

这在监控网络设备(故障交换机被修复之前不会发送任何诊断数据)或进行生产(装置间的网络连接非常不可靠)时也时有发生。

- 图11-9：乱序事件

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/201347_026068c2_508704.png)

要让流处理应用程序处理好这些场景，需要做到以下几点。

（1）识别乱序的事件。应用程序需要检查事件的时间，并将其与当前时间进行比较。

（2）规定一个时间段用于重排乱序的事件。比如3个小时以内的事件可以重排，但3周以外的事件就可以直接扔掉。

（3）具有在一定时间段内重排乱序事件的能力。这是流式处理应用与批处理作业的一个主要不同点。假设有一个每天运行的作业，一些事件在作业结束之后才到达，那么可以重新运行昨天的作业来更新事件。而在流式处理中，“重新运行昨天的作业”这种情况是不存在的，乱序事件和新到达的事件必须一起处理。

（4）具备更新结果的能力。如果处理的结果保存到数据库里，那么可以通过put或update对结果进行更新。如果流应用程序通过邮件发送结果，那么要对结果进行更新，就需要很巧妙的手段。

有一些流式处理框架，比如Google的Dataflow和Kafka的Streams，都支持独立于处理时间发生的事件，并且能够处理比当前处理时间更晚或更早的事件。它们在本地状态里维护了多个聚合时间窗口，用于更新事件，并为开发者提供配置时间窗口大小的能力。当然，时间窗口越大，维护本地状态需要的内存也越大。

StreamsAPI通常将聚合结果写到主题上。这些主题一般是压缩日志主题，也就是说，它们只保留每个键的最新值。如果一个聚合时间窗口的结果需要被更新为晚到事件的结果，Streams会直接为这个聚合时间窗口写人一个新的结果，将前一个结果覆盖掉。

## 重新处理

最后一个很重要的模式是重新处理事件，该模式有两个变种。

1. 我们对流式处理应用进行了改进，使用新版本应用处理同一个事件流，生成新的结果，并比较两种版本的结果，然后在某个时间点将客户端切换到新的结果流上。

2. 现有的流式处理应用出现了缺陷，修复缺陷之后，重新处理事件流并重新计算结果。对于第一种情况，Kafka将事件流长时间地保存在可伸缩的数据存储里。也就是说，要使用两个版本的流式处理应用来生成结果，只需要满足如下条件：
将新版本的应用作为一个新的消费者群组；

让它从输入主题的第一个偏移量开始读取数据(这样它就拥有了属于自己的输人流事件副本；

检查结果流，在新版本的处理作业赶上进度时，将客户端应用程序切换到新的结果流上。

第二种情况有一定的挑战性。它要求“重置”应用，让应用回到输入流的起始位置开始处理，同时重置本地状态(这样就不会将两个版本应用的处理结果混淆起来了)，而且还可

能需要清理之前的输出流。虽然Streams提供了一个工具用于重置应用的状态，不过如果有条件运行两个应用程序并生成两个结果流，还是建议使用第一种方案。第一种方案更加安全，多个版本可以来回切换，可以比较不同版本的结果，而且不会造成数据的丢失，也不会在清理过程中引人错误。

# Streams示例
为了演示如何在实际中实现这些模式，下面将给出一些使用StreamsAPI的例子。之所以使用这个API，是因为它相对简单，而且它是与Kafka一起发布的，用户可以直接使用它。不过要记住一点，我们可以使用任意的流式处理框架和软件包来实现这些模式，这些模式具有通用性。

Kafka有两个基于流的API，一个是底层的ProcessorAPI，一个是高级的StreamsDSL。下面的例子中将使用StreamsDSL。通过为事件流定义转换链可以实现流式处理。转换可以是简单的过滤器，也可以是复杂的流与流的连接。我们可以通过底层的API实现自己的转换，不过没必要这么做。

在使用DSLAPI时，一般会先用StreamBuilder创建一个拓扑(topology)。拓扑是一个有向图(DAG)，包含了各个转换过程，将会被应用在流的事件上。在创建好拓扑后，使用拓扑创建一个KafkaStreans执行对象。多个线程会随着KafkaStreans对象启动，将拓扑应用到流的事件上。在关闭KafkaStreans对象时，处理也随之结束。

下面将展示一些使用Streams来实现上述模式的例子。字数统计这个例子用于演示map与fiter模式以及简单的聚合，另一个例子是计算股票交易市场的各种统计信息，用于演示基于时间窗口的聚合，最后使用填充点击事件流(ClickStreamEnrichment)的例子来演示流的连接。

## 字数统计

先看一个使用了Streams的字数统计示例。

完整的示例代码可以在GitHub(https://github.com/gwenshap/kafka-streams-wordcount) 查看.

要创建一个流式处理应用，首先需要配置KafkaStreams引擎。KafkaStreams有很多配置参数，这里就不展开讨论了，感兴趣的读者可以在官方文档里查看。

另外，也可以将生产者和消费者内嵌到KafkaStreams引擎里，只要把生产者或消费者的配置信息添加到Properties对象里即可。

```java
import org.apache.kafka.clients.CommonClientConfigs;
import org.apache.kafka.clients.consumer.ConsumerConfig;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.streams.KafkaStreams;
import org.apache.kafka.streams.KeyValue;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.kstream.KStream;
import org.apache.kafka.streams.kstream.KStreamBuilder;

import java.util.Arrays;
import java.util.Properties;
import java.util.regex.Pattern;

public class WordCountExample {

    public static void main(String[] args) throws Exception{

        //1. 配置信息设置
        Properties props = new Properties();
        props.put(StreamsConfig.APPLICATION_ID_CONFIG, "wordcount");
        props.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092");
        props.put(StreamsConfig.KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());
        props.put(StreamsConfig.VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass().getName());

        // setting offset reset to earliest so that we can re-run the demo code with the same pre-loaded data
        // Note: To re-run the demo, you need to use the offset reset tool:
        // https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Streams+Application+Reset+Tool
        props.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");

        // work-around for an issue around timing of creating internal topics
        // Fixed in Kafka 0.10.2.0
        // don't use in large production apps - this increases network load
        // props.put(CommonClientConfigs.METADATA_MAX_AGE_CONFIG, 500);

        //2. 创建拓扑
        KStreamBuilder builder = new KStreamBuilder();
        KStream<String, String> source = builder.stream("wordcount-input");

        final Pattern pattern = Pattern.compile("\\W+");
        KStream counts  = source.flatMapValues(value-> Arrays.asList(pattern.split(value.toLowerCase())))
                .map((key, value) -> new KeyValue<Object, Object>(value, value))
                .filter((key, value) -> (!value.equals("the")))
                .groupByKey()
                .count("CountStore").mapValues(value->Long.toString(value)).toStream();
        counts.to("wordcount-output");

        //3. 执行程序
        KafkaStreams streams = new KafkaStreams(builder, props);
        // This is for reset to work. Don't use in production - it causes the app to re-load the state from Kafka on every start
        streams.cleanUp();
        streams.start();

        // usually the stream application would be running forever,
        // in this example we just let it run for some time and stop since the input data is finite.
        Thread.sleep(5000L);

        streams.close();

    }
}
```

就是这么简单!本例只用了几行代码，就演示了如何实现单事件处理模式(在事件上使用了map与ilter)，然后通过groupby操作对数据进行重新分区，并为统计记录个数维护了一个简单的本地状态。

建议运行完整的示例，GtHub库的README文件包含了如何运行示例的说明。

也许你会注意到，除了Kafka外，不需要在机器上安装任何软件，就可以运行完整的示例。

这类似于在“本地模式”下使用Spark。主要的不同之处在于，如果主题包含了多个分区，就可以运行多个字数统计应用实例(在不同的命令行终端运行)，而这也就是第一个Streams集群。

几个字数统计应用实例之间互相交互，协调处理任务。

Spark的本地模式非常简单，但要在生产环境运行集群，需要安装YARN或者Mesos，并在所有的机器上安装Spark，然后将你的应用提交到集群上，所以Spark有较高的准入门槛。

而如果使用StreamsAPI，只需要启动几个应用实例就可以拥有一个集群。

在开发机上运行和在生产环境中运行几乎是一样的。


# KafkaStreams的架构概览

上节的例子演示了如何使用StreamsAPI实现流式处理的设计模式。

为了更好地理解Streams的工作原理和它的伸缩性，下面深人了解API背后的设计原则。

## 构建拓扑

每个流式应用程序至少会实现和执行一个拓扑。

**拓扑(在其他流式处理框架里叫作DAG，即有向无环图)是一个操作和变换的集合，每个事件从输人到输出都会流经它。**

在之前的字数统计示例里，拓扑结构如图11-10所示。

- 图 11-10：字数统计示例的拓扑结构

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/202226_a0bc48e9_508704.png)

哪怕是一个很简单的应用，都需要一个拓扑。

拓扑是由处理器组成的，这些处理器是拓扑图里的节点(用椭圆表示)。大部分处理器都实现了一个数据操作——过滤、映射、聚合等。

数据源处理器从主题上读取数据，并传给其他组件，而数据池处理器从上一个处理器接收数据，并将它们生成到主题上。拓扑总是从一个或多个数据源处理器开始，并以一个或多个数据池处理器结束。

## 对拓扑进行伸缩

Streams通过在单个实例里运行多个线程和在分布式应用实例间进行负载均衡来实现伸缩。

用户可以在一台机器上运行Streams应用，并开启多个线程，也可以在多台机器上运行Streams应用。不管采用何种方式，所有的活动线程将会均衡地处理工作负载。

Streams引擎将拓扑拆分成多个子任务来并行执行。

拆分成多少个任务取决于Streams引擎，同时也取决于主题的分区数量。

每个任务负责一些分区：任务会订阅这些分区，并从分区读取事件数据，在将结果写到数据池之前，在每个事件上执行所有的处理步骤。

这些任务是Streams引擎最基本的并行单元，因为每个任务可以彼此独立地执行，如图11-11所示。

- 图 11-11：运行相同拓扑的两个任务每个读取主题的一个分区

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/202326_9ba50dec_508704.png)

开发人员可以选择每个应用程序使用的线程数。如果使用了多个线程，每个线程将会执行一部分任务。

如果有多个应用实例运行在多个服务器上，每个服务器上的每一个线程都会执行不同的任务。

这就是流式应用的伸缩方式：主题里有多少分区，就会有多少任务。如果想要处理得更快，就添加更多的线程。

如果一台服务器的资源被用光了，就在另一台服务器上启动应用实例。

Kafka会自动地协调工作，它为每个任务分配属于它们的分区，每个任务独自处理自己的分区，并维护与聚合相关的本地状态，如图11-12所示。

- 图11-12：处理任务可以运行在多个线程和多个服务器上

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/202455_15570d40_508704.png)

大家或许已经注意到，有时候一个步骤需要处理来自多个分区的结果，这样就会在任务之间形成依赖。

例如，在点击事件流的例子里对两个流进行了连接，在生成结果之前，需要从每一个流的分区里获取数据。

Streams将连接操作所涉及的分区全部分配给相同的任务，这样，这个任务就可以从相关的分区读取数据，并独立执行连接操作。这也就是为什么Streams要求同一个连接操作所涉及的主题必须要有相同数目的分区，而且要基于连接所使用的键进行分区。

如果应用程序需要进行重新分区，也会在任务之间形成依赖。例如，在点击事件流的例子里，所有的事件使用用户ID作为键。

如果想要基于页面或者邮政编码生成统计信息该怎么办?此时就需要使用邮政编码对数据进行重新分区，并在新分区上运行聚合操作。

如果任务1处理来自分区1的数据，这些数据到达另一个处理器，这个处理器对数据进行重新分区(groupBy操作)，它需要对数据进行shuffle，也就是把数据发送给其他任务进行处理。

与其他流式处理框架不一样的是，Streams通过使用新的键和分区将事件写到新的主题来实现重新分区，并启动新的任务从新主题上读取和处理事件。

重新分区的步骤是将拓扑拆分成两个子拓扑，每个子拓扑都有自己的任务集，如图11-13所示。

第二个任务集依赖第一个任务集，因为它们处理的是第一个子拓扑的结果。不过，它们仍然可以独立地并行执行，因为第一个任务集以自己的速率将数据写到一个主题上，而第二个任务集也以自己的速率从这个主题读取和处理事件。两个任务集之间不需要通信，也没有共享资源，而且它们也不需要运行在相同的线程里或相同的服务器上。这是Kafka提供的最有用的特性之一——减少管道各个部分之间的依赖。

- 图11-13：处理主题分区事件的两组任务

![输入图片说明](https://images.gitee.com/uploads/images/2020/0823/202648_50f4fcf4_508704.png)

## 从故障中存活下来

Streams的伸缩模型不仅允许伸缩应用，还能优雅地处理故障。

首先，包括本地状态在内的所有数据被保存到有高可用性的Kafka上。如果应用程序出现故障需要重启，可以从Kafka上找到上一次处理的数据在流中的位置，并从这个位置开始继续处理。如果本地状态丢失(比如可能需要将服务器替换掉)，应用程序可以从保存在Kafka上的变更日志重新创建本地状态。

Streams还利用了消费者的协调机制来实现任务的高可用性。如果一个任务失败，只要还有其他线程或者应用程序实例可用，就可以使用另一个线程来重启该任务。这类似于消费者群组的故障处理，如果一个消费者失效，就把分区分配给其他活跃的消费者。

# 流式处理使用场景

前面已经讲解了如何进行流式处理——从一般性的概念和模式说起，并列举了一些Streams的例子。

现在是时候让大家知道流式处理都有哪些常见的使用场景了。

本章的开头解释过，如果想快速处理事件，而不是为每个批次等上几个小时，但又不是真的要求毫秒级的响应，那么流式处理(或者说持续处理)就可以派上用场了。

话是没错，不过听起来仍然十分抽象。

下面来看一些例子，它们都使用流式处理来解决实际的问题。

## 客户服务

假设你向一个大型的连锁酒店预订了一个房间，并希望收到邮件确认和票据。在预订了几分钟之后，仍然没有收到确认邮件，于是打电话向客服确认。

客服的回复是：“我在我们的系统里看不到订单，不过从预订系统加载数据的批次作业每天只运行一次，所以请明天再打电话过来。

你应该可以在2~3个工作日之后收到确认邮件。”这样的服务有点糟糕，不过有人已经不止一次地在一家大型连锁酒店遭遇过类似的问题。

我们真正需要的是，连锁酒店的每一个系统在预订结束之后的几秒钟或者几分钟之内都能发出通知，包括客服中心、酒店、发送确认邮件的系统、网站等。

有的用户可能还希望客服中心能够立即获知自己在这家连锁酒店的历史入住数据，前台能够知道他是一个忠实的客户，从而提供更高级别的服务。

如果使用流式处理应用来构建这些系统，就可以实现几近实时的接收和处理这些事件，从而带来更好的用户体验。如果有这样的系统，就可以在几分钟之内收到邮件确认，信用卡就可以及时扣款，然后发送票据，服务台就可以马上回答有关预订房间的问题了。

## 物联网

物联网包含很多东西，从用于调节温度和自动添加洗衣剂的家居设备，到制药行业的实时质量监控设备。流式处理在传感器和设备上应用，最为常见的是用于预测何时该进行设备维护。

这个与应用监控有点相似，不过这次是应用在硬件上，而且应用在很多不同的行业——制造业、通信(识别故障基站)、有线电视(在用户投诉之前识别出故障机顶盒)等。

每一种场景都有自己的特点，不过目标是一样的——处理大量来自设备的事件，并识别出一些模式，这些模式预示着某些设备需要进行维护，比如交换机数据包的下降、生产过程中需要更大的力气来拧紧螺丝，或者用户频繁重启有线电视的机顶盒。

欺诈检测。欺诈检测也被叫作异常检查，是一个非常广泛的领域，专注于捕捉系统中的“作弊者”或不良分子，比如信用卡欺诈、股票交易欺诈、视频游戏作弊或者网络安全风险。在这些欺诈行为造成大规模的破坏之前，越早将它们识别出来越好。一个几近实时的系统可以快速地对事件作出响应，停止一个还没有通过审核的交易要比等待批次作业在3天之后才发现它是一个欺诈交易要更容易处理。这也是一个在大规模事件流里识别模式的问题。

在网络安全领域，有一个被称为发信标(beaconing)的欺诈手法，黑客在组织内部放置恶意软件，该软件时不时地连接到外部网络接收命令。

一般来说，网络可以抵挡来自外部的攻击，但难以阻止内部到外部的突围。通过处理大量的网络连接事件流，识别出不正常的通信模式，检测出该主机不经常访问的某些IP地址，在蒙受更大的损失之前向安全组织发出告警。

# 如何选择流式处理框架

在比较两个流式处理系统时，要着重考虑使用场景是什么。以下是一些需要考虑的应用类别。

## 摄取

摄取的目的是将数据从一个系统移动到另一个系统，并在传输过程中对数据进行一些修改，使其更适用于目标系统。

## 低延迟

任何要求立即得到响应的应用。有些欺诈检测场景就属于这一类。

## 异步微服务

这些微服务为大型的业务流程执行一些简单操作，比如更新仓储信息。这些应用需要通过维护本地状态缓存来提升性能。

## 几近实时的数据分析

这些流式媒体应用程序执行复杂的聚合和连接，以便对数据进行切分，并生成有趣的业务见解。

选择何种流式处理系统取决于要解决什么问题。

如果要解决摄取问题，那么需要考虑一下是需要一个流式处理系统还是一个更简单的专注于摄取的系统，比如KafkaConnect。如果确定需要一个流式处理系统，那就要确保它拥有可用的连接器，并且要保证目标系统也有高质量的连接器可用。

如果要解决的问题要求毫秒级的延迟，那么就要考虑一下是否一定要用流。一般来说，请求与响应模式更加适用于这种任务。如果确定需要一个流式处理系统，那就需要选择一个支持低延迟的模型，而不是基于微批次的模型。

如果要构建异步微服务，那么需要一个可以很好地与消息总线(希望是Kafka)集成的流式处理系统。它应该具备变更捕捉能力，这样就可以将上游的变更传递到微服务本地的缓存里，而且它要支持本地存储，可以作为微服务数据的缓存和物化视图。

如果要构建复杂的数据分析引擎，那么也需要一个支持本地存储的流式处理系统，不过这次不是为了本地缓存和物化视图，而是为了支持高级的聚合、时间窗口和连接，因为如果没有本地存储，就很难实现这些特性。API需要支持自定义聚合、基于时间窗口的操作和多类型连接。

## 全局考虑

除了使用场景外，还有如下一些全局的考虑点。

### 系统的可操作性

它是否容易部署?是否容易监控和调试?是否易于伸缩?它是否能够很好地与已有的基础设施集成起来?如果出现错误，需要重新处理数据，这个时候该怎么办?

### API的可用性和调试的简单性

为了开发出高质量的应用，同一种框架的不同版本可能需要耗费不同的时间，这类情况很常见。开发时间和上市时机太重要了，所以我们需要选择一个高效率的系统。

### 让复杂的事情简单化

几乎每一个系统都声称它们支持基于时间窗口的高级聚合操作和本地缓存，但问题是，它们够简单吗?它们是处理了规模伸缩和故障恢复方面的细节问题，还是只提供了脆弱的抽象，然后让你来处理剩下的事情?系统提供的API越简洁，封装的细节越多，开发人员的效率就越高。

### 社区

大部分流式处理框架都是开源的。对于开源软件来说，一个充满生气的社区是不可替代的。好的社区意味着用户可以定期获得新的功能特性，而且质量相对较高(没有人会使用糟糕的软件)，缺陷可以很快地得到修复，而且用户的问题可以及时得到解答。

这也意味着，如果遇到一个奇怪的问题并在Google上搜索，可以搜索到相关的信息，因为其他人也在使用这个系统，而且也遇到了相同的问题。

# 总结

本章的开头解释了流式处理，给出了流式处理范式的规范定义，介绍了它的一些常见属性，并将它与其他编程范式进行了比较。

然后列举了3个基于KafkaStreams开发的应用程序，以此来解释一些非常重要的流式处理概念。

在详述了这些示例之后，我们给出了KafkaStreams的架构概览，并解释了它的内部原理。

最后提供了一些流式处理的使用场景，给出了一些用于比较流式处理框架的建议，并以此结束本书。

# 参考资料

《kafka 权威指南》

* amy list
{:toc}

 

