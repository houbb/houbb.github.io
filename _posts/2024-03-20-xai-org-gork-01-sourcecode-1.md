---
layout: post
title: é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹å¯¹æ ‡ openai chatGPT æºç ç¡¬æ ¸ç¯‡ï¼ˆ1ï¼‰
date: 2024-03-20 21:01:55 +0800
categories: [AI]
tags: [ai, sh]
published: true
---

# æ‹“å±•é˜…è¯»

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 åº•å±‚ Transformer æ¨¡å‹è®ºæ–‡ ã€ŠAttention is All You Needã€‹](https://mp.weixin.qq.com/s/bZP2R97GUD1NxV22Tn7eOQ)

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹åº•å±‚ Transformer æ¨¡å‹åˆ°åº•æ˜¯ä¸ªå•¥ï¼Ÿ](https://mp.weixin.qq.com/s/jvpovKSitioC7IQ8IWTumg)

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹ç¡¬æ ¸æºç ç¬¬ 1 å¼¹](https://mp.weixin.qq.com/s/nMeisZVQmhVYCRi7YHTKIA)

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹ç¡¬æ ¸æºç ç¬¬ 2 å¼¹](https://mp.weixin.qq.com/s/gdrP9HXRkRf9zrMuzrCB7g)

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹ç¡¬æ ¸æºç ç¬¬ 3 å¼¹](https://mp.weixin.qq.com/s/mpoEnVvrtVBSk4PfUIKmMg)

[é©¬æ–¯å…‹å¼€æºçš„ grok-1 å¤§æ¨¡å‹ç¡¬æ ¸æºç ç¬¬ 4 å¼¹](https://mp.weixin.qq.com/s/fNLbaROZXFEfbREuBV1Kpg)


# å‰è¨€

ç½‘ä¸Šçš„å¤§éƒ¨åˆ†å†…å®¹éƒ½æ˜¯æµ…å°è¾„æ­¢ï¼Œæœ¬æ–‡è€é©¬å’Œå¤§å®¶ä¸€èµ·ç®€å•çœ‹ä¸€ä¸‹é©¬æ–¯å…‹è¿™ä¸¤å¤©å¼€æºçš„ grok åˆ°åº•æœ‰ä»€ä¹ˆå†…å®¹ã€‚

å†…å®¹è¿‡äºç¡¬æ ¸ï¼Œå»ºè®®æ”¶è—è½¬å‘â€‹æ…¢æ…¢æ¶ˆåŒ–~

# README

## Grok-1

è¯¥å­˜å‚¨åº“åŒ…å«äº†åŠ è½½å’Œè¿è¡ŒGrok-1å¼€æ”¾æƒé‡æ¨¡å‹çš„JAXç¤ºä¾‹ä»£ç ã€‚

è¯·ç¡®ä¿ä¸‹è½½æ£€æŸ¥ç‚¹å¹¶å°†`ckpt-0`ç›®å½•æ”¾ç½®åœ¨`checkpoints`ä¸­ - å‚è§[ä¸‹è½½æƒé‡](#downloading-the-weights)ã€‚

ç„¶åï¼Œè¿è¡Œ

```shell
pip install -r requirements.txt
python run.py
```

ä»¥æµ‹è¯•ä»£ç ã€‚

è¯¥è„šæœ¬åŠ è½½æ£€æŸ¥ç‚¹å¹¶ä»æ¨¡å‹å¯¹æµ‹è¯•è¾“å…¥è¿›è¡Œé‡‡æ ·ã€‚

ç”±äºæ¨¡å‹è§„æ¨¡è¾ƒå¤§ï¼ˆ314Bå‚æ•°ï¼‰ï¼Œæµ‹è¯•æ¨¡å‹æ‰€éœ€çš„GPUå†…å­˜è¶³å¤Ÿå¤§ã€‚è¯¥å­˜å‚¨åº“ä¸­MoEå±‚çš„å®ç°ä¸å¤Ÿé«˜æ•ˆã€‚é€‰æ‹©äº†æ­¤å®ç°ä»¥é¿å…éœ€è¦è‡ªå®šä¹‰å†…æ ¸ä»¥éªŒè¯æ¨¡å‹çš„æ­£ç¡®æ€§ã€‚

## æ¨¡å‹è§„æ ¼

Grok-1å½“å‰è®¾è®¡å…·æœ‰ä»¥ä¸‹è§„æ ¼ï¼š

- **å‚æ•°:** 314B
- **æ¶æ„:** 8ä¸ªä¸“å®¶çš„æ··åˆï¼ˆMoEï¼‰
- **ä¸“å®¶åˆ©ç”¨:** æ¯ä¸ªæ ‡è®°ä½¿ç”¨2ä¸ªä¸“å®¶
- **å±‚æ¬¡:** 64
- **æ³¨æ„åŠ›å¤´:** æŸ¥è¯¢ä½¿ç”¨48ä¸ªï¼Œé”®/å€¼ä½¿ç”¨8ä¸ª
- **åµŒå…¥å¤§å°:** 6,144
- **æ ‡è®°åŒ–:** ä½¿ç”¨131,072ä¸ªæ ‡è®°çš„SentencePieceåˆ†è¯å™¨
- **é™„åŠ åŠŸèƒ½:**
  - æ—‹è½¬åµŒå…¥ï¼ˆRoPEï¼‰
  - æ”¯æŒæ¿€æ´»åˆ†ç‰‡å’Œ8ä½é‡åŒ–
- **æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆä¸Šä¸‹æ–‡ï¼‰:** 8,192ä¸ªæ ‡è®°

## ä¸‹è½½æƒé‡

æ‚¨å¯ä»¥ä½¿ç”¨ç§å­å®¢æˆ·ç«¯å’Œä»¥ä¸‹ç£åŠ›é“¾æ¥ä¸‹è½½æƒé‡ï¼š

```
magnet:?xt=urn:btih:5f96d43576e3d386c9ba65b883210a393b68210e&tr=https%3A%2F%2Facademictorrents.com%2Fannounce.php&tr=udp%3A%2F%2Ftracker.coppersurfer.tk%3A6969&tr=udp%3A%2F%2Ftracker.opentrackr.org%3A1337%2Fannounce
```

æˆ–ç›´æ¥ä½¿ç”¨[HuggingFace ğŸ¤— Hub](https://huggingface.co/xai-org/grok-1)ï¼š

```
git clone https://github.com/xai-org/grok-1.git && cd grok-1
pip install huggingface_hub[hf_transfer]
huggingface-cli download xai-org/grok-1 --repo-type model --include ckpt-0/* --local-dir checkpoints --local-dir-use-symlinks False
```

## è®¸å¯è¯

æ­¤ç‰ˆæœ¬ä¸­çš„ä»£ç å’Œç›¸å…³Grok-1æƒé‡å—Apache 2.0è®¸å¯è¯çš„çº¦æŸã€‚

è¯¥è®¸å¯è¯ä»…é€‚ç”¨äºæ­¤å­˜å‚¨åº“ä¸­çš„æºæ–‡ä»¶å’ŒGrok-1çš„æ¨¡å‹æƒé‡ã€‚

# ä»£ç 

æˆ‘ä»¬å…ˆçœ‹ 2 ç¯‡æ¯”è¾ƒç®€å•çš„ã€‚

## run.py ä¸»ç¨‹åºè§£é‡Š

```python
# ç¿»è¯‘ï¼šè€é©¬å•¸è¥¿é£
# å¯¼å…¥å¿…è¦çš„åº“å’Œæ¨¡å—
import logging  # å¯¼å…¥æ—¥å¿—è®°å½•æ¨¡å—
from model import LanguageModelConfig, TransformerConfig, QuantizedWeight8bit as QW8Bit  # ä»æ¨¡å—ä¸­å¯¼å…¥æ¨¡å‹é…ç½®ç±»å’Œé‡åŒ–æƒé‡ç±»
from runners import InferenceRunner, ModelRunner, sample_from_model  # ä»æ¨¡å—ä¸­å¯¼å…¥æ¨ç†è¿è¡Œå™¨ã€æ¨¡å‹è¿è¡Œå™¨å’Œä»æ¨¡å‹ä¸­é‡‡æ ·å‡½æ•°

# æŒ‡å®šæ¨¡å‹æ£€æŸ¥ç‚¹çš„è·¯å¾„
CKPT_PATH = "./checkpoints/"

# å®šä¹‰ä¸»å‡½æ•°
def main():
    # é…ç½®Grok-1æ¨¡å‹å‚æ•°
    grok_1_model = LanguageModelConfig(
        vocab_size=128 * 1024,  # è¯æ±‡è¡¨å¤§å°
        pad_token=0,  # å¡«å……æ ‡è®°
        eos_token=2,  # ç»“æŸæ ‡è®°
        sequence_len=8192,  # åºåˆ—é•¿åº¦
        embedding_init_scale=1.0,  # åµŒå…¥åˆå§‹åŒ–æ¯”ä¾‹
        output_multiplier_scale=0.5773502691896257,  # è¾“å‡ºå€å¢æ¯”ä¾‹
        embedding_multiplier_scale=78.38367176906169,  # åµŒå…¥å€å¢æ¯”ä¾‹
        model=TransformerConfig(
            emb_size=48 * 128,  # åµŒå…¥å¤§å°
            widening_factor=8,  # æ‰©å±•å› å­
            key_size=128,  # å…³é”®å­—å¤§å°
            num_q_heads=48,  # æŸ¥è¯¢æ³¨æ„åŠ›å¤´æ•°é‡
            num_kv_heads=8,  # é”®/å€¼æ³¨æ„åŠ›å¤´æ•°é‡
            num_layers=64,  # å±‚æ¬¡æ•°é‡
            attn_output_multiplier=0.08838834764831845,  # æ³¨æ„åŠ›è¾“å‡ºå€å¢å™¨
            shard_activations=True,  # æ¿€æ´»åˆ†ç‰‡
            num_experts=8,  # MoEä¸“å®¶æ•°é‡
            num_selected_experts=2,  # æ¯ä¸ªæ ‡è®°é€‰å–çš„ä¸“å®¶æ•°é‡
            data_axis="data",  # æ•°æ®è½´
            model_axis="model",  # æ¨¡å‹è½´
        ),
    )
    
    # é…ç½®æ¨ç†è¿è¡Œå™¨
    inference_runner = InferenceRunner(
        pad_sizes=(1024,),  # å¡«å……å¤§å°
        runner=ModelRunner(
            model=grok_1_model,  # æŒ‡å®šæ¨¡å‹
            bs_per_device=0.125,  # æ¯ä¸ªè®¾å¤‡çš„æ‰¹é‡å¤§å°
            checkpoint_path=CKPT_PATH,  # æ£€æŸ¥ç‚¹è·¯å¾„
        ),
        name="local",  # åç§°
        load=CKPT_PATH,  # åŠ è½½æ£€æŸ¥ç‚¹çš„è·¯å¾„
        tokenizer_path="./tokenizer.model",  # åˆ†è¯å™¨è·¯å¾„
        local_mesh_config=(1, 8),  # æœ¬åœ°ç½‘æ ¼é…ç½®
        between_hosts_config=(1, 1),  # ä¸»æœºä¹‹é—´é…ç½®
    )
    
    # åˆå§‹åŒ–æ¨ç†è¿è¡Œå™¨
    inference_runner.initialize()
    
    # æ‰§è¡Œæ¨ç†ï¼Œå¹¶è·å¾—ç”Ÿæˆå™¨å¯¹è±¡
    gen = inference_runner.run()

    # å®šä¹‰è¾“å…¥å­—ç¬¦ä¸²
    inp = "The answer to life the universe and everything is of course"
    
    # è¿è¡Œæ¨ç†å¹¶è¾“å‡ºç»“æœ
    print(f"Output for prompt: {inp}", sample_from_model(gen, inp, max_len=100, temperature=0.01))

# æ£€æŸ¥æ˜¯å¦æ˜¯ä¸»ç¨‹åº
if __name__ == "__main__":
    # é…ç½®æ—¥å¿—è®°å½•åŸºæœ¬è®¾ç½®ï¼Œå°†æ—¥å¿—çº§åˆ«è®¾ç½®ä¸ºINFO
    logging.basicConfig(level=logging.INFO)
    # è°ƒç”¨ä¸»å‡½æ•°
    main()
```


## checkpoint.py


### åšäº†ä»€ä¹ˆ

è¿™æ®µä»£ç ä¸»è¦å®Œæˆäº†ä»¥ä¸‹åŠŸèƒ½ï¼š

1. å¯¼å…¥æ‰€éœ€çš„æ¨¡å—å’Œåº“ã€‚
2. å®šä¹‰äº†ä¸€ç³»åˆ—ç”¨äºåœ¨å…±äº«å†…å­˜ä¸­å¤åˆ¶æ–‡ä»¶çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’Œè¾…åŠ©å‡½æ•°ï¼Œä»¥æé«˜æ–‡ä»¶æ“ä½œæ•ˆç‡å¹¶èŠ‚çœèµ„æºã€‚
3. å®ç°äº†å¿«é€Ÿçš„ååºåˆ—åŒ–å’Œåºåˆ—åŒ–å‡½æ•°ï¼Œä½¿ç”¨äº†ä¸Šè¿°å®šä¹‰çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä»¥ä¾¿åœ¨å…±äº«å†…å­˜ä¸­è¿›è¡Œæ–‡ä»¶å¤åˆ¶æ“ä½œã€‚
4. æä¾›äº†åŠ è½½å¼ é‡æ•°æ®çš„å‡½æ•° `load_tensors`ï¼Œè¯¥å‡½æ•°æ”¯æŒå¤šçº¿ç¨‹å¹¶è¡ŒåŠ è½½å¼ é‡æ•°æ®ï¼Œå¹¶åœ¨åŠ è½½è¿‡ç¨‹ä¸­å¯¹æ•°æ®è¿›è¡Œåˆ†ç‰‡å’Œå¤„ç†ã€‚
5. å®šä¹‰äº†ä¸€äº›è¾…åŠ©å‡½æ•°ï¼Œç”¨äºå¤„ç†è·¯å¾„å­—ç¬¦ä¸²å’ŒåŠ è½½è·¯å¾„è§„åˆ™ï¼Œä»¥åŠåœ¨çŠ¶æ€æ¢å¤è¿‡ç¨‹ä¸­è¿›è¡ŒçŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥å’Œå‚æ•°é€‰é¡¹å¤„ç†ã€‚
6. å®ç°äº†çŠ¶æ€æ¢å¤å‡½æ•° `restore`ï¼Œè¯¥å‡½æ•°ä»æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸­åŠ è½½å¼ é‡æ•°æ®ï¼Œå¹¶å°†å…¶æ¢å¤ä¸ºçŠ¶æ€ï¼ŒåŒæ—¶è¿›è¡Œäº†çŠ¶æ€ä¸€è‡´æ€§æ£€æŸ¥å’Œå‚æ•°é€‰é¡¹å¤„ç†ã€‚

æ ¸å¿ƒç‚¹å’Œæ­¥éª¤åŒ…æ‹¬ï¼š

- æä¾›äº†é«˜æ•ˆçš„æ–‡ä»¶æ“ä½œåŠŸèƒ½ï¼Œåˆ©ç”¨äº†å…±äº«å†…å­˜å’Œå¤šçº¿ç¨‹æŠ€æœ¯ã€‚
- æ”¯æŒäº†å¿«é€Ÿçš„ååºåˆ—åŒ–å’Œåºåˆ—åŒ–è¿‡ç¨‹ã€‚
- å®ç°äº†å¹¶è¡ŒåŠ è½½å¼ é‡æ•°æ®çš„åŠŸèƒ½ï¼Œæé«˜äº†åŠ è½½æ•ˆç‡ã€‚
- åœ¨çŠ¶æ€æ¢å¤è¿‡ç¨‹ä¸­ï¼Œä¿è¯äº†åŠ è½½çš„çŠ¶æ€ä¸ä»£ç ä¸­çš„çŠ¶æ€å‚æ•°ä¸€è‡´æ€§ï¼Œå¹¶æ ¹æ®å‚æ•°é€‰é¡¹è¿›è¡Œäº†çµæ´»çš„å¤„ç†ã€‚

1. `replace_with_load_state` å‡½æ•°ï¼šè¯¥å‡½æ•°ç”¨äºæ ¹æ®åŠ è½½çŠ¶æ€æ›¿æ¢åˆå§‹çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®ã€‚

å®ƒçš„æ ¸å¿ƒæ­¥éª¤åŒ…æ‹¬ï¼š

   - å±•å¹³åŠ è½½çŠ¶æ€å’Œåˆå§‹çŠ¶æ€ï¼Œä»¥åŠè·å–åŠ è½½çŠ¶æ€ä¸­å¼ é‡æ•°æ®çš„è·¯å¾„æ˜ å°„ã€‚
   - éå†åˆå§‹çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®ï¼Œæ ¹æ®åŠ è½½è·¯å¾„è§„åˆ™è¿›è¡Œæ›¿æ¢æˆ–åˆ›å»ºæ–°çš„å¼ é‡ã€‚
   - æœ€åå°†æ›¿æ¢åçš„å¼ é‡æ•°æ®é‡æ–°ç»„è£…æˆæ ‘ç»“æ„è¿”å›ã€‚

2. `restore` å‡½æ•°ï¼šè¯¥å‡½æ•°ç”¨äºä»æ£€æŸ¥ç‚¹æ–‡ä»¶ä¸­åŠ è½½å¼ é‡æ•°æ®å¹¶å°†å…¶æ¢å¤ä¸ºçŠ¶æ€ã€‚å…¶æ ¸å¿ƒæ­¥éª¤åŒ…æ‹¬ï¼š
   - æ„å»ºæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„ï¼Œå¹¶æ‰“å°åŠ è½½æ£€æŸ¥ç‚¹çš„ä¿¡æ¯ã€‚
   - åŠ è½½çŠ¶æ€å½¢çŠ¶ä¿¡æ¯å’Œå¼ é‡æ•°æ®ã€‚
   - å¯¹åŠ è½½çš„çŠ¶æ€è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œç¡®ä¿å‚æ•°ä¸€è‡´æ€§ã€‚
   - å°†çŠ¶æ€åˆ†ç‰‡æ˜ å°„ä¸ºå…¨å±€æ•°ç»„ï¼Œå¹¶æ ¹æ®å‚æ•°é€‰é¡¹å†³å®šæ˜¯å¦ä»…è¿”å›å‚æ•°éƒ¨åˆ†ã€‚

è¿™äº›åŠŸèƒ½çš„å®ç°åŸºäº JAX åº“æä¾›çš„æ ‘ç»“æ„æ“ä½œå’Œå¹¶è¡Œè®¡ç®—åŠŸèƒ½ï¼ŒåŒæ—¶åˆ©ç”¨äº†ä¸Šä¸‹æ–‡ç®¡ç†å™¨å’Œå¤šçº¿ç¨‹æŠ€æœ¯æ¥æœ‰æ•ˆåœ°å¤„ç†æ–‡ä»¶æ“ä½œå’Œå¹¶è¡Œä»»åŠ¡ã€‚

### æºç 

æ³¨é‡Šæºç 

```python
from __future__ import annotations
# å¯¼å…¥ Python æœªæ¥æ”¯æŒçš„è¯­è¨€ç‰¹æ€§æ¨¡å—ï¼Œä»¥æ”¯æŒåœ¨ç±»å‹æç¤ºä¸­ä½¿ç”¨å­—ç¬¦ä¸²å½¢å¼çš„ç±»å

import contextlib  # ä¸Šä¸‹æ–‡ç®¡ç†æ¨¡å—ï¼Œç”¨äºåˆ›å»ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
import logging  # æ—¥å¿—è®°å½•æ¨¡å—
import math  # æ•°å­¦æ¨¡å—
import os  # æ“ä½œç³»ç»Ÿæ¨¡å—ï¼Œç”¨äºå¤„ç†æ–‡ä»¶å’Œç›®å½•è·¯å¾„
import pickle  # pickleåºåˆ—åŒ–æ¨¡å—ï¼Œç”¨äºå¯¹è±¡çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–
import re  # æ­£åˆ™è¡¨è¾¾å¼æ¨¡å—ï¼Œç”¨äºå­—ç¬¦ä¸²åŒ¹é…å’Œæœç´¢
import shutil  # æ–‡ä»¶æ“ä½œæ¨¡å—ï¼Œç”¨äºæ–‡ä»¶çš„å¤åˆ¶ã€ç§»åŠ¨ç­‰æ“ä½œ
import sys  # ç³»ç»Ÿæ¨¡å—ï¼Œæä¾›å¯¹ Python è§£é‡Šå™¨çš„è®¿é—®
import tempfile  # ä¸´æ—¶æ–‡ä»¶æ¨¡å—ï¼Œç”¨äºåˆ›å»ºä¸´æ—¶æ–‡ä»¶å’Œç›®å½•
from concurrent.futures import ThreadPoolExecutor, wait  # å¹¶å‘æ¨¡å—ï¼Œç”¨äºå¹¶è¡Œæ‰§è¡Œä»»åŠ¡
from typing import Any, Optional  # ç±»å‹æç¤ºæ¨¡å—ï¼Œç”¨äºæŒ‡å®šå‡½æ•°å‚æ•°å’Œè¿”å›å€¼çš„ç±»å‹

import jax  # JAX æ•°å€¼è®¡ç®—åº“
import numpy as np  # æ•°ç»„å¤„ç†æ¨¡å—

from jax.experimental import multihost_utils  # JAX å®éªŒæ€§æ¨¡å—ï¼Œç”¨äºå¤šä¸»æœºè¿è¡Œ

from model import QuantizedWeight8bit  # ä»è‡ªå®šä¹‰æ¨¡å—ä¸­å¯¼å…¥ QuantizedWeight8bit ç±»

logger = logging.getLogger(__name__)  # è·å–å½“å‰æ¨¡å—çš„æ—¥å¿—è®°å½•å™¨
rank_logger = logging.getLogger("rank")  # è·å–æ—¥å¿—è®°å½•å™¨ç”¨äºæ’åä¿¡æ¯

# ä¸‹é¢å®šä¹‰äº†å‡ ä¸ªä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œç”¨äºå°†æ–‡ä»¶å¤åˆ¶åˆ°å…±äº«å†…å­˜ä¸­ã€ä»å…±äº«å†…å­˜ä¸­å¤åˆ¶æ–‡ä»¶
# è¿™äº›ä¸Šä¸‹æ–‡ç®¡ç†å™¨ç¡®ä¿æ–‡ä»¶åœ¨å¤åˆ¶åè¢«åˆ é™¤ï¼Œä»¥èŠ‚çœèµ„æºå’Œç©ºé—´

@contextlib.contextmanager
def copy_to_shm(file: str):
    if file.startswith("/dev/shm/"):
        # å¦‚æœæ–‡ä»¶å·²ç»åœ¨å…±äº«å†…å­˜ä¸­ï¼Œåˆ™æ— éœ€æ“ä½œï¼Œç›´æ¥è¿”å›æ–‡ä»¶è·¯å¾„
        yield file
        return

    tmp_dir = "/dev/shm/"
    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶å¹¶å¤åˆ¶åŸå§‹æ–‡ä»¶å†…å®¹åˆ°ä¸´æ—¶æ–‡ä»¶ä¸­
    fd, tmp_path = tempfile.mkstemp(dir=tmp_dir)
    try:
        shutil.copyfile(file, tmp_path)
        yield tmp_path  # é€šè¿‡ç”Ÿæˆå™¨çš„ yield è¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    finally:
        os.remove(tmp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.close(fd)  # å…³é—­æ–‡ä»¶æè¿°ç¬¦

@contextlib.contextmanager
def copy_from_shm(file: str):
    tmp_dir = "/dev/shm/"
    fd, tmp_path = tempfile.mkstemp(dir=tmp_dir)
    try:
        yield tmp_path  # é€šè¿‡ç”Ÿæˆå™¨çš„ yield è¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„
        shutil.copyfile(tmp_path, file)  # å°†ä¸´æ—¶æ–‡ä»¶å†…å®¹å¤åˆ¶åˆ°ç›®æ ‡æ–‡ä»¶ä¸­
    finally:
        os.remove(tmp_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.close(fd)  # å…³é—­æ–‡ä»¶æè¿°ç¬¦

# ä»¥ä¸‹ä¸¤ä¸ªå‡½æ•°åˆ†åˆ«ç”¨äºå¿«é€Ÿååºåˆ—åŒ–å’Œåºåˆ—åŒ–å¯¹è±¡ï¼Œä½¿ç”¨äº†ä¸Šé¢å®šä¹‰çš„ä¸Šä¸‹æ–‡ç®¡ç†å™¨
def fast_unpickle(path: str) -> Any:
    with copy_to_shm(path) as tmp_path:
        with open(tmp_path, "rb") as f:
            return pickle.load(f)

def fast_pickle(obj: Any, path: str) -> None:
    with copy_from_shm(path) as tmp_path:
        with open(tmp_path, "wb") as f:
            pickle.dump(obj, f)

# ä¸‹é¢çš„å‡½æ•°ç”¨äºåŠ è½½å¼ é‡æ•°æ®ï¼Œå¯ä»¥åœ¨å¤šçº¿ç¨‹ç¯å¢ƒä¸‹å¹¶è¡ŒåŠ è½½å¼ é‡æ•°æ®
def load_tensors(shaped_arrays, directory, mesh_config, tensor_indices=None):
    # åˆ›å»ºä¸€ä¸ªæœ€å¤§å¹¶è¡Œçº¿ç¨‹æ•°ä¸º32çš„çº¿ç¨‹æ± 
    pool = ThreadPoolExecutor(max_workers=32)
    fs = list()
    num_tensors = 0
    num_replicas = 1
    data_model_shards = math.prod(mesh_config)
    if tensor_indices is None:
        iterator = enumerate(shaped_arrays)
    else:
        iterator = zip(tensor_indices, shaped_arrays)
    for i, t in iterator:
        # æ ¹æ®å½“å‰è¿›ç¨‹çš„ç´¢å¼•ï¼Œå†³å®šæ˜¯å¦åŠ è½½å¼ é‡æ•°æ®
        if (i % num_replicas) == ((jax.process_index() // data_model_shards) % num_replicas):
            idx = (
                jax.process_index() // (num_replicas * data_model_shards) * data_model_shards
                + jax.process_index() % data_model_shards
            )
            # æäº¤å¼‚æ­¥ä»»åŠ¡ï¼ŒåŠ è½½å¼ é‡æ•°æ®
            fs.append(
                pool.submit(fast_unpickle, os.path.join(directory, f"tensor{i:05d}_{idx:03d}"))
            )
            num_tensors += 1
        else:
            # å¦‚æœå½“å‰è¿›ç¨‹ä¸éœ€è¦åŠ è½½å¼ é‡æ•°æ®ï¼Œåˆ™åˆ›å»ºä¸€ä¸ªé›¶å¼ é‡
            fs.append(pool.submit(np.zeros, t.shape, dtype=t.dtype))
    wait(fs)  # ç­‰å¾…æ‰€æœ‰å¼‚æ­¥ä»»åŠ¡å®Œæˆ
    return [f.result() for f in fs]  # è¿”å›åŠ è½½å®Œæˆçš„å¼ é‡åˆ—è¡¨

# ä¸‹é¢çš„å‡½æ•°ç”¨äºå°†å…ƒç»„å½¢å¼çš„è·¯å¾„è½¬æ¢ä¸ºå­—ç¬¦ä¸²å½¢å¼
def path_tuple_to_string(path: tuple) -> str:
    pieces = []
    for elem in path:
        if isinstance(elem, jax.tree_util.DictKey):
            pieces.append(elem.key)
        elif isinstance(elem, jax.tree_util.GetAttrKey):
            pieces.append(elem.name)
        else:
            assert isinstance(elem, (jax.tree_util.FlattenedIndexKey, jax.tree_util.SequenceKey))
    return "/".join(pieces)

# ä¸‹é¢çš„å‡½æ•°ç”¨äºæ ¹æ®è§„åˆ™è·å–åŠ è½½è·¯å¾„å­—ç¬¦ä¸²
def get_load_path_str(
    init_path_str: str,
    load_rename_rules: Optional[list[tuple[str, str]]] = None,
    load_exclude_rules: Optional[list[str]] = None,
) -> Optional[str]:
    # æ’é™¤è§„åˆ™
    if load_exclude_rules is not None:
        for search_pattern in load_exclude_rules:
            if re.search(search_pattern, init_path_str):
                return None

    # é‡å‘½åè§„åˆ™
    load_path_str = init_path_str
    if load_rename_rules is not None:
        for search_pattern, replacement_pattern in load_rename_rules:
            if re.search(search_pattern, load_path_str):
                load_path_str = re.sub(search_pattern, replacement_pattern, load_path_str)
                break

    return load_path_str

# ä¸‹é¢çš„å‡½æ•°ç”¨äºæ›¿æ¢åˆå§‹çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®ä¸ºåŠ è½½çŠ¶æ€ä¸­çš„å¼ é‡
def replace_with_load_state(
    init_state: Any,  # åˆå§‹çŠ¶æ€ï¼Œä»»æ„ç±»å‹
    load_state: Any,  # åŠ è½½çŠ¶æ€ï¼Œä»»æ„ç±»å‹
    load_rename_rules: Optional[list[tuple[str, str]]] = None,  # åŠ è½½é‡å‘½åè§„åˆ™ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º None
    load_exclude_rules: Optional[list[str]] = None,  # åŠ è½½æ’é™¤è§„åˆ™ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º None
    mesh_config: tuple = (1, 1),  # ç½‘æ ¼é…ç½®ï¼Œå…ƒç»„ç±»å‹ï¼Œé»˜è®¤ä¸º (1, 1)
) -> Any:  # è¿”å›å€¼ä¸ºä»»æ„ç±»å‹
    # å±•å¹³åŠ è½½çŠ¶æ€ï¼Œè·å–åŠ è½½çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®å’Œè·¯å¾„
    flatten_load, _ = jax.tree_util.tree_flatten_with_path(load_state)
    # å±•å¹³åˆå§‹çŠ¶æ€ï¼Œè·å–åˆå§‹çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®å’Œè·¯å¾„ï¼Œä»¥åŠåˆå§‹çŠ¶æ€çš„ç»“æ„ä¿¡æ¯
    flatten_init, structure_init = jax.tree_util.tree_flatten_with_path(init_state)
    # æ„å»ºåŠ è½½çŠ¶æ€ä¸­å¼ é‡æ•°æ®çš„è·¯å¾„æ˜ å°„
    load_map = {path_tuple_to_string(path): tensor for path, tensor in flatten_load}

    replaced = []  # ç”¨äºå­˜å‚¨æ›¿æ¢åçš„å¼ é‡æ•°æ®åˆ—è¡¨
    num_replicas = 1  # å‰¯æœ¬æ•°é‡
    data_model_shards = math.prod(mesh_config)  # æ•°æ®æ¨¡å‹åˆ†ç‰‡æ•°é‡
    # éå†åˆå§‹çŠ¶æ€ä¸­çš„å¼ é‡æ•°æ®å’Œè·¯å¾„
    for i, (init_path, tensor) in enumerate(flatten_init):
        init_path_str = path_tuple_to_string(init_path)  # è·å–åˆå§‹çŠ¶æ€ä¸­å¼ é‡æ•°æ®çš„è·¯å¾„å­—ç¬¦ä¸²
        # æ ¹æ®åŠ è½½è·¯å¾„è§„åˆ™è·å–åŠ è½½è·¯å¾„å­—ç¬¦ä¸²
        load_path_str = get_load_path_str(init_path_str, load_rename_rules, load_exclude_rules)
        if load_path_str is None:
            # å¦‚æœåŠ è½½è·¯å¾„å­—ç¬¦ä¸²ä¸º Noneï¼Œåˆ™æ’é™¤ä¸è¿›è¡Œæ›¿æ¢
            rank_logger.info(f"Excluded from restore: {init_path_str}.")
            replaced.append(tensor)
        elif load_path_str in load_map:
            # å¦‚æœåŠ è½½è·¯å¾„å­—ç¬¦ä¸²åœ¨åŠ è½½è·¯å¾„æ˜ å°„ä¸­å­˜åœ¨ï¼Œåˆ™è¿›è¡Œæ›¿æ¢
            if load_path_str == init_path_str:
                rank_logger.info(f"Restored from ckpt: {init_path_str}.")
            else:
                rank_logger.info(f"Restored from ckpt: {init_path_str} <-- {load_path_str}.")
            replaced.append(load_map[load_path_str])
        else:
            # å¦‚æœåŠ è½½è·¯å¾„å­—ç¬¦ä¸²åœ¨åŠ è½½è·¯å¾„æ˜ å°„ä¸­ä¸å­˜åœ¨ï¼Œåˆ™æ ¹æ®è§„åˆ™åˆ›å»ºå¼ é‡æˆ–é›¶å¼ é‡
            rank_logger.info(f"Not found in ckpt: {init_path_str}.")
            if (i % num_replicas) == ((jax.process_index() // data_model_shards) % num_replicas):
                replaced.append(tensor)
            else:
                replaced.append(np.zeros_like(tensor))

    return jax.tree_util.tree_unflatten(structure_init, replaced)  # å°†æ›¿æ¢åçš„å¼ é‡æ•°æ®é‡æ–°ç»„è£…æˆæ ‘ç»“æ„è¿”å›


def restore(
    checkpoint_path: str,  # æ£€æŸ¥ç‚¹è·¯å¾„ï¼Œå­—ç¬¦ä¸²ç±»å‹
    state_shapes: Any,  # çŠ¶æ€å½¢çŠ¶ï¼Œä»»æ„ç±»å‹
    mesh,  # ç½‘æ ¼
    between_hosts_config,  # ä¸»æœºé—´é…ç½®
    params_only,  # æ˜¯å¦åªè¿”å›å‚æ•°
    state_sharding,  # çŠ¶æ€åˆ†ç‰‡
    init_state: Optional[Any] = None,  # åˆå§‹çŠ¶æ€ï¼Œå¯é€‰å‚æ•°ï¼Œé»˜è®¤ä¸º None
) -> Any:  # è¿”å›å€¼ä¸ºä»»æ„ç±»å‹
    ckpt_path = os.path.join(checkpoint_path, "ckpt-0")  # æ„å»ºæ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„

    rank_logger.info("Loading checkpoint at {}".format(ckpt_path))  # æ‰“å°åŠ è½½æ£€æŸ¥ç‚¹ä¿¡æ¯
    ckpt_shapes = state_shapes  # è·å–çŠ¶æ€å½¢çŠ¶ä¿¡æ¯
    # å±•å¹³çŠ¶æ€å½¢çŠ¶ï¼Œè·å–çŠ¶æ€å½¢çŠ¶ä¸­çš„å¼ é‡å½¢çŠ¶å’Œè·¯å¾„ï¼Œä»¥åŠçŠ¶æ€å½¢çŠ¶çš„ç»“æ„ä¿¡æ¯
    ckpt_shapes_with_path, structure = jax.tree_util.tree_flatten_with_path(ckpt_shapes)

    ckpt_shapes_flat = [elem[1] for elem in ckpt_shapes_with_path]  # è·å–çŠ¶æ€å½¢çŠ¶ä¸­çš„å¼ é‡å½¢çŠ¶åˆ—è¡¨
    # åŠ è½½å¼ é‡æ•°æ®
    loaded_tensors = load_tensors(ckpt_shapes_flat, ckpt_path, between_hosts_config)

    state = jax.tree_util.tree_unflatten(structure, loaded_tensors)  # å°†åŠ è½½çš„å¼ é‡æ•°æ®é‡æ–°ç»„è£…æˆçŠ¶æ€

    # å¯¹çŠ¶æ€è¿›è¡Œä¸€è‡´æ€§æ£€æŸ¥ï¼Œç¡®ä¿å‚æ•°ä¸€è‡´æ€§
    ckpt_keys = set(state.params.keys())
    code_keys = set(state_sharding.params.keys())

    if ckpt_keys != code_keys and init_state is None:
        # å¦‚æœæ£€æŸ¥ç‚¹å‚æ•°ä¸ä»£ç å‚æ•°ä¸ä¸€è‡´ä¸”åˆå§‹çŠ¶æ€ä¸ºç©ºï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        missing_in_ckpt = code_keys - ckpt_keys
        missing_locally = ckpt_keys - code_keys
        raise ValueError(
            "Parameters in the code are not matching checkpoint parameters.\n"
            "Params missing in checkpoint: {}\nParams missing in code: {}".format(
                missing_in_ckpt, missing_locally
            )
        )
    # å°†çŠ¶æ€åˆ†ç‰‡æ˜ å°„ä¸ºå…¨å±€æ•°ç»„
    state_sharding = jax.tree_util.tree_map(
        lambda x: jax.sharding.PartitionSpec() if x is None else x,
        state_sharding,
        is_leaf=lambda x: x is None,
    )
    state = multihost_utils.host_local_array_to_global_array(state, mesh, state_sharding)  # å°†æœ¬åœ°æ•°ç»„è½¬æ¢ä¸ºå…¨å±€æ•°ç»„
    if params_only:
        state = state.params  # å¦‚æœä»…è¿”å›å‚æ•°ï¼Œåˆ™è¿”å›çŠ¶æ€çš„å‚æ•°éƒ¨åˆ†
    return state  # è¿”å›çŠ¶æ€
``` 

# å‚è€ƒèµ„æ–™


* any list
{:toc}
