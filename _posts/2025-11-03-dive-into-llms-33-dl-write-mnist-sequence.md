---
layout: post
title: dive-into-llms-34-CNNï¼ˆConvolutional Neural Networkï¼Œå·ç§¯ç¥ç»ç½‘ç»œï¼‰ä»‹ç» 
date: 2025-11-03 20:40:12 +0800
categories: [AI]
tags: [ai, learn-note]
published: true
---



# chat

## å¦‚æœæˆ‘æƒ³å®ç°è¿ç»­å¤šä¸ªæ•°å­—çš„å›¾ç‰‡è¯†åˆ«ï¼Œè¦å¦‚ä½•å®ç°ï¼Ÿ

å¦‚ä½•è§£å†³è¿™ä¸ªæ€è·¯å‘¢?

æˆ‘ä»¬å¯ä»¥ä¸ä¿®æ”¹å•ä¸ª CNN æ•°å­—è§£æï¼Œç„¶åå®ç°è¿™ä¸ªåŠŸèƒ½ã€‚

è¦æ”¯æŒ**â€œä¸€å¼ å›¾ç‰‡ä¸­åŒ…å«å¤šä¸ªæ•°å­—â€ï¼ˆæ¯”å¦‚ 123ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥ä¸æ”¹æ¨¡å‹ç»“æ„ï¼Œ

è€Œæ˜¯åœ¨æ¨ç†é˜¶æ®µ**ï¼ˆinferenceï¼‰åšã€Œå¤šæ•°å­—åˆ†å‰² + æ‰¹é‡è¯†åˆ«ã€ã€‚

ä¹Ÿå°±æ˜¯è¯´ï¼ŒCNN ä¾ç„¶æ˜¯è¯†åˆ«â€œå•ä¸ªæ•°å­—â€ï¼Œæˆ‘ä»¬è®©å®ƒå¯¹æ¯ä¸ªæ•°å­—å°å—ä¾æ¬¡é¢„æµ‹ã€‚

è¿™æ ·ä½ ä¸éœ€è¦é‡æ–°è®­ç»ƒæ–°æ¨¡å‹ï¼Œä¹Ÿèƒ½ç›´æ¥è¯†åˆ«ã€Œè¿ç»­å¤šä¸ªæ•°å­—ã€ã€‚

## å®Œæ•´å®ç°ï¼šæ”¯æŒå¤šæ•°å­—è¯†åˆ«ï¼ˆæ”¹è¿›ç‰ˆï¼‰

ä¸‹é¢è¿™ä»½æ˜¯ä½ ä»£ç çš„ç›´æ¥æ”¹è¿›ç‰ˆï¼Œæ ¸å¿ƒæ”¹åŠ¨åªæœ‰ä¸¤ä¸ªåœ°æ–¹ï¼š

è¯†åˆ«å‰ï¼Œç”¨ OpenCV æ‰¾è½®å»“ è‡ªåŠ¨åˆ‡å‰²å‡ºæ¯ä¸ªæ•°å­—ï¼›

é€ä¸ªé€å…¥ CNN æ¨¡å‹è¯†åˆ«åï¼Œæ‹¼æ¥æˆç»“æœå­—ç¬¦ä¸²ã€‚

```py
import cv2
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms

# ======================
# âœ… 1. å®šä¹‰ CNN æ¨¡å‹ç»“æ„
# ======================
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.dropout(x)
        x = x.view(-1, 64 * 14 * 14)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# ======================
# âœ… 2. åŠ è½½æ¨¡å‹
# ======================
model = CNN()
model.load_state_dict(torch.load("model/mnist_cnn.pth", map_location="cpu"))
model.eval()


# ======================
# âœ… 3. å›¾åƒé¢„å¤„ç†
# ======================
def preprocess_image_for_mnist(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    pil = Image.fromarray(gray)
    try:
        resample = Image.Resampling.LANCZOS
    except AttributeError:
        resample = Image.ANTIALIAS
    pil = pil.resize((28, 28), resample)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    tensor = transform(pil).unsqueeze(0)
    return tensor


# ======================
# âœ… 4. åˆ†å‰²å¤šä¸ªæ•°å­—
# ======================
def segment_digits(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    _, thresh = cv2.threshold(gray, 30, 255, cv2.THRESH_BINARY)
    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

    boxes = [cv2.boundingRect(c) for c in contours]
    boxes = sorted(boxes, key=lambda x: x[0])  # æŒ‰ x åæ ‡ä»å·¦åˆ°å³æ’åº

    digits = []
    for (x, y, w, h) in boxes:
        if w > 10 and h > 10:  # è¿‡æ»¤å™ªç‚¹
            digit_img = gray[y:y+h, x:x+w]
            # åœ¨æ–¹æ¡†å†…è¡¥ç™½èƒŒæ™¯ï¼Œè®©æ¯”ä¾‹å±…ä¸­
            size = max(w, h)
            square = np.ones((size, size), dtype=np.uint8) * 0
            offset_x = (size - w) // 2
            offset_y = (size - h) // 2
            square[offset_y:offset_y + h, offset_x:offset_x + w] = digit_img
            square = cv2.bitwise_not(square)
            digits.append(square)

    return digits


# ======================
# âœ… 5. ç»˜å›¾çª—å£
# ======================
canvas = np.ones((280, 560, 3), dtype=np.uint8) * 255
drawing = False
last_point = None
prediction_text = None

def draw(event, x, y, flags, param):
    global drawing, last_point
    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        last_point = (x, y)
    elif event == cv2.EVENT_MOUSEMOVE and drawing:
        cv2.line(canvas, last_point, (x, y), (0, 0, 0), 12)
        last_point = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        last_point = None


cv2.namedWindow("ğŸ–Œ MNIST Multi-Digit Board", cv2.WINDOW_NORMAL)
cv2.setMouseCallback("ğŸ–Œ MNIST Multi-Digit Board", draw)

print("ğŸ¨ ç”¨é¼ æ ‡å·¦é”®ç”»å¤šä¸ªæ•°å­—ï¼ˆä¾‹å¦‚ï¼š1234ï¼‰")
print("âœ… æŒ‰ 's' è¯†åˆ«æ‰€æœ‰æ•°å­—")
print("ğŸ§¹ æŒ‰ 'c' æ¸…ç©ºç”»å¸ƒ")
print("âŒ æŒ‰ 'q' é€€å‡º")

# ======================
# âœ… 6. ä¸»å¾ªç¯
# ======================
while True:
    display = canvas.copy()
    if prediction_text is not None:
        cv2.putText(display, f"RES: {prediction_text}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)

    cv2.imshow("ğŸ–Œ MNIST Multi-Digit Board", display)
    key = cv2.waitKey(10) & 0xFF

    if key == ord('q'):
        break

    elif key == ord('c'):
        canvas[:] = 255
        prediction_text = None

    elif key == ord('s'):
        img_for_pred = canvas.copy()
        digits = segment_digits(img_for_pred)

        if not digits:
            print("âš ï¸ æ²¡æ£€æµ‹åˆ°æ•°å­—ï¼Œè¯·é‡è¯•ï¼")
            continue

        preds = []
        for d in digits:
            tensor = preprocess_image_for_mnist(cv2.cvtColor(d, cv2.COLOR_GRAY2BGR))
            with torch.no_grad():
                outputs = model(tensor)
                _, predicted = torch.max(outputs, 1)
                preds.append(str(predicted.item()))

        prediction_text = "".join(preds)
        print(f"ğŸ§  Predicted digits: {prediction_text}")

cv2.destroyAllWindows()
```

## æ•ˆæœ

æ•ˆæœè¿˜è¡Œï¼Œä¸‹ä¸€æ­¥å¯ä»¥ç›´æ¥è¯•ä¸€ä¸‹é‡æ–°è®­ç»ƒä¸€ä¸ªæ”¯æŒå¤šä¸ªå­—ç¬¦çš„æ¨¡å‹

* any list
{:toc}