---
layout: post
title: dive-into-llms-31-å¦‚ä½•å…¥é—¨æ·±åº¦å­¦ä¹ 
date: 2025-11-03 20:40:12 +0800
categories: [AI]
tags: [ai, learn-note]
published: true
---



# å‡†å¤‡å·¥ä½œ

## ä¸‹è½½ python

https://www.python.org/ftp/python/3.12.6/python-3.12.6-amd64.exe

ä¸‹è½½åç›´æ¥å®‰è£…ï¼Œå‹¾é€‰ä¸Š ADD PATH é€‰é¡¹ã€‚

## å®‰è£…

```sh
pip install torch torchvision
```

## ç¼–ç 

- mnist_train.py

```py
# mnist_train.py
# ä¸€ä¸ªæœ€ç®€å•çš„ PyTorch ç¥ç»ç½‘ç»œï¼šæ‰‹å†™æ•°å­—è¯†åˆ«

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms


def main():
    # 1ï¸âƒ£ æ•°æ®é¢„å¤„ç†ï¼šæŠŠå›¾ç‰‡è½¬æˆ tensor å¹¶å½’ä¸€åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # 2ï¸âƒ£ ä¸‹è½½å¹¶åŠ è½½ MNIST æ•°æ®é›†
    train_dataset = torchvision.datasets.MNIST(
        root='./data', train=True, download=True, transform=transform)
    test_dataset = torchvision.datasets.MNIST(
        root='./data', train=False, download=True, transform=transform)

    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=64, shuffle=False)

    # 3ï¸âƒ£ å®šä¹‰ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ
    class SimpleNN(nn.Module):
        def __init__(self):
            super(SimpleNN, self).__init__()
            self.flatten = nn.Flatten()  # æŠŠ 28x28 å±•å¼€æˆä¸€ç»´
            self.fc1 = nn.Linear(28 * 28, 128)
            self.relu = nn.ReLU()
            self.fc2 = nn.Linear(128, 10)  # 10 ä¸ªè¾“å‡ºç±»åˆ«ï¼ˆæ•°å­— 0~9ï¼‰

        def forward(self, x):
            x = self.flatten(x)
            x = self.fc1(x)
            x = self.relu(x)
            x = self.fc2(x)
            return x

    model = SimpleNN()

    # 4ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 5ï¸âƒ£ è®­ç»ƒæ¨¡å‹
    num_epochs = 5
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

    # 6ï¸âƒ£ æµ‹è¯•æ¨¡å‹å‡†ç¡®ç‡
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"âœ… Accuracy on test set: {100 * correct / total:.2f}%")

    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ç»å­¦ä¼šè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚")


if __name__ == "__main__":
    main()
```


## è¿è¡Œ

```
python mnist_train.py
```

## æµ‹è¯•æ•ˆæœ

æ‰§è¡Œåçš„æµ‹è¯•æ•ˆæœ

```
>python mnist_train.py
100.0%
100.0%
100.0%
100.0%
Epoch [1/5], Loss: 0.3926
Epoch [2/5], Loss: 0.2096
Epoch [3/5], Loss: 0.1493
Epoch [4/5], Loss: 0.1209
Epoch [5/5], Loss: 0.1010
âœ… Accuracy on test set: 96.60%
ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ç»å­¦ä¼šè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚
```


# å¦‚ä½•ä½¿ç”¨

## è¯´æ˜

æ¨¡å‹çš„è®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä¿å­˜ä¹‹åä½¿ç”¨ã€‚

## ä¿å­˜

è®­ç»ƒç»“æŸååŠ ä¸Š

```java
torch.save(model.state_dict(), "model/mnist_model.pth")
print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º mnist_model.pth")
```

è¿™ä¼šåœ¨å½“å‰ç›®å½•ç”Ÿæˆä¸€ä¸ª `model/mnist_model.pth` æ–‡ä»¶ï¼Œä¿å­˜æ¨¡å‹å‚æ•°ã€‚

é‡æ–°æ‰§è¡Œä¸€éï¼š

```
python mnist_train.py
Epoch [1/5], Loss: 0.3826
Epoch [2/5], Loss: 0.1920
Epoch [3/5], Loss: 0.1380
Epoch [4/5], Loss: 0.1108
Epoch [5/5], Loss: 0.0957
âœ… Accuracy on test set: 97.10%
ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ç»å­¦ä¼šè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚
âœ… æ¨¡å‹å·²ä¿å­˜ä¸º mnist_model.pth
```

## ä½¿ç”¨æ¨¡å‹

æ–°å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œä¾‹å¦‚ mnist_predict.pyï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image

# å®šä¹‰å’Œè®­ç»ƒæ—¶ä¸€æ ·çš„æ¨¡å‹ç»“æ„
class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# æ¨¡å‹è¶…å‚æ•°ï¼ˆè¦å’Œè®­ç»ƒæ—¶ä¸€æ ·ï¼‰
input_size = 28 * 28
hidden_size = 128
num_classes = 10

# åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶åŠ è½½æƒé‡
model = NeuralNet(input_size, hidden_size, num_classes)
model.load_state_dict(torch.load("model/mnist_model.pth"))
model.eval()  # è¿›å…¥æ¨ç†æ¨¡å¼

# å›¾åƒé¢„å¤„ç†ï¼šç°åº¦åŒ–ã€ç¼©æ”¾ã€è½¬Tensorã€æ ‡å‡†åŒ–
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # è½¬ä¸ºç°åº¦
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# è¯»å–è¦è¯†åˆ«çš„å›¾ç‰‡è·¯å¾„
img_path = "digit.png"   # ä½ è¦è¯†åˆ«çš„å›¾ç‰‡è·¯å¾„
image = Image.open(img_path).convert('L')  # è½¬ä¸ºç°åº¦
image = transform(image).view(-1, 28*28)

# æ¨¡å‹é¢„æµ‹
with torch.no_grad():
    output = model(image)
    _, predicted = torch.max(output.data, 1)
    print(f"ğŸ§  é¢„æµ‹ç»“æœæ˜¯æ•°å­—ï¼š{predicted.item()}")
```

## å›¾ç‰‡å‡†å¤‡

å›¾ç‰‡è¦æ±‚ï¼š

èƒŒæ™¯æœ€å¥½æ˜¯ç™½è‰²æˆ–é»‘è‰²ï¼›

æ•°å­—åŒºåŸŸè¦æ¸…æ™°ï¼›

å°ºå¯¸ä¸é™ï¼ˆä»£ç ä¼šè‡ªåŠ¨ç¼©æ”¾åˆ° 28Ã—28ï¼‰ï¼›

å¯ä»¥ç”¨æ‰‹æœºæ‹ç…§ç„¶åè£å‰ªæˆæ­£æ–¹å½¢ã€‚

ä¿å­˜æˆ digit.png æ”¾åœ¨ä¸ä½ çš„ mnist_predict.py åŒç›®å½•ä¸‹ã€‚

## æµ‹è¯•

å‘ç°ç»™æ•°å­— 7 è¯†åˆ«æˆäº† 0ï¼Œåªèƒ½è¯´ä¹Ÿä¸æ˜¯é‚£ä¹ˆå‡†ç¡®ã€‚

```
> python mnist_predict.py
ğŸ§  é¢„æµ‹ç»“æœæ˜¯æ•°å­—ï¼š0
```

# ä¸ºä»€ä¹ˆç¿»è½¦äº†ï¼Ÿ

æ®µä»£ç ç¡®å®æ˜¯ MNIST å…¥é—¨ç‰ˆ â€”â€” ç®€å•æ˜“æ‡‚ï¼Œä½†å®ƒçš„èƒ½åŠ›æœ‰é™ï¼š

å®ƒåªç”¨äº†ä¸¤å±‚å…¨è¿æ¥ç½‘ç»œï¼Œæ²¡æœ‰å·ç§¯å±‚ï¼ˆCNNï¼‰ï¼Œæ‰€ä»¥å½“ä½ æ‹¿â€œç°å®æˆªå›¾â€å»è¯†åˆ«ï¼Œå°±å¾ˆå®¹æ˜“ç¿»è½¦ã€‚

MNIST è®­ç»ƒé›†çš„å›¾ç‰‡æ˜¯è¿™æ ·çš„ï¼š

é»‘åº•ç™½å­—

å¹²å‡€ã€å±…ä¸­ã€28Ã—28 å°ºå¯¸

è€Œä½ æˆªå›¾çš„æ•°å­—å›¾ç‰‡å¯èƒ½æ˜¯ï¼š

ç™½åº•é»‘å­—ï¼ˆåè‰²ï¼‰

èƒŒæ™¯æ‚ã€ä½ç½®å

å°ºå¯¸ä¸ä¸€æ ·ï¼ˆä¸æ˜¯ 28Ã—28ï¼‰

æœ‰ç°åº¦ã€å™ªå£°æˆ–è¾¹ç¼˜æ¨¡ç³Š

## å‡çº§ç‰ˆæœ¬ CNN

### è®­ç»ƒç‰ˆæœ¬

- mnist_train_cnn.py

```py
# mnist_train_cnn.py
# ä¸€ä¸ªæ›´å¼ºçš„ CNN æ¨¡å‹ï¼Œç”¨äºæ‰‹å†™æ•°å­—è¯†åˆ«

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms


def main():
    # 1ï¸âƒ£ æ•°æ®é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # 2ï¸âƒ£ MNIST æ•°æ®é›†
    train_dataset = torchvision.datasets.MNIST(
        root='./data', train=True, download=True, transform=transform)
    test_dataset = torchvision.datasets.MNIST(
        root='./data', train=False, download=True, transform=transform)

    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=64, shuffle=False)

    # 3ï¸âƒ£ å®šä¹‰å·ç§¯ç¥ç»ç½‘ç»œ
    class CNN(nn.Module):
        def __init__(self):
            super(CNN, self).__init__()
            self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
            self.pool = nn.MaxPool2d(2, 2)
            self.dropout = nn.Dropout(0.25)

            # ä¸´æ—¶åˆ›å»ºä¸€ä¸ªå‡è¾“å…¥è‡ªåŠ¨æ¨å¯¼ flatten å¤§å°
            x = torch.zeros(1, 1, 28, 28)
            x = self._forward_features(x)
            flatten_size = x.view(1, -1).size(1)

            self.fc1 = nn.Linear(flatten_size, 128)
            self.fc2 = nn.Linear(128, 10)

        def _forward_features(self, x):
            x = torch.relu(self.conv1(x))
            x = self.pool(torch.relu(self.conv2(x)))
            x = self.dropout(x)
            return x

        def forward(self, x):
            x = self._forward_features(x)
            x = x.view(x.size(0), -1)
            x = torch.relu(self.fc1(x))
            x = self.fc2(x)
            return x

    model = CNN()

    # 4ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 5ï¸âƒ£ è®­ç»ƒæ¨¡å‹
    num_epochs = 5
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            outputs = model(images)
            loss = criterion(outputs, labels)
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

    # 6ï¸âƒ£ æµ‹è¯•å‡†ç¡®ç‡
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"âœ… Accuracy on test set: {100 * correct / total:.2f}%")

    # ä¿å­˜æ¨¡å‹
    torch.save(model.state_dict(), "model/mnist_cnn.pth")
    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ° model/mnist_cnn.pth")


if __name__ == "__main__":
    main()
```

æ‰§è¡Œè®­ç»ƒ

```
> python mnist_train_cnn.py
Epoch [1/5], Loss: 0.1438
Epoch [2/5], Loss: 0.0460
Epoch [3/5], Loss: 0.0300
Epoch [4/5], Loss: 0.0203
Epoch [5/5], Loss: 0.0157
âœ… Accuracy on test set: 98.74%
ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ä¿å­˜åˆ° model/mnist_cnn.pth
```

æ„Ÿè§‰è¿™ä¸ªè¦æ¯”ç¬¬ä¸€ç§æ–¹å¼æ…¢äº†ä¸å°‘ã€‚

### æ¨ç†è„šæœ¬ï¼ˆå•ä¸ªå›¾ç‰‡é¢„æµ‹ï¼‰

- mnist_cnn_predict.pyï¼š

```python
import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms

# æ¨¡å‹ç»“æ„éœ€ä¸è®­ç»ƒæ—¶ä¸€è‡´
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = self.pool(x)              # ä¸€æ¬¡æ± åŒ–ï¼Œ28â†’14
        x = self.dropout(x)
        x = x.view(-1, 64 * 14 * 14)  # æ”¹æˆå¯¹åº”çš„ç»´åº¦
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# åŠ è½½æ¨¡å‹
model = CNN()
model.load_state_dict(torch.load("model/mnist_cnn.pth"))
model.eval()

# å›¾ç‰‡é¢„å¤„ç†
transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize((0.5,), (0.5,))
])

# ä½ çš„æˆªå›¾è·¯å¾„
img_path = "digit.png"
image = Image.open(img_path).convert("RGB")
image = transform(image).unsqueeze(0)

# æ¨ç†
with torch.no_grad():
    outputs = model(image)
    _, predicted = torch.max(outputs, 1)
    print(f"ğŸ§  æ¨¡å‹é¢„æµ‹ç»“æœ: {predicted.item()}")
```

æ‰§è¡Œæµ‹è¯•ï¼š

```
ğŸ§  æ¨¡å‹é¢„æµ‹ç»“æœ: 7
```

è¿™æ¬¡å¯¹äº†ã€‚

åç»­æˆ‘ä»¬å¯ä»¥ä»ç†è®ºè§’åº¦çœ‹ä¸€ä¸‹ä¸ºä»€ä¹ˆ CNN çš„æ•ˆæœæ›´å¥½ã€‚

# v3-å®æ—¶æ‰‹å†™æ•°å­—è¯†åˆ«

## æ€è·¯

ä¸Šé¢çš„ CNN å·²ç»å¯ä»¥è¯†åˆ«æ•°å­—ï¼Œä½†æ˜¯ä¸å¤Ÿæœ‰è¶£ã€‚

æˆ‘ä»¬å¯ä»¥å®ç°ä¸€ä¸ªç”»æ¿ï¼Œæ‰‹åŠ¨å†™æ•°å­—ï¼Œç„¶åè®©å…¶é¢„æµ‹ã€‚

## å®‰è£…ä¾èµ–

å¯ä»¥é€šè¿‡ opencv æ„å»ºä¸€ä¸ªç”»æ¿

æˆ‘ä»¬å…ˆå®‰è£…ä¸€ä¸‹ä¾èµ–

```
pip install torch torchvision opencv-python pillow numpy
```

## å®ç°

```python
import cv2
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms

# ======================
# âœ… 1. å®šä¹‰ CNN æ¨¡å‹ç»“æ„ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
# ======================
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        # æ³¨æ„æ˜¯ 64 * 14 * 14ï¼ˆå› ä¸ºåªæ± åŒ–ä¸€æ¬¡ï¼‰
        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.dropout(x)
        x = x.view(-1, 64 * 14 * 14)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x


# ======================
# âœ… 2. åŠ è½½æ¨¡å‹
# ======================
model = CNN()
model.load_state_dict(torch.load("model/mnist_cnn.pth", map_location="cpu"))
model.eval()

# ======================
# âœ… 3. å›¾åƒé¢„å¤„ç†å‡½æ•°
# ======================
def preprocess_image_for_mnist(image):
    # è½¬æˆç°åº¦
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    # åè‰²ï¼šç™½åº•é»‘å­— -> é»‘åº•ç™½å­—
    gray = cv2.bitwise_not(gray)
    # è½¬ PIL
    pil = Image.fromarray(gray)
    # å…¼å®¹ Pillow æ–°æ—§ç‰ˆæœ¬
    try:
        resample = Image.Resampling.LANCZOS
    except AttributeError:
        resample = Image.ANTIALIAS
    pil = pil.resize((28, 28), resample)
    # å˜æˆ Tensor
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    tensor = transform(pil).unsqueeze(0)
    return tensor


# ======================
# âœ… 4. OpenCV ç»˜å›¾çª—å£
# ======================
canvas = np.ones((280, 280, 3), dtype=np.uint8) * 255
drawing = False
last_point = None

def draw(event, x, y, flags, param):
    global drawing, last_point
    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        last_point = (x, y)
    elif event == cv2.EVENT_MOUSEMOVE and drawing:
        cv2.line(canvas, last_point, (x, y), (0, 0, 0), 12)
        last_point = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        last_point = None

cv2.namedWindow("MNIST Draw Board")
cv2.setMouseCallback("MNIST Draw Board", draw)

print("ğŸ¨ Draw a digit with the mouse.")
print("âœ… Press 's' to save & predict.")
print("ğŸ§¹ Press 'c' to clear.")
print("âŒ Press 'q' to quit.")

# ======================
# âœ… 5. ä¸»å¾ªç¯
# ======================
while True:
    cv2.imshow("MNIST Draw Board", canvas)
    key = cv2.waitKey(1) & 0xFF

    if key == ord('q'):
        break

    elif key == ord('c'):
        canvas[:] = 255  # æ¸…ç©ºç”»æ¿

    elif key == ord('s'):
        # æ‹·è´å½“å‰ç”»å¸ƒ
        img_for_pred = canvas.copy()

        # é¢„å¤„ç†æˆæ¨¡å‹è¾“å…¥
        tensor = preprocess_image_for_mnist(img_for_pred)

        # æ¨¡å‹é¢„æµ‹
        with torch.no_grad():
            outputs = model(tensor)
            _, predicted = torch.max(outputs, 1)
            result = predicted.item()

        print(f"ğŸ§  Predicted digit: {result}")

        # åœ¨çª—å£ä¸Šæ˜¾ç¤ºè¯†åˆ«ç»“æœï¼ˆä¿ç•™å½“å‰ç”»é¢ï¼‰
        display = img_for_pred.copy()
        cv2.putText(display, f"RES: {result}", (10, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 255), 3)

        # æ˜¾ç¤ºé¢„æµ‹ç»“æœçª—å£
        cv2.imshow("MNIST Draw Board", display)

        # ç­‰å¾… 2 ç§’ï¼Œè®©ä½ èƒ½çœ‹æ¸…ç»“æœ
        key2 = cv2.waitKey(2000) & 0xFF
        if key2 == ord('q'):
            break
        elif key2 == ord('c'):
            canvas[:] = 255  # æ¸…ç©º
        else:
            # 2 ç§’åå›åˆ°åŸç”»å¸ƒ
            cv2.imshow("MNIST Draw Board", canvas)


cv2.destroyAllWindows()
```

æµ‹è¯•

```
python mnist_draw_predict.py
```

ä½†æ˜¯å®é™…å‘ç°é¢„æµ‹çš„æ•ˆæœä¸€èˆ¬ã€‚


## ä¸ºä»€ä¹ˆä¸é‚£ä¹ˆå‡†ç¡®å‘¢ï¼Ÿ

çœŸæ­£çš„åŸå› åœ¨äºï¼š**ä½ çš„æ‰‹å†™å›¾ç‰‡åˆ†å¸ƒå’Œ MNIST çš„è®­ç»ƒæ•°æ®åˆ†å¸ƒä¸ä¸€æ ·**ã€‚

## ğŸ§  ä¸€ã€ä¸ºä»€ä¹ˆä½ çš„æ‰‹å†™æ¨¡å‹è¯†åˆ«ä¸å‡†ï¼Ÿ

æˆ‘ä»¬æ¥æ‹†è§£ä¸€ä¸‹å·®å¼‚ï¼š

### 1ï¸âƒ£ èƒŒæ™¯ä¸åŒ

* MNIST è®­ç»ƒé›†çš„å›¾ç‰‡æ˜¯ **çº¯é»‘èƒŒæ™¯ + ç™½è‰²æ•°å­—**ã€‚
* ä½ åœ¨ç”»å¸ƒä¸Šæ˜¯ **ç™½èƒŒæ™¯ + é»‘è‰²æ•°å­—**ã€‚
* è™½ç„¶ä½ åšäº† `Normalize((0.5,), (0.5,))`ï¼Œä½†é¢œè‰²æ–¹å‘åäº†ã€‚

> âœ… è§£å†³æ–¹æ³•ï¼šåœ¨é¢„æµ‹å‰åè½¬å›¾åƒé¢œè‰²ï¼š
>
> ```python
> pil = ImageOps.invert(pil)
> ```
>
> æ”¾åœ¨ä½  `preprocess_image_for_mnist()` å‡½æ•°é‡Œã€‚

---

### 2ï¸âƒ£ æ•°å­—å¤ªé è¾¹ or ä¸å±…ä¸­

MNIST çš„æ•°å­—æ˜¯å±…ä¸­åœ¨ 28x28 å›¾åƒä¸­ï¼Œè€Œä½ ç”»çš„æ•°å­—å¯èƒ½åä¸Šã€åå·¦æˆ–å¤ªå¤§ã€‚
CNN å¯¹â€œç©ºé—´ä½ç½®â€æ˜¯ç›¸å¯¹æ•æ„Ÿçš„ï¼Œæ‰€ä»¥ï¼š

* åç§»ä¸€ç‚¹ï¼Œç‰¹å¾å›¾åˆ†å¸ƒå°±å˜äº†ï¼›
* æ¨¡å‹è®¤ä¸ºè¿™æ˜¯å¦ä¸€ä¸ªâ€œç±»â€ã€‚

> âœ… è§£å†³æ–¹æ³•ï¼š
>
> * åœ¨é¢„å¤„ç†æ—¶åšä¸€ä¸ª **è‡ªåŠ¨å±…ä¸­**ï¼š
>
>   * æŠŠæ‰‹å†™å›¾åƒäºŒå€¼åŒ–ï¼›
>   * æ‰¾å‡ºæ•°å­—çš„è¾¹ç•Œæ¡†ï¼›
>   * æŠŠå®ƒè£å‰ªå‡ºæ¥å¹¶å±…ä¸­æ”¾å› 28x28ã€‚
>
> æˆ‘å¯ä»¥å¸®ä½ å†™è¿™ä¸ªå¢å¼ºç‰ˆé¢„å¤„ç†ã€‚

---

### 3ï¸âƒ£ çº¿æ¡ç²—ç»†ã€é£æ ¼ä¸åŒ

* MNIST çš„ç¬”è¿¹æ˜¯æ‰«æè¿‡çš„ï¼Œéå¸¸å¹³æ»‘ã€çº¿æ¡è¾ƒç²—ï¼›
* ä½ ç”¨é¼ æ ‡ç”»çš„çº¿å¯èƒ½ï¼š

  * è¿‡ç»†ï¼›
  * é”¯é½¿æ˜æ˜¾ï¼›
  * ä¸è¿ç»­ã€‚

> âœ… è§£å†³æ–¹æ³•ï¼š
>
> * æŠŠçº¿æ¡ç”»ç²—ä¸€ç‚¹ï¼ˆæ¯”å¦‚ `cv2.line(..., thickness=20)`ï¼‰ï¼›
> * æˆ–åœ¨é¢„å¤„ç†æ—¶æ¨¡ç³Šä¸€ä¸‹ï¼ˆ`cv2.GaussianBlur`ï¼‰ï¼›
> * ç”šè‡³å¯ä»¥è®­ç»ƒæ—¶åŠ ä¸Šâ€œé£æ ¼å™ªå£°å¢å¼ºâ€æ¥æå‡æ³›åŒ–ã€‚

---

### 4ï¸âƒ£ æ¨¡å‹æ˜¯â€œåœ¨ MNIST ä¸Šè®­ç»ƒçš„â€

MNIST è™½ç„¶ç»å…¸ï¼Œä½†å¤ªè€ã€å¤ªå¹²å‡€ã€‚

ä½ çš„æ‰‹å†™æ•°æ®å…¶å®æ˜¯ä¸€ä¸ªã€Œæ–°çš„åˆ†å¸ƒã€ï¼Œ

æ¨¡å‹æ²¡è§è¿‡è¿™ç§é£æ ¼ï¼Œå°±ä¼šè¯¯åˆ¤ã€‚

> âœ… æ ¹æœ¬æ€§è§£å†³æ–¹æ¡ˆï¼š
>
> * è‡ªå·± **æ”¶é›†æ‰‹å†™æ•°æ®**ï¼ˆæ¯”å¦‚ä½ ç”» 100 å¼ æ•°å­—å›¾ï¼‰ï¼›
> * ç”¨è¿™äº›æ•°æ®å† **å¾®è°ƒï¼ˆfine-tuneï¼‰æ¨¡å‹**ï¼›
> * æ¨¡å‹ç«‹åˆ»ä¼šå¯¹ä½ çš„ç¬”è¿¹é£æ ¼æ›´æ•æ„Ÿã€‚


## ä¼˜åŒ–ç‰ˆæœ¬

```python
import cv2
import numpy as np
import torch
import torch.nn as nn
from PIL import Image
import torchvision.transforms as transforms

# ======================
# âœ… 1. å®šä¹‰ CNN æ¨¡å‹ç»“æ„ï¼ˆä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
# ======================
class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.pool = nn.MaxPool2d(2, 2)
        self.dropout = nn.Dropout(0.25)
        self.fc1 = nn.Linear(64 * 14 * 14, 128)
        self.fc2 = nn.Linear(128, 10)

    def forward(self, x):
        x = torch.relu(self.conv1(x))
        x = torch.relu(self.conv2(x))
        x = self.pool(x)
        x = self.dropout(x)
        x = x.view(-1, 64 * 14 * 14)
        x = torch.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# ======================
# âœ… 2. åŠ è½½æ¨¡å‹
# ======================
model = CNN()
model.load_state_dict(torch.load("model/mnist_cnn.pth", map_location="cpu"))
model.eval()

# ======================
# âœ… 3. å›¾åƒé¢„å¤„ç†å‡½æ•°
# ======================
def preprocess_image_for_mnist(image):
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    gray = cv2.bitwise_not(gray)
    pil = Image.fromarray(gray)
    try:
        resample = Image.Resampling.LANCZOS
    except AttributeError:
        resample = Image.ANTIALIAS
    pil = pil.resize((28, 28), resample)
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    tensor = transform(pil).unsqueeze(0)
    return tensor

# ======================
# âœ… 4. ç»˜å›¾çª—å£è®¾ç½®
# ======================
canvas = np.ones((280, 280, 3), dtype=np.uint8) * 255
drawing = False
last_point = None
prediction_text = None  # ä¿å­˜é¢„æµ‹ç»“æœä»¥ä¾¿æ˜¾ç¤º

def draw(event, x, y, flags, param):
    global drawing, last_point
    if event == cv2.EVENT_LBUTTONDOWN:
        drawing = True
        last_point = (x, y)
    elif event == cv2.EVENT_MOUSEMOVE and drawing:
        cv2.line(canvas, last_point, (x, y), (0, 0, 0), 12)
        last_point = (x, y)
    elif event == cv2.EVENT_LBUTTONUP:
        drawing = False
        last_point = None

cv2.namedWindow("ğŸ–Œ MNIST Draw Board", cv2.WINDOW_NORMAL)
cv2.setMouseCallback("ğŸ–Œ MNIST Draw Board", draw)

print("ğŸ¨ ç”¨é¼ æ ‡å·¦é”®ç”»æ•°å­—")
print("âœ… æŒ‰ 's' è¯†åˆ«æ•°å­—")
print("ğŸ§¹ æŒ‰ 'c' æ¸…ç©ºç”»å¸ƒ")
print("âŒ æŒ‰ 'q' é€€å‡º")

# ======================
# âœ… 5. ä¸»å¾ªç¯
# ======================
while True:
    # å¦‚æœæœ‰é¢„æµ‹ç»“æœï¼Œåˆ™å åŠ æ˜¾ç¤ºåœ¨ç”»å¸ƒä¸Š
    display = canvas.copy()
    if prediction_text is not None:
        cv2.putText(display, f"RES: {prediction_text}", (10, 60),
                    cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3)

    cv2.imshow("ğŸ–Œ MNIST Draw Board", display)
    key = cv2.waitKey(10) & 0xFF

    if key == ord('q'):
        break

    elif key == ord('c'):
        canvas[:] = 255
        prediction_text = None

    elif key == ord('s'):
        img_for_pred = canvas.copy()
        tensor = preprocess_image_for_mnist(img_for_pred)
        with torch.no_grad():
            outputs = model(tensor)
            _, predicted = torch.max(outputs, 1)
            prediction_text = str(predicted.item())
            print(f"ğŸ§  Predicted digit: {prediction_text}")

cv2.destroyAllWindows()
```

æ•ˆæœè¿˜è¡Œ

* any list
{:toc}