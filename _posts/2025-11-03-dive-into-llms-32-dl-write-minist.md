---
layout: post
title: dive-into-llms-31-å¦‚ä½•å…¥é—¨æ·±åº¦å­¦ä¹ 
date: 2025-11-03 20:40:12 +0800
categories: [AI]
tags: [ai, learn-note]
published: true
---



# å‡†å¤‡å·¥ä½œ

## ä¸‹è½½ python

https://www.python.org/ftp/python/3.12.6/python-3.12.6-amd64.exe

ä¸‹è½½åç›´æ¥å®‰è£…ï¼Œå‹¾é€‰ä¸Š ADD PATH é€‰é¡¹ã€‚

## å®‰è£…

```sh
pip install torch torchvision
```

## ç¼–ç 

- mnist_train.py

```py
# mnist_train.py
# ä¸€ä¸ªæœ€ç®€å•çš„ PyTorch ç¥ç»ç½‘ç»œï¼šæ‰‹å†™æ•°å­—è¯†åˆ«

import torch
import torch.nn as nn
import torch.optim as optim
import torchvision
import torchvision.transforms as transforms


def main():
    # 1ï¸âƒ£ æ•°æ®é¢„å¤„ç†ï¼šæŠŠå›¾ç‰‡è½¬æˆ tensor å¹¶å½’ä¸€åŒ–
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])

    # 2ï¸âƒ£ ä¸‹è½½å¹¶åŠ è½½ MNIST æ•°æ®é›†
    train_dataset = torchvision.datasets.MNIST(
        root='./data', train=True, download=True, transform=transform)
    test_dataset = torchvision.datasets.MNIST(
        root='./data', train=False, download=True, transform=transform)

    train_loader = torch.utils.data.DataLoader(
        train_dataset, batch_size=64, shuffle=True)
    test_loader = torch.utils.data.DataLoader(
        test_dataset, batch_size=64, shuffle=False)

    # 3ï¸âƒ£ å®šä¹‰ä¸€ä¸ªç®€å•çš„ç¥ç»ç½‘ç»œ
    class SimpleNN(nn.Module):
        def __init__(self):
            super(SimpleNN, self).__init__()
            self.flatten = nn.Flatten()  # æŠŠ 28x28 å±•å¼€æˆä¸€ç»´
            self.fc1 = nn.Linear(28 * 28, 128)
            self.relu = nn.ReLU()
            self.fc2 = nn.Linear(128, 10)  # 10 ä¸ªè¾“å‡ºç±»åˆ«ï¼ˆæ•°å­— 0~9ï¼‰

        def forward(self, x):
            x = self.flatten(x)
            x = self.fc1(x)
            x = self.relu(x)
            x = self.fc2(x)
            return x

    model = SimpleNN()

    # 4ï¸âƒ£ å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    # 5ï¸âƒ£ è®­ç»ƒæ¨¡å‹
    num_epochs = 5
    for epoch in range(num_epochs):
        running_loss = 0.0
        for images, labels in train_loader:
            # å‰å‘ä¼ æ’­
            outputs = model(images)
            loss = criterion(outputs, labels)

            # åå‘ä¼ æ’­å’Œä¼˜åŒ–
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}")

    # 6ï¸âƒ£ æµ‹è¯•æ¨¡å‹å‡†ç¡®ç‡
    correct = 0
    total = 0
    with torch.no_grad():
        for images, labels in test_loader:
            outputs = model(images)
            _, predicted = torch.max(outputs.data, 1)
            total += labels.size(0)
            correct += (predicted == labels).sum().item()

    print(f"âœ… Accuracy on test set: {100 * correct / total:.2f}%")

    print("ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ç»å­¦ä¼šè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚")


if __name__ == "__main__":
    main()
```


## è¿è¡Œ

```
python mnist_train.py
```

## æµ‹è¯•æ•ˆæœ

æ‰§è¡Œåçš„æµ‹è¯•æ•ˆæœ

```
>python mnist_train.py
100.0%
100.0%
100.0%
100.0%
Epoch [1/5], Loss: 0.3926
Epoch [2/5], Loss: 0.2096
Epoch [3/5], Loss: 0.1493
Epoch [4/5], Loss: 0.1209
Epoch [5/5], Loss: 0.1010
âœ… Accuracy on test set: 96.60%
ğŸ‰ è®­ç»ƒå®Œæˆï¼æ¨¡å‹å·²ç»å­¦ä¼šè¯†åˆ«æ‰‹å†™æ•°å­—ã€‚
```


# å¦‚ä½•ä½¿ç”¨

## è¯´æ˜

æ¨¡å‹çš„è®­ç»ƒä¹‹åï¼Œæˆ‘ä»¬å¯ä»¥ä¿å­˜ä¹‹åä½¿ç”¨ã€‚

## ä¿å­˜

è®­ç»ƒç»“æŸååŠ ä¸Š

```java
torch.save(model.state_dict(), "mnist_model.pth")
print("âœ… æ¨¡å‹å·²ä¿å­˜ä¸º mnist_model.pth")
```

è¿™ä¼šåœ¨å½“å‰ç›®å½•ç”Ÿæˆä¸€ä¸ª mnist_model.pth æ–‡ä»¶ï¼Œä¿å­˜æ¨¡å‹å‚æ•°ã€‚

## ä½¿ç”¨æ¨¡å‹

æ–°å»ºä¸€ä¸ª Python æ–‡ä»¶ï¼Œä¾‹å¦‚ predict.pyï¼Œå†…å®¹å¦‚ä¸‹ï¼š

```python
import torch
import torch.nn as nn
import torchvision.transforms as transforms
from PIL import Image

# å®šä¹‰å’Œè®­ç»ƒæ—¶ä¸€æ ·çš„æ¨¡å‹ç»“æ„
class NeuralNet(nn.Module):
    def __init__(self, input_size, hidden_size, num_classes):
        super(NeuralNet, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_size)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(hidden_size, num_classes)

    def forward(self, x):
        out = self.fc1(x)
        out = self.relu(out)
        out = self.fc2(out)
        return out

# æ¨¡å‹è¶…å‚æ•°ï¼ˆè¦å’Œè®­ç»ƒæ—¶ä¸€æ ·ï¼‰
input_size = 28 * 28
hidden_size = 100
num_classes = 10

# åˆ›å»ºæ¨¡å‹å®ä¾‹å¹¶åŠ è½½æƒé‡
model = NeuralNet(input_size, hidden_size, num_classes)
model.load_state_dict(torch.load("mnist_model.pth"))
model.eval()  # è¿›å…¥æ¨ç†æ¨¡å¼

# å›¾åƒé¢„å¤„ç†ï¼šç°åº¦åŒ–ã€ç¼©æ”¾ã€è½¬Tensorã€æ ‡å‡†åŒ–
transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),  # è½¬ä¸ºç°åº¦
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,))
])

# è¯»å–è¦è¯†åˆ«çš„å›¾ç‰‡è·¯å¾„
img_path = "digit.png"   # ä½ è¦è¯†åˆ«çš„å›¾ç‰‡è·¯å¾„
image = Image.open(img_path).convert('L')  # è½¬ä¸ºç°åº¦
image = transform(image).view(-1, 28*28)

# æ¨¡å‹é¢„æµ‹
with torch.no_grad():
    output = model(image)
    _, predicted = torch.max(output.data, 1)
    print(f"ğŸ§  é¢„æµ‹ç»“æœæ˜¯æ•°å­—ï¼š{predicted.item()}")
```

## å›¾ç‰‡å‡†å¤‡

å›¾ç‰‡è¦æ±‚ï¼š

èƒŒæ™¯æœ€å¥½æ˜¯ç™½è‰²æˆ–é»‘è‰²ï¼›

æ•°å­—åŒºåŸŸè¦æ¸…æ™°ï¼›

å°ºå¯¸ä¸é™ï¼ˆä»£ç ä¼šè‡ªåŠ¨ç¼©æ”¾åˆ° 28Ã—28ï¼‰ï¼›

å¯ä»¥ç”¨æ‰‹æœºæ‹ç…§ç„¶åè£å‰ªæˆæ­£æ–¹å½¢ã€‚

ä¿å­˜æˆ digit.png æ”¾åœ¨ä¸ä½ çš„ predict.py åŒç›®å½•ä¸‹ã€‚











* any list
{:toc}