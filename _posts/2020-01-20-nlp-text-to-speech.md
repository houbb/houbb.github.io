---
layout: post
title: NLP TTS 文本转语音
date:  2020-1-20 10:09:32 +0800
categories: [NLP]
tags: [nlp, tts, sh]
published: true
---

# 基本原理

1. 从文本中攫取足量信息至少我们要知道需要合成什么单词，以及单词顺序吧。

这就需要一套语言学标注系统，先给文本分词，再把文本转换成只有单词串起来的句子（例如把 1989 转成 nineteen eighty nine）后，再给这句话标注音素级别（上一个音素／下一个音素）、音节级别（单词的第几个音节）、单词级别（词性／在句子中的位置）等对语音合成有帮助的信息。

2. 生成波形

两种思路。

一种思路是，既然我们要生成语音，我们做个语音库，从库里面找找有没有合适的 speech unit，拼起来就好了呗。

第二种思路是，我们做个语音库，用统计模型学习到每个音到底怎么发的，再根据学出来的特征，复原出来，不就好了呗。

无论哪种思路，总之要先讲讲我们生成语音的原料，也就是语音库。

语音库是大量文本和其对应音频的 pairs。

为了实现更精细的语音合成，我们会用语音学标注系统自动标一遍文本。

再用类似语音识别的工具得到音素和音频时间上的切分。

这样你就会得到，语音库里的每一个音素，它在音频中的起止时间（即音素本身的 waveform），以及其对应的语言学标注。

第一种思路，基于拼接的语音合成系统。我们用同样的语言学标注系统跑一遍输入文本，得到了一串语言学标注。

然后，接下来就该从库里面找，有没有不仅在语言学特征上，还在声学特征上也是类似的音素 waveform。找到了，拼起来，找不到，看看退而求其次的音素，就这样，合成一句句子。缺点是，如果库里的音素切分出错、语言学标注出错，那显然它最后会找错。优点是，听起来的确很自然，毕竟是真人的声音。

第二种思路，基于参数的语音合成系统。它其实是一个文本抽象成语音学特征，再用统计学模型学习出来语音学特征和其声学特征的对应关系后，再从预测出来的声学特征还原成 waveform 的过程。

核心是个预测问题，有若干统计模型可以解决，目前主流是用神经网络用来预测。

然后用声码器 (vocoder) 生成波形，实现特征到 waveform 这最后一步。

这种思路缺点是，听起来不自然，因为最后输出的是用声码器合成的声音，毕竟有损失。

优点是，对于语音库里的标注错误不敏感，因为预测时候是学的是一个统计模型嘛。

最后呢，还有取两种思路的优点，混合的语音合成解决方案。

用基于参数的语音合成系统预测声学上最匹配的音素后，再从库里把它找出来。

业界基本上是用这种，合成效果融合两种思路的长处，效果最优。

另外，其实还有第三种思路。

用神经网络直接学习文本端到声学特征这一端的对应关系，这就直接省去了第一步，不再需要语言学标注系统标注文本了。

这就是 Google 的 Tacotron。不过最后还是要需要声码器。

再或者，用神经网络直接学习语言学标注端到帧级别的 waveform 端的对应关系，这就直接省去了最后一步，不再需要声码器了。这就是 DeepMind 的 WaveNet。不过第一步还是需要语言学标注系统。

会不会未来的语音合成，就直接是学习，纯文本端，直接到，帧级别的 waveform 的对应关系呢？喵，立一个 flag。

为了写得平易近人，我特意一带而过了非常多的坑……而每个坑都会坑死人。

比如，语料库怎么筛选文本才能让语音合成系统效果最好？语料库标注质量怎么保证？

选哪种语音单位作为合成的最小单位？

语言学标注系统怎么实现？

到底要标注几层语言学标注才算足量？

对于第一种思路，从库里找匹配的音素时，怎样算和目标音素语音学上匹配？

怎样才算和目标音素声学上匹配？最后搜索的时候，怎么定义这两方面都最相似？

对于第二种思路，得到语言学标注后，到底需要哪些特征向量？特征向量怎么最优表示？

同理，到底需要哪些声学特征向量？怎么最优表示？怎么获得静态声学特征的同时也捕捉动态声学特征？

训练预测模型的时候，用什么神经网络结构比较好？用什么声码器？And the questions run on and on...

对语音合成感兴趣的同学可以先看最基础的 Paul Taylor 的 [Text-to-speech Synthesis](https://www.amazon.com/Text-Speech-Synthesis-Paul-Taylor/dp/0521899273) ，里面基本涵盖了这两种思路的技术细节。

如果要 follow 最新进展，还是要看 paper 呢。

# 开源项目

[marytts](https://github.com/marytts/marytts)

[FreeTTS](https://freetts.sourceforge.io/docs/index.php)

# 参考资料

## 核心原理

[语音合成 TTS (Text-To-Speech) 的原理是什么？](https://www.zhihu.com/question/26815523?sort=created)

[TTS背后的技术原理——前端和后端系统](https://www.sohu.com/a/333140126_255990)

## 基本资料

[7 个开源的TTS（文本转语音）系统推荐](https://www.iteye.com/news/23832)

[java通过jacob实现文本转语音修改语音库为男声](https://blog.csdn.net/ming19951224/article/details/81046488)

[离线语音合成使用——科大讯飞or云知音or百度语音](https://blog.csdn.net/qq_34855745/article/details/80292379)

* any list
{:toc}