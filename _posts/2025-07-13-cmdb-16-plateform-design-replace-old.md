---
layout: post
title: cmdb-16-CMDB 如何取代旧的系统？
date: 2025-7-13 14:12:33 +0800
categories: [CMDB]
tags: [cmdb, sh]
published: true
---


# chat

## 如果公司已经有一个 cmdb 系统，但是苟延残喘，也不好直接去掉。让你新建一个更好的平台，你会采取怎么方案逐步取代，为什么？

非常现实也非常常见的场景 —— 老旧 CMDB 停滞、弃之可惜、留之阻碍推进。

把新平台平滑替换旧平台，要既**稳**又**快**，

核心思路是：**并存 → 同步 → 渐进切换（strangler / façade）→ 收割**。

下面给出一套可直接落地、工程化、降低风险的逐步替代方案（含技术手段、组织配套、度量指标与回滚策略），并说明为什么每一步要这样做。

---

# 核心原则（先说为什么）

1. **最小风险原则**：任何一次变动都不能中断消费方业务（监控、发布、告警等）。
2. **逐步验证原则**：先小范围验证功能和数据一致性，再扩大范围。
3. **双向可控同步**：新旧系统数据要能双向对齐直到完全迁移。
4. **最短可回退路径**：每步都可快速回滚到旧系统状态。
5. **责任与可观测**：清晰 owner、可观测的 KPI（一致率、延迟、错误率）。

---

# 高层迁移策略概览（一句话）

采用 **“脖子树（Strangler Fig）+ 同步层（Adapter / Canonical Model）+ 事件驱动”** 的渐进迁移：逐个消费者/功能模块切到新平台，直到旧系统无消费者后退役。

---

# 详细分步方案（可操作）

## 阶段 0 — 评估与准备（先干这块再动手）

要做的事（交付件）：

* 列出**所有依赖 CMDB 的上下游系统**（监控、告警、发布、ITSM、自动化、财务…），并记录调用方式（API、DB查询、导出表、手工报表）。
* 统计旧 CMDB 的**核心数据模型**（CI 类型、字段、关系），并识别差异。
* 识别关键 SLA（哪些接口必须 100% 可用、哪些可容忍延迟/失一致）。
* 确定团队和负责人（数据所有者、迁移 owner、回滚 owner、监控 owner）。
* 定义**Key Success Metrics**（例：CI 一致率 >= 99%，查询延迟 < X，错误率 < Y，消费方切换成功率）。

为什么：全面摸清上下游和数据模型是降低未知风险的根本。

---

## 阶段 1 — 设计中间层（Canonical Model + Adapter）

要做的事：

* 设计**统一语义模型（Canonical CI Model）**：把旧 CMDB 和新 CMDB 的字段/关系映射到统一模型（包含字段映射表、转换规则、数据质量规则）。
* 构建 **同步适配层（Adapter / Integration Layer）**：

  * 从旧 CMDB 拉数据并转换为 canonical model（ETL / CDC）。
  * 从新 CMDB 同步数据到 canonical model（或反向）。
  * 暴露统一 API（REST/GraphQL）给消费方，API 背后可配置读写路由（指向旧/新）。
* 用事件总线（Kafka / MQ / EventGrid）做变更事件的可靠传递，支持幂等消费与重放。

为什么：中间层把语义差异隔离开，消费方只对统一接口编程，大幅降低改动面；事件总线保证变更可追溯、可重放。

---

## 阶段 2 — 被动同步验证（Shadow Sync / Read-through）

要做的事：

* 实现**单向 Shadow 写或读透**：

  * Shadow Write（双写）：当上游系统发生变更，写入旧 CMDB 的同时写入新 CMDB（或写入中间层），先不切消费方；或者
  * Read-through（读优先旧）：消费方读请求仍指向旧系统，但中间层在后台用相同请求去新系统做对比校验。
* 开启**一致性比对与报表**：定期对比旧/新 CI 数据差异（字段级、关系级），量化差异并生成修复清单。
* 修复数据差异：自动修复（若有确定规则）或人工审核修复。

为什么：双写/读透能让新系统在真实业务数据与负载下“热身”，并暴露模型/逻辑缺陷。

---

## 阶段 3 — 小流量试点切换（Canary / Consumer-by-Consumer）

要做的事：

* 选择**非关键或低风险的消费方**（例如内部工具、报表）作为首批迁移对象。
* 将这些消费者的 API 指向中间层并在中间层中把流量路由到新系统（canary）。
* 监控关键指标：响应正确性、一致率、延迟、错误率、用户反馈。
* 逐步扩大试点范围（更多业务线）。

技术手段：

* 使用**feature flags / routing rules** 在 API 层控制哪些消费者读新或读旧。
* 对重要读接口使用 **灰度比例切换**（先 1% 请求到新系统，观察后逐渐放大）。

为什么：按消费者逐个切换风险最小，问题能被局部快速回滚。

---

## 阶段 4 — 关键路径切换（All-read, then All-write）

要做的事：

* 在确认大部分消费者稳定后，进行**“读切换”**：统一将读请求切到新平台（仍保留旧平台作为写或事件源，或开启双写直到验证完毕）。
* 再次监控和修复。
* 当读写都稳定后，切换写流量（旧系统停止写入，所有变更写入新平台），同时把旧平台变更事件完全迁移到新平台同步逻辑。

为什么：先把读流量切换能验证查询性能和拓扑语义，随后切写才能完成最终一致性。

---

## 阶段 5 — 回收与退役（退化旧系统）

要做的事：

* 确认无消费者并验证数据一致后，执行旧 CMDB 退役流程：

  * 关闭写接口并保留历史备份只读（满足审计要求）。
  * 迁移历史变更记录 / 审计日志到归档系统（或导出到数据仓库）。
  * 卸载运维依赖、停掉 Agent/任务、清理 DNS/路由、关停服务。
* 保留一段时间的“查询兼容层”（如果有需要保留旧 API 适配器），方便极少数历史系统继续读取。

为什么：退役必须合规（审计、备份），同时给业务方缓冲期。

---

# 关键技术实现细节（更落地的指引）

1. **Canonical Model 映射表**

   * 每个 CI type 做字段映射表（旧字段 → 新字段 → 转换函数），记录必填/可选/默认值、来源优先级。
   * 维护在代码库或配置中心，支持动态变更与版本化。

2. **Change Data Capture（CDC）**

   * 若旧 CMDB 有数据库或支持变更日志，使用 CDC（Debezium、数据库 binlog）把变更写成事件入队，保证增量稳定同步。
   * 若无 CDC，则靠定期全量快照 + 差分比对。

3. **幂等与冲突解决**

   * 事件必须幂等（idempotent key），同步器要能自动解决冲突（时间戳优先、数据主权规则）。

4. **双写策略注意事项**

   * 双写容易产生不一致，必须先实现**幂等写 + 回放机制 + 原子确认**。
   * 推荐中间层做“单事务确认”并在失败时回滚或标记待补偿。

5. **读路由与网关**

   * 所有消费方流量建议通过 API Gateway / Proxy（可控制路由）访问 CMDB。这样可透明切换读写目标。
   * Gateway 层记录每次请求来源、路由目标，便于问题定位和回滚。

6. **对外兼容 Adapter**

   * 对旧系统暴露的 API 一律写 Adapter 层（Facade），Adapter 内部可以同时调用旧/new。便于逐步下线旧 API。

7. **数据质量监控**

   * 建立自动化健康仪表盘：一致率、差异量、最新更新时间、孤儿 CI 数量、错误事件计数。
   * 设定阈值告警，一旦跨阈触发自动降级或回滚。

---

# 组织与流程配套（不可忽视）

* **迁移委员会**：跨部门小组（平台/监控/安全/网络/业务），定期决策 cutover 时间和策略。
* **变更窗口与沟通计划**：任何关键切换需提前通告、准备回滚。
* **迁移演练（Runbook）**：为每个切换场景写好 playbook（切换步骤、验证项、回滚步骤、联系人）。
* **灰度与回滚演练**：先在 sandbox 做完整演练再到 production。
* **培训与文档**：对消费方做 API/行为变更培训、更新 SLO 文档。

---

# 风险与缓解（必须写清楚）

* 风险：数据不一致导致上游业务错误。
  缓解：双向校验、阈值告警、回滚开关、手动修复流程。
* 风险：双写导致性能下降。
  缓解：异步写、批处理、后端队列削峰。
* 风险：旧系统与新系统模型深度不匹配（业务语义差异）。
  缓解：先做 canonical layer 抽象并补齐语义缺口，必要时用补偿逻辑。
* 风险：变更窗口沟通失败，业务方被动。
  缓解：迁移委员会+变更公告+多人 on-call。

---

# 成功判定指标（切换决策依据）

* 消费方级别：已迁移消费方中，错误率/异常率 ≈ 基线水平。
* 数据级别：字段级/关系级一致率达到预设阈值（如 99%+，按关键字段设置更高阈值）。
* 性能级别：查询延迟、吞吐量满足 SLO。
* 运维级别：可观测性达标（指标、日志、追踪），能在 15 分钟定位并回滚问题（根据公司 SLA 调整）。

---

# 回滚与紧急处理（必备 Runbook 概要）

1. 触发条件：一致率低于阈值、关键业务报错率升高、关键监控链路告警。
2. 回滚步骤（快速）：

   * 在 API Gateway 层把流量回路由到旧系统（instant）。
   * 在中间层暂停写入新系统，切换为写旧或中断写并记录未同步事件。
   * 启动数据补偿流程，记录差异并排查缘由。
3. 事后：事故原因分析、补丁推送、流程改进、向迁移委员会汇报。

---

# 逐步替代的时间与里程碑建议（不写具体天数，仅阶段性）

* 里程碑 A：完成评估与 canonical model，搭好中间层（可读、可写）并完成 smoke tests。
* 里程碑 B：完成 shadow write / read-through 并实现自动一致性报表。
* 里程碑 C：完成首批消费者 canary 切换并稳定。
* 里程碑 D：完成全部关键消费者切换（读先后写），达到数据一致阈值。
* 里程碑 E：完成旧系统退役与历史数据归档。

---

# 为什么这套方案值得采用（总结）

* **可控**：每一步都能回滚，风险边界清晰。
* **迭代快**：先验证价值再扩展，避免一次性大改动失败。
* **兼容性强**：中间层与 adapter 把旧系统依赖抽离，消费方改动最小。
* **可观测、可治理**：一致性报表、阈值告警让迁移变得可测量。
* **支持智能化**：迁移完成后，新平台就能承接 AIOps、RCA 等能力。

---

如果你愿意，我可以马上帮你：

* 生成一份**迁移 Runbook 模板**（含 API Gateway 路由示例、回滚命令、检查清单、监控仪表盘模板）；
* 或者根据你现有旧 CMDB 的信息（API、数据模型、消费方清单）**写出具体的 canonical model 映射表 + 同步策略实现草案**（含伪代码与 DB/队列选型建议）。

你想先要哪个交付物？


# 参考资料


* any list
{:toc}