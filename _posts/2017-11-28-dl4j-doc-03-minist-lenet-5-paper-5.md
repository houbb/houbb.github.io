---
layout: post
title:  dl4j doc-03-minist 手写识别 Lenet-5 paper 论文学习 《Gradient-Based Learning Applied to Document Recognition》 V
date:  2017-04-16 12:03:32 +0800
categories: [Deep Learning]
tags: [AI, DL, dl4j, neural network]
published: true
---

# VII. 多对象识别：空间位移神经网络  Multiple Object Recognition: Space Displacement Neural Network

在明确使用启发式方法对字符字符串图像进行分割的简单替代方案中有一个简单的替代方法。这个想法是在整个单词或字符串的标准化图像上沿着所有可能的位置扫描一个识别器，如图22所示。通过这种技术，不需要分割启发式方法，因为系统本质上检查输入的所有可能分割。然而，这种方法存在问题。

首先，该方法通常相当昂贵。识别器必须应用在输入的每个可能位置上，或者至少应用在足够大的位置子集上，以便对识别器视野中字符的错位影响小到足以不影响错误率。其次，当识别器位于要识别的字符中心时，中心字符的邻居将出现在识别器的视野中，可能会触碰中心字符。

因此，识别器必须能够正确识别其输入字段中心的字符，即使相邻字符非常接近或接触中心字符。第三，单词或字符字符串无法完全大小标准化。字符串中的单个字符可能具有差异很大的大小和基线位置。因此，识别器必须对移位和大小变化非常稳健。

如果在输入字段上复制卷积网络，这三个问题就可以优雅地避免。

首先，正如第III节所示，卷积神经网络对于输入图像的移位和尺度变化，以及输入中的噪声和杂项具有很强的鲁棒性。这些特性解决了前一段中提到的后两个问题。其次，当在大型输入字段上复制时，卷积网络可以显著节省计算需求。

复制的卷积网络，也称为空间位移神经网络或SDNN [27]，如图23所示。虽然一般情况下扫描识别器可能成本高昂，但卷积网络可以非常高效地在大型、可变大小的输入字段上进行扫描或复制。考虑卷积网络的一个实例及其在附近位置的对应实例。由于网络的卷积性质，观察输入相同位置的两个实例的单元具有相同的输出，因此它们的状态不需要计算两次。只需要重新计算两个网络实例不共享的新状态的薄片。当将所有薄片放在一起时，结果就是一个结构与原始网络相同的更大的卷积网络，只是特征图在水平维度上更大。

换句话说，通过增加进行卷积的字段的大小，并相应地复制输出层，可以简单地复制卷积网络。输出层实际上变成了一个卷积层。接收场位于基本对象中心的输出将产生该对象的类，而中间输出可能表示没有字符或包含垃圾。这些输出可以被解释为在输入字段的所有可能位置存在对象的证据。

SDNN 架构对于识别草书手写体似乎特别有吸引力，因为没有可靠的分割启发式方法存在。尽管 SDNN 的想法很古老，而且非常简单，但直到最近才引起了广泛的兴趣，因为如上所述，它对识别器提出了巨大的要求。

在语音识别中，识别器至少要小一个数量级，因此复制卷积网络更容易实现，例如在 Haner 的多状态 TDNN 模型中。


## A. 解释带有 GTN 的 SDNN 的输出

SDNN 的输出是一系列向量，编码了在输入的相应位置找到特定类别标签的字符的可能性、惩罚或分数。

需要一个后处理器从这个向量序列中提取出最佳的标签序列。SDNN 输出的一个示例如图25所示。很多时候，个别字符被识别器的几个相邻实例发现，这是由于识别器对水平平移的稳健性。而且很多时候，字符被错误地由只看到字符一部分的识别器实例检测到。例如，只看到“4”的右侧三分之一的识别器实例可能输出标签1。

我们如何从输出序列中消除这些多余的字符并提取出最佳解释？这可以通过使用一个新类型的图形转换器来实现，该转换器具有两个输入图，如图24所示。SDNN 产生的向量序列首先被编码成一个线性图，该图具有在连续节点对之间的多条弧。每个节点对之间的弧包含在该位置上 SDNN 为该类别标签产生的标签，以及惩罚。

这个图称为 SDNN 输出图。转换器的第二个输入图是一个语法转换器，更具体地说是一个有限状态转换器，它编码了类别标签的输入字符串与识别字符的相应输出字符串之间的关系。这个转换器是一个加权有限状态机（图），其中每条弧都包含一对标签，可能还有一个惩罚。与有限状态机类似，当观察到的输入符号与弧上附加的符号对中的第一个符号匹配时，转换器处于一种状态，并跟随一条弧转移到新状态。

此时，转换器发出该对中的第二个符号以及将输入符号的惩罚和弧的惩罚组合起来的惩罚。因此，转换器将加权符号序列转换为另一个加权符号序列。

图24所示的图形转换器执行识别图与语法转换器之间的组合。此操作将识别图中的每个可能序列与语法转换器中的路径进行匹配。

组合产生解释图，其中包含每个对应的输出标签序列的路径。这种组合操作可能看起来是组合性难以解决的，但事实证明有一种有效的算法描述如下，更多细节请参见第VIII节。

- F24 & F25

![F24](https://img-blog.csdnimg.cn/direct/ef456413455840dea4944bc88cea98fe.png#pic_center)

- F26

![F26](https://img-blog.csdnimg.cn/direct/1507dfd4da66476e901472f6004670ed.png#pic_center)

## B. SDNN的实验

在一系列实验中，LeNet-5被训练的目标是被复制，以便识别多个字符而无需分割。数据是从先前描述的改编的NIST数据集生成的，方法如下。

训练图像由一个中心字符组成，两侧的字符随机从训练集中挑选。字符之间的边界框的间隔在-1到4个像素之间随机选择。在其他情况下，没有中心字符存在，此时网络的期望输出是空白空间类别。

此外，训练图像受到了10%的椒盐噪声（随机像素反转）的影响。

图25和图26显示了LeNet-5 SDNN成功识别多个字符的几个示例。基于启发式分割的标准技术在许多这些示例中将表现不佳。

从这些例子可以看出，该网络具有显著的不变性和抗噪性质。虽然一些作者认为不变性需要比前馈神经网络更复杂的模型，但LeNet-5在很大程度上展示了这些特性。同样，有人提出准确识别多个重叠对象需要明确解决所谓的特征绑定问题的机制。如图25和图26所示，即使字符紧密交织在一起，该网络也能够将字符区分开来，而这是使用更传统的启发式分割技术无法实现的任务。SDNN还能够正确地组合形成字符的不连续的墨迹片段。图26上半部分展示了这种情况的良好示例。在左上方的示例中，数字4和0彼此之间的连接性比它们与自身的连接性更强，但系统正确地将4和0识别为单独的对象。右上方的示例有几个有趣之处。

首先，系统正确地识别了三个单独的1。其次，尽管几何信息无法确定将4的左半部分与其左侧或右侧的垂直杠相联系，但4的左半部分和右半部分被正确地分组在一起。

数字4的右半部分导致了SDNN输出中出现了一个错误的1，但这个错误的1被字符模型转换器移除了，该转换器防止字符出现在连续的输出中。

SDNN的另一个重要优势是它们在并行硬件上的易实现性。专用的模拟/数字芯片已经被设计并用于字符识别和图像预处理应用。

然而，传统处理器技术的迅速进步，减少精度的矢量算术指令（例如英特尔的MMX），使得专用硬件的成功成为可能性。

您可以在http://www.research.att.com/~yann/ocr上观看LeNet-5 SDNN的短视频片段。

![F26](https://img-blog.csdnimg.cn/direct/1507dfd4da66476e901472f6004670ed.png#pic_center)



## C. SDNN的全局训练

在上述实验中，字符串图像是从单个字符人工生成的。优点是我们事先知道重要字符的位置和标签。

在实际训练数据中，字符串的正确标签序列通常是可用的，但是输入图像中每个相应字符的精确位置是未知的。

在前一节描述的实验中，使用了一个非常简单的图形转换器从SDNN输出中提取了最佳解释。

可以通过通过类似于第VI节中描述的体系结构中排列的图形转换器将梯度反向传播来全局训练SDNN。这在某种程度上相当于使用隐马尔可夫模型对SDNN的输出进行建模。

全局训练的、可变大小的TDNN/HMM混合模型已被用于语音识别和在线手写识别。空间位移神经网络已经与HMM或其他弹性匹配方法结合使用于手写单词识别。

- F27

![F27](https://img-blog.csdnimg.cn/direct/ee798899560c48d7bcbfb1b2397c051b.png#pic_center)

图27显示了使用区分性前向准则训练SDNN/HMM混合模型的图形转换器架构。顶部部分与图21的顶部部分相似。

在右侧，将识别图与语法组合，得到包含所有可能合法解释的解释图。在左侧，使用一个只包含所需标签序列路径的语法进行组合。这与前一节中使用的路径选择器具有类似的功能。

与VI-D节中一样，损失函数是从左半部分获得的前向得分与从右半部分获得的前向得分之间的差异。为了通过组合转换器进行反向传播，我们需要记录识别图中的哪个弧产生了解释图中的哪些弧。

与识别图中的弧相关的导数等于其产生的所有解释图中的弧的导数之和。还可以计算对语法图上的惩罚的导数，从而学习它们。

与前面的示例一样，必须使用区分性准则，因为如果网络的输出RBF是自适应的，使用非区分性准则可能会导致崩溃效应。

以上训练程序可以等效地用HMM来表述。早期在邮政编码识别和最近在在线手写识别中的实验已经证明了全局训练的SDNN/HMM混合模型的想法。

**SDNN是一种极具潜力和吸引力的OCR技术，但到目前为止，其效果尚不如启发式分割技术**。

我们希望随着对这些模型的更多经验积累，这些结果会得到改善。

## D. 利用SDNN进行目标检测和定位

SDNN的一个有趣应用是目标检测和定位。卷积网络的不变性特性，结合它们在大范围内复制的高效性，表明它们可以用于在大型图像中进行“蛮力”目标定位和检测。主要思想是训练一个单一的卷积网络，以区分感兴趣对象的图像与背景中的图像。在利用模式下，网络被复制以覆盖整个待分析的图像，从而形成一个二维空间位移神经网络。SDNN的输出是一个二维平面，其中激活单元指示相应感受场中感兴趣对象的存在。由于图像中要检测的对象的大小未知，因此可以将图像以多种分辨率呈现给网络，并结合多种分辨率的结果。该思想已应用于面部定位、信封上地址块的定位和视频中的手部跟踪。

为了说明该方法，我们将考虑在图像中检测人脸的情况，如[93]所述。首先，收集包含不同比例人脸的图像。这些图像经过零均值拉普拉斯滤波器滤波，以消除全局照明和低空间频率照明梯度的变化。然后，从这些图像中手动提取面部和非面部的训练样本。然后，对面部子图像进行尺寸归一化，使整个面部的高度大约为20个像素，同时保持相当大的变化范围（在两倍范围内）。背景子图像的比例是随机选择的。对这些样本中的子图像进行分类，以区分面部子图像和非面部子图像。

当要分析场景图像时，首先通过拉普拉斯滤波器进行滤波，并在二的幂次分辨率上进行子采样。网络在多个分辨率图像上复制。使用简单的投票技术来结合多个分辨率的结果。

可以使用前一节描述的全局训练方法的二维版本来缓解构建训练样本时手动定位面部的需求[93]。每个可能的位置都被视为一种替代解释，即简单图中的几个并行弧之一，该图仅包含起始节点和结束节点。

其他作者已经成功地使用神经网络或其他分类器，如支持向量机进行人脸检测[96]，[97]。他们的系统与上述系统非常相似，包括将图像以多种尺度呈现给网络的思想。但由于这些系统不使用卷积网络，它们无法利用此处描述的加速，并且必须依赖其他技术，如预过滤和实时跟踪，以保持合理范围内的计算要求。
此外，因为这些分类器对尺度变化的不变性要远低于卷积网络，所以需要将图像呈现给分类器的尺度数量乘以。

# 参考资料

http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf

* any list
{:toc}
