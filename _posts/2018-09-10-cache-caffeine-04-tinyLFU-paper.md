---
layout: post
title: Caffeine-04-TinyLFU A Highly Efficient Cache Admission Policy
date:  2018-09-10 07:44:19 +0800
categories: [Cache]
tags: [cache, middleware, in-memory cache, sh]
published: true
---

# 这篇技术文档的中文翻译如下：

**摘要**
本文提出了一种基于频率的缓存准入策略，以提高受访问分布偏差影响的缓存的有效性。给定一个新访问的项目和缓存中的一个驱逐候选项，我们的方案基于最近的访问历史来决定，是否值得以驱逐候选项为代价将新项目纳入缓存。
实现这一概念是通过一种新颖的近似LFU（最近最少使用）结构，称为TinyLFU，它维护了一个最近访问的大样本项目的访问频率的近似表示。TinyLFU非常紧凑和轻量级，因为它建立在布隆过滤器理论之上。
我们通过模拟合成工作负载以及多个来源的多个真实跟踪来研究TinyLFU的属性。这些模拟展示了通过增强各种替换策略与TinyLFU驱逐策略所获得的性能提升。此外，还介绍了一种新的组合替换和驱逐策略方案，昵称为W-TinyLFU。W-TinyLFU被证明在这些跟踪上获得等于或优于其他最先进替换策略的命中率。它是唯一在所有跟踪上都能获得如此好结果的方案。

**说明**：
- "cache admission policy" 指的是缓存准入策略，即决定哪些数据可以被存储在缓存中的规则。
- "eviction candidate" 指的是可能被从缓存中移除的数据项。
- "access history" 指的是数据访问的历史记录。
- "LFU" 指的是最近最少使用算法，一种缓存替换算法。
- "TinyLFU" 是一种近似的LFU算法，它使用布隆过滤器（Bloom filter）理论来近似地表示数据的访问频率。
- "Bloom filter" 是一种空间效率很高的数据结构，用于测试一个元素是否是一个集合的成员。
- "synthetic workloads" 指的是人工合成的工作负载，通常用于模拟真实世界的情况。
- "real traces" 指的是从实际系统中收集的数据。
- "hit-ratios" 指的是命中率，即缓存中成功找到请求数据的比率。

希望这个翻译对你有所帮助。如果需要更详细的解释或有其他问题，请随时告知。

# 1 引言

缓存是计算机科学中最基本和有效的方法之一，用于提升多个领域系统的性能。通过在一个更快速或更接近应用程序的内存中保留一小部分数据项来实现。当整个数据域无法适应这个快速的近端内存时，就会采取这种方式。缓存有效的直觉原因是计算机科学的许多领域中的数据访问展现出相当程度的“局部性”。更正式地捕捉这种“局部性”的方式是通过概率分布表征所有可能的数据项的访问频率，并注意在计算机科学的许多有趣的领域中，概率分布是高度偏斜的，意味着少数对象比其他对象更有可能被访问。此外，在许多工作负载中，访问模式以及相应的概率分布会随时间改变。这种现象也被称为“时间局部性”。

当一个数据项被访问时，如果它已经存在于缓存中，我们称之为缓存命中；否则，它是缓存未命中。缓存命中率是缓存命中次数与总数据访问次数之比。因此，如果缓存中的项对应于最常访问的项，那么缓存可能会产生更高的命中率[33]。

鉴于缓存大小通常是有限的，缓存设计者面临如何选择存储在缓存中的项的困境。特别是当为缓存保留的内存变满时，决定哪些项应该从缓存中删除。显然，应该高效地做出驱逐决策，以避免计算和空间开销超过使用缓存的好处。用于决定哪些项应该插入到缓存中，哪些项应该被驱逐的缓存机制使用的空间被称为缓存的元数据。在许多缓存方案中，操作元数据的时间复杂性以及元数据的大小与存储在缓存中的项的数量成比例。

当数据访问模式的概率分布随时间保持不变时，可以容易地显示最少使用（LFU）产生最高的缓存命中率[8, 51]。根据LFU，在大小为n的项的缓存中，每时每刻都保留迄今为止使用最频繁的n个项。然而，LFU有两个重大局限性。首先，已知的LFU实现需要维护大型和复杂的元数据。其次，在大多数实际工作负载中，访问频率会随时间发生剧烈变化。例如，考虑一个视频缓存服务；在某一天非常受欢迎的视频片段可能几天后就不再被访问了。因此，一旦其受欢迎程度下降，就没有必要继续保留该项在缓存中。

因此，已开发了LFU的各种替代方案。其中许多包括老化机制和/或专注于最近W次访问的有限大小窗口。这种老化旨在限制元数据的大小，并调整缓存和驱逐决策以适应项目的更近期的受欢迎程度。一个著名的例子是称为窗口LFU（WLFU）[38]的方案，如下所述。此外，在绝大多数情况下，新访问的项总是被插入到缓存中，缓存方案仅专注于其驱逐策略，即决定哪个项应该被驱逐。这是因为维护不在缓存中的对象的元数据被认为是不切实际的。

值得注意的是，由于维护所有曾经遇到的对象的频率直方图的成本极高，实施LFU方案的已发表作品仅维护缓存中的项目的频率直方图[48]。因此，我们通过称前者为完美LFU（PLFU）和后者为内存LFU来区分它们。由于WLFU优于内存LFU[8]（以更大的元数据为代价），因此我们只讨论WLFU和PLFU。

一个依赖于“时间局部性”属性的LFU的流行替代方案称为最近最少使用（LRU）[33]，其中最后访问的项总是被插入到缓存中，最近最少访问的项在缓存满时被驱逐。

与LFU相比，LRU的实现要高效得多，并自动适应数据访问模式的时间变化和工作负载的突发性。然而，在许多工作负载下，为了获得相同的命中率，LRU需要比LFU更大的缓存。



# 参考资料

https://arxiv.org/pdf/1512.00727.pdf

* any list
{:toc}