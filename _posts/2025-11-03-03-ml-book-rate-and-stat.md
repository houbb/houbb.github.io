---
layout: post
title: 第3章　概率与统计
date: 2025-11-03 20:40:12 +0800
categories: [AI]
tags: [ai, learn-note]
published: true
---




# 【AI简史】第3章 概率与统计：机器学习的灵魂数学

> 你以为机器学习靠的是算力，其实靠的是“算概率”。

很多人一听到“概率与统计”，第一反应就是头疼。
但如果你真想理解机器学习的底层逻辑，这一块必须得啃下来。

因为无论是推荐算法、语音识别，还是 ChatGPT，
它们本质上都在做一件事——**在不确定性中做决策。**

而能让机器理解“不确定”，只有概率论和统计学。

---

## 一、不确定世界的语言

数学大体分两种：

* 一种描述“确定”的世界，比如代数、几何；
* 另一种描述“不确定”的世界——那就是概率与统计。

生活中充满了不确定：
天气会不会下雨、股价明天涨不涨、下一部电影火不火。

概率论告诉我们：如何用数字描述这些不确定性；
统计学则告诉我们：如何从数据里发现它们背后的规律。

这两者结合，就是机器学习的数学灵魂。
说白了，机器学习的目标就是——**用数据去推测未来。**

---

## 二、随机变量：世界的骰子

掷一个骰子，结果可能是 1 到 6。
我们用 X 表示这个结果。

X 就是一个“随机变量”，它把一个不确定的事件转化为一个数值。

随机变量有两类：

* 离散型，比如骰子点数、硬币正反、商品是否被点击；
* 连续型，比如气温、身高、股价。

而概率分布，就是告诉我们这些值出现的可能性有多大。
对离散变量看概率质量函数（PMF），
对连续变量看概率密度函数（PDF）。

一句话概括：

> 概率分布，就是世界的“可能性地图”。

---

## 三、期望与方差：平均与不确定

“期望”代表平均结果——长期来看系统的中心。
“方差”代表波动——系统有多容易出岔子。

在机器学习里，期望是模型的预测值，
方差体现模型预测的稳定性。

你可以这么理解：

> 期望让我们知道“最可能发生什么”，
> 方差让我们知道“它有多不稳定”。

模型预测值的平均误差、损失函数的定义、模型泛化能力的衡量，
背后都离不开这两个概念。

---

## 四、极大似然估计：最像真的那个参数

假设你掷了 10 次硬币，出现 8 次正面。
你猜这枚硬币的正面概率是多少？

答案是 0.8——
这是一个典型的“极大似然估计”（Maximum Likelihood Estimation，简称 MLE）。

它的思想是：

> 给定观测数据，找到最可能产生这些数据的参数。

比如逻辑回归、隐马尔可夫模型、GMM、高斯混合分布，
这些模型训练时，都是在背后做这件事——
寻找最可能的那一组参数。

可以说，MLE 是所有概率模型的共同语言。

---

## 五、贝叶斯推断：用信念更新信念

贝叶斯推断比极大似然更“哲学”一点。

它认为，我们永远不是从零开始。
每一次新的观察，都是在修正我们原有的信念。

用公式表达就是：

P(参数 | 数据) = [P(数据 | 参数) × P(参数)] / P(数据)

别被符号吓到。它的意思很简单：

> 我有一个先验信念（Prior），
> 看到新数据（Likelihood）后，
> 更新成新的信念（Posterior）。

举个例子：
你原本觉得硬币是公平的（p=0.5），
但掷了十次后出现八次正面，
你自然会觉得它“可能稍微偏正面一点”。

这就是贝叶斯思维。
不是推翻旧信念，而是根据证据去更新它。

现代机器学习里，很多方法都带着这种思维：
朴素贝叶斯分类器、贝叶斯网络、高斯过程，
甚至大语言模型的“先验知识”也有贝叶斯的影子。

---

## 六、朴素贝叶斯：简单的高分选手

朴素贝叶斯是贝叶斯思想的一个简化版。
它假设输入特征之间相互独立——虽然不太现实，但计算效率极高。

算法逻辑是这样的：

P(y|x₁, x₂, …, xₙ) ∝ P(y) × Π P(xᵢ|y)

通俗地讲：
一个邮件是不是垃圾邮件，
取决于它是否包含“中奖”、“免费”、“限时”等词语，
以及这些词在垃圾邮件中出现的概率。

训练时，我们统计这些概率；
预测时，我们计算每个类别的概率，选最大的那个。

它结构简单，但在文本分类上表现出奇效。
垃圾邮件过滤、情感分析、新闻分类——它都能打。

有人说：

> “朴素贝叶斯是那个看起来平平无奇，却次次考高分的学生。”

---

## 七、信息论：用数字衡量“未知”

香农的信息论，让我们第一次能用数学量化“不确定性”。

熵（Entropy）描述系统的混乱程度：

H(X) = - Σ P(x) log P(x)

一个永远正面的硬币，熵是 0；
一个完全随机的硬币，熵是 1。
熵越高，系统越不可预测。

KL 散度（相对熵）衡量两个分布的差距，
比如模型预测分布 Q(x) 和真实分布 P(x) 的差异。

交叉熵（Cross Entropy）是实际中最常用的形式，
是深度学习里分类任务的标准损失函数。

一句话总结：

> 熵衡量不确定，KL 衡量差距，交叉熵用来优化。

---

## 八、为什么要懂概率？

因为这不仅是理解机器学习的钥匙，
也是理解世界的一种方式。

当模型说“猫的概率是 0.8”时，
它并不是在说“这一定是猫”，
而是在说：“在我所见的世界里，最有可能是猫。”

这其实跟人类判断世界的方式一模一样。
我们也从不追求“绝对正确”，
我们只是在不断修正、不断接近真相。

概率论教会机器理性，
统计学教会机器学习，
而理解它们，
就是理解智能本身。

---

**结语**

当你真正学懂概率，会发现一个奇妙的变化：
世界从“随机与混乱”，
变成了“有迹可循的可能性空间”。

这就是机器学习的起点，
也是人类理解智能的开始。

---

是否希望我帮你补上适合发布的**标题备选 + 封面文案 + 公众号摘要（引导点击的简介）**？
我可以直接给出三套风格（思考型 / 科普型 / 干货型）供你选择。






--------------------------------------------------------------------------------


# 第3章　概率与统计

这一章可以说是机器学习的数学“灵魂”章节——**概率与统计**是理解一切模型（从朴素贝叶斯到深度神经网络）的底层逻辑。

## 🌟 引言

机器学习的核心任务其实就是“在不确定性中做决策”。

而**概率论**提供了处理不确定性的语言，**统计学**提供了从数据中估计规律的方法。

如果说：

* 代数 → 是确定世界的数学；
* 概率与统计 → 就是“不确定世界的数学”。

---

## 3.1 随机变量与分布

### ✅ 随机变量（Random Variable）

* **定义**：随机变量是一个用数字表示随机事件结果的函数。
  比如：

  * 掷骰子 → 可能结果 {1,2,3,4,5,6}
  * 把“点数”定义为随机变量 X，那 X 就是一个离散随机变量。

### 🧩 两大类：

1. **离散型随机变量（Discrete）**

   * 取值是有限或可数的
   * 如骰子点数、硬币正反面
   * 常用分布：伯努利分布、二项分布、泊松分布

2. **连续型随机变量（Continuous）**

   * 取值是连续的（可取任意实数）
   * 如人的身高、温度
   * 常用分布：正态分布、均匀分布、指数分布

### 📊 概率分布（Probability Distribution）

概率分布定义了随机变量的取值“可能性”：

* 对离散变量 → 概率质量函数（PMF）
  ( P(X=x_i) )
* 对连续变量 → 概率密度函数（PDF）
  ( f(x) )，且 ( P(a \le X \le b) = \int_a^b f(x) dx )

### 🎯 期望与方差

* **期望**：平均值（模型预测的平均输出）
  [
  E[X] = \sum_i x_i P(x_i)
  ]
* **方差**：不确定性的量化
  [
  Var(X) = E[(X - E[X])^2]
  ]

这些是机器学习里「损失函数」与「不确定性」的数学基石。

---

## 3.2 极大似然估计（MLE）与贝叶斯推断

### 🎯 极大似然估计（Maximum Likelihood Estimation, MLE）

**目标**：在已知数据的情况下，找到最可能生成这些数据的模型参数。

假设我们有样本数据 ( D = {x_1, x_2, ..., x_n} )，
模型的参数为 ( \theta )，则似然函数为：

[
L(\theta) = P(D|\theta) = \prod_i P(x_i|\theta)
]

取对数方便计算：

[
\hat{\theta} = \arg\max_\theta \log L(\theta)
]

🧠 举个例子：

* 掷硬币 n 次，结果正面次数 k
* 假设正面概率为 ( p )，似然函数：
  [
  L(p) = p^k (1-p)^{n-k}
  ]
* 最大化后得到：
  [
  \hat{p} = \frac{k}{n}
  ]
  这就是最直观的「极大似然估计」。

---

### 🧮 贝叶斯推断（Bayesian Inference）

贝叶斯思想强调「先验知识 + 数据更新」：
[
P(\theta|D) = \frac{P(D|\theta) P(\theta)}{P(D)}
]

* **先验（Prior）**：在看到数据前对参数的信念。
* **似然（Likelihood）**：数据在参数下出现的可能性。
* **后验（Posterior）**：看到数据后的新信念。

📘 举例：
如果你认为硬币可能是公平的（先验 ( p=0.5 )），
但你掷了10次出现8次正面，贝叶斯更新后你会认为“可能稍偏正面”。

👉 贝叶斯方法在现代机器学习中非常重要：

* 朴素贝叶斯分类器
* 贝叶斯网络
* 高斯过程（Gaussian Process）
* LLM 先验知识建模

---

## 3.3 条件概率与朴素贝叶斯模型

### 🧩 条件概率（Conditional Probability）

[
P(A|B) = \frac{P(A,B)}{P(B)}
]

理解为“在 B 发生的前提下，A 发生的概率”。

比如：

* 事件 A：邮件是垃圾邮件
* 事件 B：邮件中出现“中奖”一词
  则 ( P(A|B) ) 表示：出现“中奖”的邮件是垃圾邮件的概率。

---

### 📘 朴素贝叶斯分类器（Naive Bayes）

假设输入特征之间相互独立（朴素假设）：

[
P(y|x_1, ..., x_n) \propto P(y) \prod_i P(x_i|y)
]

算法流程：

1. 从训练数据估计先验 ( P(y) )
2. 估计条件概率 ( P(x_i|y) )
3. 对新样本，计算各类的后验概率并选取最大者。

📊 应用场景：

* 垃圾邮件分类
* 文本情感分析
* 新闻主题分类

🧠 尽管“朴素”，但在高维稀疏数据（如文本词袋模型）上效果惊人好。

---

## 3.4 信息论基础：熵、KL散度、交叉熵

### 🔹 熵（Entropy）

衡量不确定性的数学量：

[
H(X) = - \sum_x P(x) \log P(x)
]

* 熵越大 → 不确定性越高
* 熵越小 → 越有序

📘 举例：

* 公平硬币 ( H = 1 )
* 总是正面的硬币 ( H = 0 )

---

### 🔹 相对熵（KL 散度）

衡量两个分布的“差距”：
[
D_{KL}(P||Q) = \sum_x P(x) \log \frac{P(x)}{Q(x)}
]

在机器学习中：

* 衡量模型分布 ( Q ) 与真实分布 ( P ) 的差距。
* 是许多损失函数（例如交叉熵）的理论来源。

---

### 🔹 交叉熵（Cross Entropy）

[
H(P,Q) = - \sum_x P(x) \log Q(x)
]

当 ( P ) 是真实分布、( Q ) 是模型预测分布时，
最小化交叉熵 ≈ 让模型预测尽可能接近真实。

📘 应用：

* 分类任务中的损失函数（Softmax + CrossEntropyLoss）
* 信息压缩与语言模型的困惑度（Perplexity）计算

---

## 🌍 小结

| 概念              | 核心作用     | 在机器学习中的体现   |
| --------------- | -------- | ----------- |
| 随机变量            | 建模不确定性   | 特征、标签的概率表达  |
| MLE             | 参数估计     | 逻辑回归、GMM    |
| 贝叶斯推断           | 融合先验与数据  | 朴素贝叶斯、贝叶斯网络 |
| 条件概率            | 推断关系     | 分类与推荐       |
| 熵 / KL 散度 / 交叉熵 | 信息量与分布差异 | 损失函数、模型评估   |

* any list
{:toc}