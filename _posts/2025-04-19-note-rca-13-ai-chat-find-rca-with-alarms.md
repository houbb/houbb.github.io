---
layout: post
title: RCA 根因分析推断-12-从告警出发，推断出根因+分析报告
date: 2025-4-19 14:31:52 +0800
categories: [Note]
tags: [note, rca, ai, devops, alarm, sh]
published: true
---

# 序言

结合 ai 打造 rca 系统，先让 ai 回答一下。


# chat

## 你是一名监控报警+运维的资深架构师，经验丰富，知识跨多个领域。性格严谨、理性。简单起见，我们先从一段时间内的多个报警出发，如何推断出当前问题的根因？要求 top3，并且准确性尽可能的高


非常好，**从一段时间内的多个报警出发，推断当前问题的根因**，这是 AI 根因分析系统中最关键、最具挑战性的场景。

我会以你要求的风格：**专业、理性、高准确率优先**，不浮夸，强调严谨性。

---

## 🎯 场景目标

> ✅ **输入**：一个时间窗口内的多条报警（不同组件、主机、服务、级别）
> ✅ **输出**：排序后的 **Top 3 根因候选**，附带推理路径和置信评分

---

## 🧱 解决方案核心思路：以图驱动的根因推断

我们可以抽象出以下分析步骤：

### **1. 多报警事件归一建模**

### **2. 构建报警传播图（因果/依赖图）**

### **3. 进行根因评分计算（结合指标、日志、Trace）**

### **4. 输出 Top 3 根因候选 + 推理路径 + 打分**

---

## 📌 Step 1：多报警标准化建模

将每条报警统一转换为结构化格式：

```json
{
  "timestamp": "2025-08-07T09:00:00",
  "host": "node-a",
  "service": "payment-service",
  "metric": "latency_p99",
  "value": "2500ms",
  "severity": "critical",
  "message": "延迟超过阈值"
}
```

在一个时间窗内（如5分钟），我们收集所有告警，形成一个“报警事件集”。

---

## 📌 Step 2：构建告警传播图（Alert Graph）

> 类似调用链拓扑，但这里我们构造一个**报警因果图**或称为**传播图**，通过依赖 + 时间 +传播方向 构建节点间关系。

* 节点 = 每条报警（带上下文）
* 边 = 依赖关系（如服务 A 调用服务 B）
* 属性 = 告警时间、指标波动、日志异常、Trace延迟

示意：

```
A (error) → B (延迟) → C (降级)
         ↘ D (QPS下降)
```

此时构建出报警传播图后，就可以做“根因评分”。

---

## 📌 Step 3：根因候选打分（RCA Scoring）

为每个节点（报警）评估其成为「根因」的可能性，基于以下打分机制：

| 维度          | 含义                      | 分值建议      |
| ----------- | ----------------------- | --------- |
| 📍 异常源评分    | 是否为拓扑叶子节点；传播链起点         | +0.2\~0.3 |
| ⏱ 时间优先评分    | 最早触发报警（先于其他依赖）          | +0.1\~0.2 |
| 📊 指标剧烈变动   | 指标突变严重程度（如错误率>50%）      | +0.1\~0.3 |
| 🧾 日志证据     | 是否有明确的异常日志/关键词命中        | +0.2\~0.4 |
| 🧠 Trace 定位 | Trace中是否为瓶颈Span（>80%耗时） | +0.2\~0.4 |
| 🔁 上游是否正常   | 如果下游报警但上游无异常，怀疑根因在下游    | +0.2      |

加权计算每个节点的根因概率分数 `score(node_i)`，输出 Top 3 分数最高者。

---

## 📌 Step 4：输出结构化推理结果（Top3）

示例输出如下：

```json
{
  "top3_root_causes": [
    {
      "service": "mysql",
      "score": 0.91,
      "reasoning": [
        "最早触发报警：08:32:01",
        "错误率高达35%，明显异常",
        "payment-service日志显示：connect mysql timeout",
        "Trace中此节点耗时占整链 85%"
      ],
      "suggestion": "检查数据库连接池、网络或数据库状态"
    },
    {
      "service": "payment-service",
      "score": 0.78,
      "reasoning": [
        "延迟升高，但下游 mysql 异常更加严重",
        "Trace显示 payment 调用 mysql 耗时过长",
        "属于受影响而非根因"
      ]
    },
    {
      "service": "order-service",
      "score": 0.56,
      "reasoning": [
        "受 payment-service 异常传导影响",
        "自身指标无明显异常"
      ]
    }
  ]
}
```

---

## 📊 Root Cause Scoring 公式建议（可配置）

```text
score = 
  0.25 * topology_rootness     // 是否在传播链尾
+ 0.20 * early_alarm_factor     // 是否最先报警
+ 0.20 * metrics_severity       // 异常幅度
+ 0.25 * log_anomaly_score      // 日志异常分
+ 0.10 * trace_bottleneck_score // Trace 耗时
```

---

## 🔁 后续闭环反馈（增强准确率）

每次输出后允许人工确认 + 反馈，闭环机制包括：

1. **人工标注根因**：用于监督训练或校验
2. **LLM提示修正增强**：对错误分析可修正提示模板
3. **知识库补充**：新增“mysql连接超时”的案例供下次使用（RAG）

---

## 🧠 示例总结（简洁场景复盘）

**输入报警列表：**

```
[08:32] payment-service 错误率升高 > 20%
[08:33] order-service 延迟 > 2s
[08:34] mysql 错误日志：“connection timeout”
```

**分析结果：**

* 根因候选：

  1. `mysql`（score: 0.91）✅
  2. `payment-service`（score: 0.78）
  3. `order-service`（score: 0.56）
* 推理链条清晰
* 可配置评分逻辑
* 可反馈修正

---

## ✅ 最小可用闭环系统建议（MVP）

如果你希望快速落地一个最小可用闭环系统，可以这样：

| 模块   | 技术实现建议                            |
| ---- | --------------------------------- |
| 告警接收 | Prometheus + Alertmanager Webhook |
| 数据聚合 | Kafka + Loki + PromQL + Trace 接口  |
| 推理逻辑 | Java/Python 实现评分系统 + 依赖图分析        |
| 报告生成 | JSON 输出 + Web可视化（如 Vue + ECharts） |
| 人工反馈 | 提交真实根因，记录结果                       |
| 增量学习 | 基于反馈更新提示模板、归档案例库                  |

---

需要我下一步帮你：

* 编写代码实现 Top3 根因排序逻辑？
* 提供一套 LLM Prompt 模板进行链式推理（COT）？
* 构建报警传播图的推理算法设计细节？

你可以选一个，我马上展开。



# 告警出发的例子

## 我们来模拟一个例子

假设现在我们有多个服务 service-A  serivce-B  serivce-C  service-D 4个服务在短期内同时告警。

1) TRACE 调用关系

service-A、serivce-B、serivce-C 都依赖 service-D

2) cmdb 基础关系

service-A 依赖 mysql-A
service-B 依赖 mysql-B
service-C 依赖 mysql-C
service-D 依赖 mysql-D

3）变更事件

变更期间，A B C D 4个服务都发生了变更，都是普通的 propertoes 配置变更，变更风险为低

service-D 数据库进行域名切换，风险等级为中

4）告警信息

service-A、serivce-B、serivce-C 产生告警,调用 service-D rpc 超时

service-D 产生告警，访问数据库超时

给出一步步的推断过程分析报告，top3 根因



## gpt 回答

非常好，这是一个典型的微服务场景下的根因推理问题。

你提供的信息维度非常关键，包括：

* Trace 调用链
* CMDB 依赖关系
* 变更信息
* 告警数据

我们可以利用这些信息，构建一个标准化的 **根因分析流程（闭环+打分机制）**，然后输出一个清晰的“Top 3 根因推理报告”。

---

## 🧠 根因分析过程（Step by Step）

---

### 🔍 Step 1：初步告警聚合

#### 📌 报警列表

| 服务        | 报警类型    | 报警描述            |
| --------- | ------- | --------------- |
| service-A | RPC 超时  | 调用 service-D 超时 |
| service-B | RPC 超时  | 调用 service-D 超时 |
| service-C | RPC 超时  | 调用 service-D 超时 |
| service-D | 数据库连接超时 | 无法连接 mysql-D    |

#### 🧩 聚合结论：

* 多个服务同时异常，存在潜在的**共享依赖问题**
* service-D 被多个服务调用，可能是**扇出故障热点**
* service-D 本身也异常，优先级上升

---

### 🛠 Step 2：依赖图分析

结合 Trace + CMDB：

```
service-A/B/C
     ↓
   service-D
     ↓
   mysql-D
```

> 🔗 service-A/B/C → service-D → mysql-D

#### 🧠 初步图谱结论：

* service-A/B/C 并非直接故障，而是调用 service-D 超时，属于 **下游影响**
* service-D 自身告警，且下探到数据库 → 需要重点关注 mysql-D

---

### 🔁 Step 3：变更数据关联

| 服务      | 变更类型      | 风险等级 | 时间点 |
| ------- | --------- | ---- | --- |
| A/B/C/D | 配置变更（低风险） | 低    | ✔️  |
| mysql-D | 域名切换（中风险） | 中    | ✔️  |

#### 🎯 变更关联分析：

* 所有服务都有低风险配置变更，但这**不符合异常的爆发范围和影响性**
* **唯一匹配 Trace + CMDB + service-D 告警的变更是 mysql-D 域名切换**

---

### 📈 Step 4：根因候选项打分（统一评分机制）

打分维度如下：

| 指标                    | 说明                   |
| --------------------- | -------------------- |
| 🔁 异常影响范围分数（Impact）   | 被依赖次数，传播路径长度         |
| ⏱ 时间关联性分数（Temporal）   | 告警时间是否紧随变更           |
| 🧠 根因合理性分数（Reasoning） | 是否解释上下游所有异常          |
| 📉 相似历史案例（History）    | 是否有类似历史变更导致故障（若有知识库） |
| ✅ 置信度调整项（可信度）         | 实例关联数越多、越靠近底层可信度越高   |

---

### 🏅 Step 5：Top 3 根因推理报告

| 根因候选                     | 分析说明                                                 | 打分（满分10） |
| ------------------------ | ---------------------------------------------------- | -------- |
| 🥇 mysql-D 域名切换导致连接失败    | service-D 自身报错 + A/B/C 上游全部受影响，唯一符合 Trace/CMDB/变更的事件 | 9.5      |
| 🥈 service-D 配置变更影响连接池参数 | 配置变更存在，但为低风险，未涉及 DB 配置项，可信度低                         | 6.0      |
| 🥉 service-A/B/C 配置变更    | 多个服务变更，但没有解释 service-D 异常，推测为误关联                     | 3.5      |

---

## 📊 分析报告（可呈现在平台中）

```markdown
### 🧠 AI根因分析报告

#### 🆘 异常概况
- 多个上游服务（A/B/C）在同一时间出现调用超时
- 共用下游服务 D，且 service-D 也出现数据库连接超时告警

#### 🔍 系统依赖关系
- Trace 路径：A/B/C → D → mysql-D
- CMDB 配置：D 独占 mysql-D

#### 🔄 变更事件分析
- D 服务所依赖的 mysql-D 刚刚进行“域名切换”，中等风险
- 告警在变更之后出现，时间强相关

#### ✅ 根因结论（Top 3）
1. **mysql-D 域名切换导致连接失败**
   - 解释所有告警路径
   - 变更时间一致
   - service-D 首发告警，符合因果链条
   - **评分：9.5**

2. service-D 配置变更误操作（待进一步验证）
   - 暂无明确影响指标
   - **评分：6.0**

3. A/B/C 服务自身配置变更
   - 不符合 service-D 自身异常
   - **评分：3.5**

#### 🔁 建议措施
- 回滚 mysql-D 域名切换，观察服务恢复
- 检查 service-D 的数据库连接配置（DNS、连接池）
- 标记此案例为知识样本，纳入后续 AI 训练
```

---

## ✅ 关键亮点总结：

| 特性          | 实现方式                   |
| ----------- | ---------------------- |
| 📦 多源异构信息聚合 | Trace + CMDB + 告警 + 变更 |
| 🔍 依赖图分析    | 推出上下游影响链               |
| 🎯 变更匹配定位   | 突出时间、风险、路径重叠性          |
| 🧠 AI打分机制   | 解释性 + 可信度 + 全局评估       |
| 🔄 闭环机制     | 建议动作 + 标记为样本 + 反馈优化模型  |

---

如你需要，我可以帮你把这个流程转化成：

* 可执行的架构方案
* 打分引擎原型设计
* NOC 流程嵌入文档
* 前端可视化设计草图

是否要继续深入？我们可以进一步把评分引擎、反馈训练机制也详细设计出来。







# 参考资料


* any list
{:toc}