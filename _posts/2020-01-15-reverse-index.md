---
layout: post
title: 倒排索引原理与实现
date:  2020-1-9 10:09:32 +0800
categories: [Search]
tags: [search, reverse-index, index, sh]
published: true
---

# 关于倒排索引

场景是：给定几个关键词，找出包含关键词的文档

倒排索引： 不是由记录来确定属性值，而是由属性值来确定记录的位置

lucene 是基于倒排索引实现的。 

倒排文件(inverted file)：存储倒排索引的物理文件 

倒排索引组成：单词词典和倒排文件。

倒排索引一般表示为一个关键词，然后是它的频度（出现的次数），位置（出现在哪一篇文章或网页中，及有关的日期，作者等信息），它相当于为互联网上几千亿页网页做了一个索引，好比一本书的目录、标签一般。

读者想看哪一个主题相关的章节，直接根据目录即可找到相关的页面。

不必再从书的第一页到最后一页，一页一页的查找。

![image](https://user-images.githubusercontent.com/18375710/72408170-f8fd5800-379c-11ea-9ad9-d4883337b03c.png)

## 倒排文件

所有单词的倒排列表顺序的存储在磁盘的某个文件里，这个文件即被称为倒排文件，倒排文件是存储倒排索引的物理文件。

## 单词词典

1 单词词典是由文档集合中出现过的所有单词构成的字符串集合，单词词典内每条索引项记载单词本身的一些信息以及指向“倒排列表”的指针。

2 是倒排索引中非常重要的组成部分，它是用来维护文档集合中所有单词的相关信息，同时用来记载某个单词对应的倒排列表在倒排文件中的位置信息。

在支持搜索时，根据用户的查询词，去单词词典里查询，就能够获得相应的倒排列表。

对于一个规模很大的文档集合来说，可能包含了几十万甚至上百万的不同单词，

3 快速定位某个单词直接决定搜索的响应速度，所以我们需要很高效的数据结构对单词词典进行构建和查找。

常用的数据结构包含哈希加链表和树形词典结构。

# Lucene倒排索引原理

Lucerne使用的是倒排文件索引结构。

该结构及相应的生成算法如下： 　　

设有两篇文章1和2：

文章1的内容为：Tom lives in Guangzhou,I live in Guangzhou too. 　　

文章2的内容为：He once lived in Shanghai.

## 取得关键词

由于lucene是基于关键词索引和查询的，首先我们要取得这两篇文章的关键词，通常我们需要如下处理措施： 　　

a. 我们现在有的是文章内容，即一个字符串，我们先要找出字符串中的所有单词，即分词。英文单词由于用空格分隔，比较好处理。中文单词间是连在一起的需要特殊的分词处理。 　 　

b. 文章中的”in”, “once” “too”等词没有什么实际意义，中文中的“的”“是”等字通常也无具体含义，这些不代表概念的词可以过滤掉 　　

c. 用户通常希望查“He”时能把含“he”，“HE”的文章也找出来，所以所有单词需要统一大小写。 　　

d. 用户通常希望查“live”时能把含“lives”，“lived”的文章也找出来，所以需要把“lives”，“lived”还原成“live” 　
　
e. 文章中的标点符号通常不表示某种概念，也可以过滤掉 　　

在lucene中以上措施由Analyzer类完成。 经过上面处理后，

文章 1 的所有关键词为：`[tom] [live] [guangzhou] [i] [live] [guangzhou]`　 　

文章 2 的所有关键词为：`[he] [live] [shanghai]`

## 建立倒排索引

有了关键词后，我们就可以建立倒排索引了。

对应关系是：“关键词”对“拥有该关键词的所有文章号”。

文章1，2经过倒排后变成

```
关键词          文章号 　　
guangzhou        1 　　
he               2 　　
i                1 　　
live             1,2 　　
shanghai         2 　　
tom              1
```

通常仅知道关键词在哪些文章中出现还不够，我们还需要知道关键词在文章中出现次数和出现的位置，通常有两种位置：

a. 字符位置，即记录该词是文章中第几个字符（优点是关键词亮显时定位快）；

b. 关键词位置，即记录该词是文章中第几个关键词（优点是节约索引空间、词组（phase）查询快），lucene中记录的就是这种位置。 　　

加上“出现频率”和“出现位置”信息后，我们的索引结构变为：

```
关键词            文章号[出现频率]              出现位置 　　
guangzhou           1[2]                      3，6 　　
he                  2[1]                      1 　　
i                   1[1]                      4 　　
live                1[2]                      2，5, 
                    2[1]                      2 　　
shanghai            2[1]                      3 　　
tom                 1[1]                      1 
```

以live 这行为例：

```
live      1[2]     2，5, //文章1中出现了2次，位于文章1中的2位置,5位置
 
 　
          2[1]     2    //文章2中出现了1次，位于文章2中的2位置
```

我们注意到关键字是按字符顺序排列的（lucene没有使用B树结构），因此lucene可以用二分搜索算法快速定位关键词。

## 实现

实现时，lucene将上面三列分别作为词典文件（Term Dictionary）、频率文件(frequencies)、位置文件 (positions)保存。其中词典文件不仅保存有每个关键词，还保留了指向频率文件和位置文件的指针，通过指针可以找到该关键字的频率信息和位置信息。 　　

Lucene中使用了field的概念，用于表达信息所在位置（如标题中，文章中，url中），在建索引中，该field信息也记录在词典文件中，每个关键词都有一个field信息(因为每个关键字一定属于一个或多个field)。

## 压缩算法

为了减小索引文件的大小，Lucene对索引还使用了压缩技术。

首先，对词典文件中的关键词进行了压缩，关键词压缩为<前缀长度，后缀>，例如：当前词为“阿拉伯语”，上一个词为“阿拉伯”，那么“阿拉伯语”压缩为<3，语>。

其次大量用到的是对数字的压缩，数字只保存与上一个值的差值（这样可以减小数字的长度，进而减少保存该数字需要的字节数）。

例如当前文章号是16389（不压缩要用3个字节保存），上一文章号是16382，压缩后保存7（只用一个字节）。

ps: 压缩就是空间和时间之间的 trade-off。

## 应用原因

下面我们可以通过对该索引的查询来解释一下为什么要建立索引。 　　

假设要查询单词 “live”，lucene先对词典二元查找、找到该词，通过指向频率文件的指针读出所有文章号，然后返回结果。

词典通常非常小，因而，整个过程的时间是毫秒级的。 　　

而用普通的顺序匹配算法，不建索引，而是对所有文章的内容进行字符串匹配，这个过程将会相当缓慢，当文章数目很大时，时间往往是无法忍受的。

# 拓展阅读

前缀树 Trie Tree 算法

Regex 与 DFA 算法

分词算法

关键词提取算法

摘要生成算法

相似度分析算法

[luence 基础知识](https://houbb.github.io/2018/11/15/lucence-base)

# 参考资料

[倒排索引原理和实现](https://blog.csdn.net/zhou920786312/article/details/83857264)

* any list
{:toc}